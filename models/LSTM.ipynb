{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b680a614",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb1a44",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. Imports\n",
    "2. Data\n",
    "3. Model\n",
    "5. Train\n",
    "6. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b23d55",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baed98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc101f4",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846f422",
   "metadata": {},
   "source": [
    "### Ingestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path of the current working directory\n",
    "curPath = os.getcwd()\n",
    "# Appened the parent directory to the current path to step out of the current folder\n",
    "parentDir = os.path.abspath(os.path.join(curPath, os.pardir))\n",
    "print(\"Parent Directory\", parentDir)\n",
    "# Save the path to all of the datasets\n",
    "india_cases_path = os.path.join(parentDir, \"cleaned_datasets/india/daily_cases_india.csv\")\n",
    "india_vacc_path = os.path.join(parentDir, \"cleaned_datasets/india/daily_vacc_india.csv\")\n",
    "usa_cases_path = os.path.join(parentDir, \"cleaned_datasets/usa/daily_cases_usa.csv\")\n",
    "usa_vacc_path = os.path.join(parentDir, \"cleaned_datasets/usa/vacc_usa.csv\")\n",
    "\n",
    "# Quick check to make sure the path exists\n",
    "print(\"Path:\", india_cases_path)\n",
    "print(\"Exists:\", os.path.exists(india_cases_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb50f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data as a pandas dataframe\n",
    "india_cases_df = pd.read_csv(india_cases_path)\n",
    "india_vacc_df =  pd.read_csv(india_vacc_path)\n",
    "\n",
    "usa_cases_df = pd.read_csv(usa_cases_path)\n",
    "usa_vacc_df = pd.read_csv(usa_vacc_path)\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('India Vacc:\\n',india_vacc_df.head(),'\\n')\n",
    "\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')\n",
    "print('USA Vacc:\\n',usa_vacc_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01edd055",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c9fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the Confirmed column for univariate analysis\n",
    "# Selecting from the first index because the 0th index is NaN\n",
    "india_cases_df = india_cases_df[[\"Confirmed\"]][1:]\n",
    "usa_cases_df = usa_cases_df[[\"Confirmed\"]][1:]\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55483a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "india_cases_mean = india_cases_df.mean()\n",
    "india_cases_std = india_cases_df.std()\n",
    "\n",
    "usa_cases_mean = usa_cases_df.mean()\n",
    "usa_cases_std = usa_cases_df.std()\n",
    "\n",
    "\n",
    "india_cases_df = (india_cases_df-india_cases_mean)/india_cases_std\n",
    "usa_cases_df = (usa_cases_df-usa_cases_mean)/usa_cases_std\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5cc363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train test splits\n",
    "india_cases_train, india_cases_test = train_test_split(india_cases_df, test_size=0.2)\n",
    "india_vacc_train, india_vacc_test = train_test_split(india_vacc_df, test_size=0.2)\n",
    "\n",
    "usa_cases_train, usa_cases_test = train_test_split(usa_cases_df, test_size=0.2)\n",
    "usa_vacc_train, usa_vacc_test = train_test_split(usa_vacc_df, test_size=0.2)\n",
    "\n",
    "# Visualize splits\n",
    "print('India Cases:\\n',india_cases_train,'\\n')\n",
    "print('USA Cases:\\n',usa_cases_train,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01face15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "india_cases_train, india_cases_test = india_cases_train.to_numpy().flatten(), india_cases_test.to_numpy()\n",
    "usa_cases_train, usa_cases_test = usa_cases_train.to_numpy().flatten(), usa_cases_test.to_numpy()\n",
    "\n",
    "# Visualize outputs\n",
    "print('India Cases:\\n',india_cases_train,'\\n')\n",
    "print('USA Cases:\\n',usa_cases_train,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate data preparation\n",
    "from numpy import array\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca8149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "india_cases_train_X, india_cases_train_y = split_sequence(india_cases_train, n_steps)\n",
    "india_cases_test_X, india_cases_test_y = split_sequence(india_cases_test, n_steps)\n",
    "\n",
    "\n",
    "# summarize the data\n",
    "for i in range(0,5):\n",
    "    print(india_cases_train_X[i], india_cases_train_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data into [samples, timesteps, features]\n",
    "# univariate\n",
    "n_features = 1\n",
    "\n",
    "india_cases_train_X = india_cases_train_X.reshape((india_cases_train_X.shape[0], \n",
    "                                                   india_cases_train_X.shape[1], n_features))\n",
    "india_cases_test_X = india_cases_test_X.reshape((india_cases_test_X.shape[0], \n",
    "                                                 india_cases_test_X.shape[1], n_features))\n",
    "\n",
    "# Visualize outputs\n",
    "print('India Cases:\\n',india_cases_train_X,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e40f6",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6119e325",
   "metadata": {},
   "source": [
    "### Univariate non-stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7cc198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d80147",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_uni = Sequential()\n",
    "model_uni.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model_uni.add(Dense(1))\n",
    "model_uni.compile(optimizer='adam',loss='mse')\n",
    "model_uni.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc2a67",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8645ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_uni_stacked = Sequential()\n",
    "model_uni_stacked.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model_uni_stacked.add(LSTM(50, activation='relu'))\n",
    "model_uni_stacked.add(Dense(1))\n",
    "model_uni_stacked.compile(optimizer='adam',loss='mse')\n",
    "model_uni_stacked.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b14488",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38071f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard callback\n",
    "logdir = os.path.join(parentDir+\"/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190a5d2",
   "metadata": {},
   "source": [
    "### Univariate non-stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7019359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model_uni.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=500,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae07aa",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582c6a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model_uni_stacked.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=500,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a274610",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdf2acf",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d40ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array([india_cases_test_X[25]])\n",
    "print(x_input)\n",
    "yhat = model_uni.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3295d5",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d40ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array([india_cases_test_X[25]])\n",
    "print(x_input)\n",
    "yhat = model_uni_stacked.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3261c5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
