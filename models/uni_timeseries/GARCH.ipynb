{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GARCH Model\n",
    "\n",
    "- While autoregressive models are good at predicting univariate time series data with trends (ARIMA) and seasonality (SARIMA), they assume that the variance of the errors does not change over time.\n",
    "\n",
    "- In time series where varinace changes over time due to volatility, the series is said to be heteroscedastic (typically financial data). \n",
    "\n",
    "- Heteroscedastic time series can sometimes be adjusted by transforming the data (log-transform, power transform).\n",
    "\n",
    "- If the change in variance can be correlated over time, then it can be modelled using an AR process like ARCH or GARCH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cases_india = pd.read_csv('../../cleaned_datasets/india/daily_cases_india.csv', parse_dates=['Date'], index_col=0)\n",
    "cum_cases_india = pd.read_csv('../../cleaned_datasets/india/cum_cases_india.csv', parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_cases_india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cases_india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cases_india.iloc[0] = cum_cases_india.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cases_india.to_csv('../../cleaned_datasets/india/daily_cases_india.csv')\n",
    "daily_cases_india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_confirmed = daily_cases_india.drop(['Recovered', 'Deaths', 'Active'], axis=1)\n",
    "daily_confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the cumulative cases over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_confirmed.plot(figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for stationarity\n",
    "\n",
    "We will plot the rolling average of the plot at different window sizes and compare the plots to see if the mean is constant.\n",
    "\n",
    "We will also plot the rolling standard deviation to check for stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_ts = daily_confirmed.set_index(['Date'])['Confirmed']\n",
    "\n",
    "def roll_stats(ts, window, title):\n",
    "    ''' Function to find rolling mean and rolling std dev and plot them'''\n",
    "    rollmean = ts.rolling(window = window).mean()\n",
    "    rollstd = ts.rolling(window = window).std()\n",
    "    print(rollmean, rollstd)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    close = plt.plot(ts, color = 'blue', label = 'Original')\n",
    "    mean = plt.plot(rollmean, color = 'red', label = 'Rolling Mean')\n",
    "    std = plt.plot(rollstd, color = 'green', label = 'Rolling Standard Dev')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-day moving average\n",
    "roll_stats(daily_ts, 7, '7-day rolling statistics for Daily cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30-day moving average\n",
    "roll_stats(daily_ts, 30, '30-day rolling statistics for Daily cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From visual inspection, the time series is not stationary and needs to be differenced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Dickey-Fuller Test\n",
    "\n",
    "- $H_0:$ Presence of a unit root (Time Series is not stationary)\n",
    "- $H_1:$ There is no unit root (Time-series is stationary)\n",
    "\n",
    "$DF_t = \\frac{\\gamma}{SE(\\gamma)}$\n",
    "\n",
    "The more negative $DF_t$, the stronger evidence for rejecting $H_0$.   \n",
    "If p-value < 0.001, we can reject $H_0$ and say that the time series is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def run_dicky_fuller(ts):\n",
    "  '''Function to run Augmented Dicky Fuller test on the passed time series and report the statistics from the test'''\n",
    "  print(\"Observations of Dickey-fuller test\")\n",
    "  dftest = adfuller(ts,autolag='AIC')\n",
    "  dfoutput=pd.Series(dftest[0:4],index=['Test Statistic','p-value','#lags used','number of observations used'])\n",
    "\n",
    "  for key,value in dftest[4].items():\n",
    "      dfoutput['critical value (%s)'%key]= value\n",
    "  print(dfoutput)\n",
    "\n",
    "run_dicky_fuller(daily_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value > 0.001, the time series is not stationary and it needs to be transformed/differenced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for trend and seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "def decomp_mult(ts, period):\n",
    "    decomp = seasonal_decompose(ts, model='multiplicable', period=period)\n",
    "    fig = plt.figure()  \n",
    "    fig = decomp.plot() \n",
    "    fig.set_size_inches(16, 9)\n",
    "    \n",
    "# Some data are incorrect and < 0\n",
    "daily_pos = daily_ts[daily_ts.index[daily_ts >= 0]]\n",
    "\n",
    "# Add a constant for the 0's\n",
    "const_added = daily_pos + 1\n",
    "\n",
    "# Period = 5\n",
    "decomp_mult(const_added, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Period = 30\n",
    "decomp_mult(const_added, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Period = 100\n",
    "decomp_mult(const_added, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are two peaks in the trend, and noticable seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First-order differencing\n",
    "\n",
    "The time series is differenced to try and make the mean constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_ts_diff_1 = daily_ts - daily_ts.shift(1)\n",
    "daily_ts_diff_1.plot(figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-day moving average\n",
    "roll_stats(daily_ts_diff_1, 7, '7-day rolling statistics for first-order differenced cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second-order differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_ts_diff_2 = daily_ts_diff_1 - daily_ts_diff_1.shift(1)\n",
    "daily_ts_diff_2.plot(figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-day moving average\n",
    "roll_stats(daily_ts_diff_2, 7, '7-day rolling statistics for second-order differenced cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TS of second-prder differenced data looks stationary. As we can see, the volatility is conditional and it looks like a good candidate for a GARCH model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GARCH Model\n",
    "\n",
    "- $GARCH(p, q)$\n",
    "    - $p$: number of lag residual errors\n",
    "    - $q$: number of lag variances\n",
    "\n",
    "- Formula\n",
    "    - $a_t = \\varepsilon_t \\sqrt{\\omega + \\sum_{i=1}^{p} \\alpha_i a_{t-i}^2  + \\sum_{i=1}^{q} \\beta_i \\sigma_{t-i}^2 }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACF and PACF plots\n",
    "\n",
    "- To find the parameters of the GARCH model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf \n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = plot_acf(daily_ts_diff_2.dropna()**2, lags=100, ax = ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = plot_pacf(daily_ts_diff_2.dropna()**2, lags=100, ax = ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible model: GARCH(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_80 = int(len(daily_ts_diff_2)*0.8)\n",
    "\n",
    "train = daily_ts_diff_2.iloc[:percent_80].dropna()\n",
    "test = daily_ts_diff_2.iloc[percent_80:]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 8)\n",
    "\n",
    "ax.plot(train, color = 'blue', label = 'Train')\n",
    "ax.plot(test, color = 'red', label = 'Test')\n",
    "ax.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model \n",
    "\n",
    "model = arch_model(train, mean='Zero', vol='GARCH', p=2, q=2)\n",
    "model_fit = model.fit()\n",
    "yhat = model_fit.forecast(horizon=len(test))\n",
    "\n",
    "\n",
    "yhatvar = pd.DataFrame(pd.DataFrame(test).reset_index()['Date'])\n",
    "\n",
    "yhatvar['var'] = yhat.variance.values[-1, :]\n",
    "\n",
    "plt.plot(yhatvar['Date'], yhatvar['var'])\n",
    "plt.plot(test**2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
