{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion \n",
    "Data is ingested and the index for the dataset is set to `Date` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cases = pd.read_csv('../../cleaned_datasets/india/daily_cases_india.csv')\n",
    "daily_cases['Date'] = pd.to_datetime(daily_cases['Date'], format = '%Y-%m-%d')\n",
    "daily_cases = daily_cases[:-1]\n",
    "daily_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = daily_cases.set_index('Date')\n",
    "indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed['Confirmed'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed['Deaths'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed['Recovered'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed['Active'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Split**     \n",
    "Keep upto `08-08-2021` or 0.895 of overall timeseries as train for timeseries and beyond that for forecasting. This also eliminates the outlier caused due to missing data in `Recovered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = indexed[:\"2021-08-08\"]\n",
    "# val = indexed[\"2021-08-09\":]\n",
    "\n",
    "splitlen = int(0.9*len(daily_cases))\n",
    "\n",
    "# train = daily_cases[:splitlen-3]\n",
    "# val = daily_cases[splitlen+1-3:]\n",
    "\n",
    "train = daily_cases[:splitlen]\n",
    "val = daily_cases[splitlen:]\n",
    "\n",
    "train = train.set_index('Date')\n",
    "val = val.set_index('Date')\n",
    "\n",
    "# train = indexed[:\"2021-07-04\"]\n",
    "# val = indexed[\"2021-07-05\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Recovered'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_ts = train['Confirmed'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unvariate Time Series for Confirmed Cases \n",
    "def roll_stats(ts, window):\n",
    "  ''' Function to find rolling mean and rolling std dev and plot them'''\n",
    "  rollmean = ts.rolling(window = window).mean()\n",
    "  rollstd = ts.rolling(window = window).std()\n",
    "  print(rollmean, rollstd)\n",
    "\n",
    "  close = plt.plot(ts, color = 'blue', label = 'Original')\n",
    "  mean = plt.plot(rollmean, color = 'red', label = 'Rolling Mean')\n",
    "  std = plt.plot(rollstd, color = 'green', label = 'Rolling Standard Dev')\n",
    "  plt.legend(loc = 'best')\n",
    "  plt.title('Rolling Statistics for Confirmed')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_stats(confirmed_ts, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_stats(confirmed_ts, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def run_dicky_fuller(ts):\n",
    "  '''Function to run Augmented Dicky Fuller test on the passed time series and report the statistics from the test'''\n",
    "  print(\"Observations of Dickey-fuller test\")\n",
    "  dftest = adfuller(ts,autolag='AIC')\n",
    "  dfoutput=pd.Series(dftest[0:4],index=['Test Statistic','p-value','#lags used','number of observations used'])\n",
    "\n",
    "  for key,value in dftest[4].items():\n",
    "      dfoutput['critical value (%s)'%key]= value\n",
    "  print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dicky_fuller(confirmed_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original time-series is **Non-stationary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomp = seasonal_decompose(confirmed_ts, model='additive', freq=10)\n",
    "fig = plt.figure()  \n",
    "fig = decomp.plot()  \n",
    "fig.set_size_inches(16, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = confirmed_ts.diff() \n",
    "roll_stats(diff, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = confirmed_ts.diff() \n",
    "roll_stats(diff, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dicky_fuller(diff.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that after differencing the time-series looks stationary both in the rolling statistics plot as well as the Dicky-Fuller test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf \n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = plot_acf(diff.dropna(), lags=50, ax = ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = plot_pacf(diff.dropna(), lags=50, ax = ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(p,q) = (1,1), (1,2), (2,1), (2,2) seem viable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA \n",
    "\n",
    "# ARIMA (3,1,2) and (1,1,2) show similar results but (3,1,2) chosen due to lower AIC value\n",
    "\n",
    "# ARIMA(p,d,q) = (3,1,2)\n",
    "model_ARIMA = ARIMA(confirmed_ts, order=(3,1,2))\n",
    "results_ARIMA = model_ARIMA.fit()\n",
    "results_ARIMA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ARIMA.plot_predict(start = 100, end = 900, dynamic = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA(p,d,q) = (1,1,0) - AR model\n",
    "model_AR = ARIMA(confirmed_ts, order=(1,1,0))\n",
    "results_AR = model_AR.fit()\n",
    "results_AR.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_AR.plot_predict(start = 100, end = 900, dynamic = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA(p,d,q) = (0,1,1) - MA model\n",
    "model_MA = ARIMA(confirmed_ts, order=(0,1,1))\n",
    "results_MA = model_MA.fit()\n",
    "results_MA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_MA.plot_predict(start = 100, end = 900, dynamic = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing AIC values of ARIMA, AR and MA we can see that ARIMA is the best, so we proceed with ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc, se, conf = results_ARIMA.forecast(len(val), alpha=0.05)  # 95% conf\n",
    "\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=val.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=val.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=val.index)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5), dpi=100)\n",
    "plt.plot(confirmed_ts, label='training')\n",
    "plt.plot(val['Confirmed'], label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "# plt.plot(lower_series, linestyle = '--', color = 'grey', label = '95% Confidence Interval')\n",
    "# plt.plot(upper_series, linestyle = '--', color = 'grey')\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()\n",
    "# plt.savefig('../../figures/india_arima.eps', format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8,5), dpi=100)\n",
    "plt.plot(val['Confirmed'], label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoARIMA = pmdarima.auto_arima(confirmed_ts)\n",
    "model_autoARIMA.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that auto-ARIMA picked out (p,d,q) = (3,1,2) for this particular train-val split, but for others it was noticed that (1,1,2) was picked. As the ACF and PACF also suggest (1,1,2) we go with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = model_autoARIMA.predict(n_periods=len(val))\n",
    "\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=val.index)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(confirmed_ts, label='training')\n",
    "plt.plot(val['Confirmed'], label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ARIMA we see that ARIMA(3,1,2) or ARIMA(1,1,2) is the most optimal, but still both of them are not accurate in predicting spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try SARIMAX, with p,d,q = (1,1,2). But getting the seasonal order (P,D,Q,S) is not obvious from ACF and PACF. So we will apply GridSearch to find the most optimal SARIMAX(p,d,q)(P,D,Q,S) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoSARIMA = pmdarima.auto_arima(confirmed_ts, seasonal=True)\n",
    "model_autoSARIMA.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with seasonal ARIMA considered, we see that seasonal models aren't as effective, as `auto_arima` has predicted seasonal_order of (0,0,0,0). The models are tested based on AIC internally and SARIMA with seasonal components seem to have performed worse than non-seasonal ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = model_autoSARIMA.predict(n_periods=len(val))\n",
    "\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=val.index)\n",
    "# lower_series = pd.Series(conf[:, 0], index=val.index)\n",
    "# upper_series = pd.Series(conf[:, 1], index=val.index)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(confirmed_ts, label='training')\n",
    "plt.plot(val['Confirmed'], label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "# plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "#                  color='k', alpha=.15)\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT RUN THIS CELL\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# import itertools\n",
    "# # from sm.tsa.statespace import SARIMAX\n",
    "\n",
    "# def sarimax(ts,pdq,seasonal_pdq):\n",
    "#     results = []\n",
    "#     for order in pdq:\n",
    "#         for seas in seasonal_pdq:\n",
    "#             print(order, seas)\n",
    "#             try:\n",
    "#                 mod = sm.tsa.statespace.SARIMAX(ts,\n",
    "#                               order=order,\n",
    "#                               seasonal_order=seas)\n",
    "#                 res = mod.fit()\n",
    "#                 results.append((res,res.aic,param))\n",
    "#                 print('Tried out SARIMAX{}x{} - AIC:{}'.format(param[0], param[1], round(res.aic,2)))\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "            \n",
    "#     return results\n",
    "# # set parameter range\n",
    "# # p,d,q = range(0,3),[1],range(0,3)\n",
    "# P,D,Q,s = range(0,2),[0],range(0,2),[250]\n",
    "# # list of all parameter combos\n",
    "# pdq = [(1,1,2)]\n",
    "# seasonal_pdq = list(itertools.product(P, D, Q, s))\n",
    "# # all_param = list(itertools.product(pdq,seasonal_pdq))\n",
    "# # all_param = [(pdq, s) for s in seasonal_pdq]\n",
    "# # for param in all_param:\n",
    "# #     print(param)\n",
    "\n",
    "# all_res = sarimax(confirmed_ts,pdq, seasonal_pdq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA + GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the residuals from the ARIMA(1,1,2) model fit earlier \n",
    "resid = results_ARIMA.resid \n",
    "resid.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf \n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = plot_acf(resid.dropna(), lags=60, ax = ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = plot_pacf(resid.dropna(), lags=60, ax = ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "\n",
    "resid_GARCH = arch_model(resid, p=1, q=1)\n",
    "garch_fit = resid_GARCH.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garch_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_forecasts = garch_fit.forecast(horizon=len(val))\n",
    "resid_fc = resid_forecasts.residual_variance.values[-1, :]\n",
    "resid_fc\n",
    "resid_fc = np.sqrt(resid_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc, se, conf = results_ARIMA.forecast(len(val), alpha=0.05)  # 95% conf\n",
    "\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=val.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=val.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=val.index)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5), dpi=100)\n",
    "plt.plot(confirmed_ts, label='training')\n",
    "plt.plot(val['Confirmed'], label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "plt.fill_between(lower_series.index, fc_series + resid_fc, fc_series - resid_fc, \n",
    "                 color='k', alpha=.15)\n",
    "# plt.plot(fc_series + resid_fc, linestyle = '--', color = 'grey', label = '95% Confidence Interval')\n",
    "# plt.plot(fc_series - resid_fc, linestyle = '--', color = 'grey')\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()\n",
    "# plt.savefig('../../figures/india_arima+garch.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the Confidence Interval is now narrowed down and isn't exploding like earlier. GARCH has made the variance predictable hence the narrower CI. Without GARCH the CI was exponentially expanding (as can be seen earlier) which would lead to inaccurate prediction of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=val.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=val.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=val.index)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(val['Confirmed'], label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "plt.fill_between(lower_series.index, fc_series + resid_fc, fc_series - resid_fc, \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling forecasts (Short-term)\n",
    "\n",
    "Here only the next days cases is predicted and the data is given to the ARIMA model as it comes in to predict the following days cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = confirmed_ts.copy()\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roll_fc = pd.Series(index = val.index)\n",
    "roll_resid = pd.Series(index = val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only rolling ARIMA\n",
    "\n",
    "for exp in val['Confirmed']:\n",
    "    model = ARIMA(history, order=(3,1,2))\n",
    "    model_fit = model.fit()\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    newindex = history.index[-1] + pd.to_timedelta(1, 'D')\n",
    "    roll_fc[newindex] = yhat[0]\n",
    "    history[newindex] = exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling ARIMA + rolling GARCH\n",
    "\n",
    "# for exp in val['Confirmed']:\n",
    "#     model = ARIMA(history, order=(1,1,2))\n",
    "#     model_fit = model.fit()\n",
    "#     output = model_fit.forecast()\n",
    "#     resid = model_fit.resid\n",
    "#     roll_garch = arch_model(resid, p=1, q=1)\n",
    "#     roll_garch_fit = roll_garch.fit(disp=-1)\n",
    "#     garch_fc = roll_garch_fit.forecast().residual_variance.values[-1, :]\n",
    "#     yhat = output[0]\n",
    "#     newindex = history.index[-1] + pd.to_timedelta(1, 'D')\n",
    "#     roll_fc[newindex] = yhat[0]\n",
    "#     history[newindex] = exp\n",
    "#     roll_resid[newindex] = np.sqrt(garch_fc)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_fc.plot()\n",
    "print(val['Confirmed'])\n",
    "roll_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_series = pd.Series(conf[:, 0], index=val.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=val.index)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5), dpi=100)\n",
    "plt.plot(confirmed_ts, label='training')\n",
    "plt.plot(val['Confirmed'], label='actual')\n",
    "plt.plot(roll_fc, label='forecast')\n",
    "# plt.fill_between(lower_series.index, roll_fc + resid_fc, roll_fc - resid_fc, \n",
    "#                  color='k', alpha=.15)\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()\n",
    "# plt.savefig('../../figures/india_arima_rolling.eps', format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lower_series = pd.Series(conf[:, 0], index=val.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=val.index)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(val['Confirmed'], label='actual')\n",
    "plt.plot(roll_fc, label='forecast')\n",
    "# plt.fill_between(lower_series.index, roll_fc + resid_fc, roll_fc - resid_fc, \n",
    "#                  color='k', alpha=.15)\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower_series = pd.Series(conf[:, 0], index=val.index)\n",
    "# upper_series = pd.Series(conf[:, 1], index=val.index)\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(12,5), dpi=100)\n",
    "# plt.plot(val['Confirmed'], label='actual')\n",
    "# plt.plot(roll_fc, label='forecast')\n",
    "# plt.fill_between(lower_series.index, roll_fc + roll_resid, roll_fc - roll_resid, \n",
    "#                  color='k', alpha=.15)\n",
    "# plt.title('Forecast vs Actuals')\n",
    "# plt.legend(loc='upper left', fontsize=8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "MAPE and MAE used\n",
    "\n",
    "Comparing both short-term and long-term forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(Y_actual,Y_Predicted, title):\n",
    "    mask = Y_actual != 0\n",
    "    \n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual)[mask])*100\n",
    "#     print(mape)\n",
    "    print(f\"MAPE of {title} is {mape}%\")\n",
    "#     return mape[mape.index[0]]\n",
    "\n",
    "\n",
    "mape_fc = MAPE(val['Confirmed'], fc_series, title=\"Long-term\")\n",
    "mape_roll = MAPE(val['Confirmed'], roll_fc, title=\"Short-term (rolling)\")\n",
    "# mape_cases = MAPE(test_original[['undiff_Confirmed']], fore_original[['undiff_Confirmed']], title=\"Daily cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MeanAbsolutePercentageError, MeanAbsoluteError\n",
    "\n",
    "mape_keras = MeanAbsolutePercentageError() \n",
    "\n",
    "print(mape_keras(val['Confirmed'], fc_series).numpy())\n",
    "print(mape_keras(val['Confirmed'], roll_fc).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE of Long-term:', mean_absolute_error(val['Confirmed'], fc_series))\n",
    "print('MAE of short-term:', mean_absolute_error(val['Confirmed'], roll_fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
