{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da7f88f7",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b493ee8",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. [Imports](#imports)\n",
    "2. [Data](#data)\n",
    "3. [Model](#model)\n",
    "5. [Train](#train)\n",
    "6. [Predict](#predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184bbb54",
   "metadata": {},
   "source": [
    "<a name=imports></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f68681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68972792",
   "metadata": {},
   "source": [
    "<a name=data></a>\n",
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8f3b4",
   "metadata": {},
   "source": [
    "### Ingestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6ed14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Directory /covid19-prediction/models\n",
      "Path: /covid19-prediction/models/../cleaned_datasets/india/daily_cases_india.csv\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "# Get the path of the current working directory\n",
    "curPath = os.getcwd()\n",
    "# Appened the parent directory to the current path to step out of the current folder\n",
    "parentDir = os.path.abspath(os.path.join(curPath, os.pardir))\n",
    "print(\"Parent Directory\", parentDir)\n",
    "# Save the path to all of the datasets\n",
    "india_cases_path = os.path.join(parentDir, \"../cleaned_datasets/india/daily_cases_india.csv\")\n",
    "india_vacc_path = os.path.join(parentDir, \"../cleaned_datasets/india/daily_vacc_india.csv\")\n",
    "usa_cases_path = os.path.join(parentDir, \"../cleaned_datasets/usa/daily_cases_usa.csv\")\n",
    "usa_vacc_path = os.path.join(parentDir, \"../cleaned_datasets/usa/vacc_usa.csv\")\n",
    "\n",
    "# Quick check to make sure the path exists\n",
    "print(\"Path:\", india_cases_path)\n",
    "print(\"Exists:\", os.path.exists(india_cases_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c18b18a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "    Unnamed: 0        Date  Confirmed  Deaths  Recovered  Active\n",
      "0           0  2020-01-30        1.0     0.0        0.0     0.0\n",
      "1           1  2020-01-31        0.0     0.0        0.0     0.0\n",
      "2           2  2020-02-01        0.0     0.0        0.0     0.0\n",
      "3           3  2020-02-02        1.0     0.0        0.0     0.0\n",
      "4           4  2020-02-03        1.0     0.0        0.0     0.0 \n",
      "\n",
      "India Vacc:\n",
      "    Updated On  Total_Doses  First_Dose  Second_Dose\n",
      "0  2021-01-16          NaN         NaN          NaN\n",
      "1  2021-01-17      20656.0     20656.0          0.0\n",
      "2  2021-01-18      81690.0     81690.0          0.0\n",
      "3  2021-01-19     192152.0    192152.0          0.0\n",
      "4  2021-01-20     111510.0    111510.0          0.0 \n",
      "\n",
      "USA Cases:\n",
      "          Date  Confirmed  Deaths  Recovered\n",
      "0  2020-04-12        NaN     NaN        NaN\n",
      "1  2020-04-13    25322.0  1546.0    11785.0\n",
      "2  2020-04-14    26713.0  2305.0     6484.0\n",
      "3  2020-04-15    29380.0  2478.0     6093.0\n",
      "4  2020-04-16    31542.0  4616.0     5234.0 \n",
      "\n",
      "USA Vacc:\n",
      "          date  total_doses  people_vacc  people_fully_vacc  daily_vacc\n",
      "0  2020-12-20     556208.0          0.0                0.0         0.0\n",
      "1  2020-12-21     614117.0          0.0                0.0     57909.0\n",
      "2  2020-12-22          0.0          0.0                0.0    127432.0\n",
      "3  2020-12-23    1008025.0          0.0                0.0    150606.0\n",
      "4  2020-12-24          0.0          0.0                0.0    191001.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data as a pandas dataframe\n",
    "india_cases_df = pd.read_csv(india_cases_path)\n",
    "india_vacc_df =  pd.read_csv(india_vacc_path)\n",
    "\n",
    "usa_cases_df = pd.read_csv(usa_cases_path)\n",
    "usa_vacc_df = pd.read_csv(usa_vacc_path)\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('India Vacc:\\n',india_vacc_df.head(),'\\n')\n",
    "\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')\n",
    "print('USA Vacc:\\n',usa_vacc_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f3fa3",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897297ae",
   "metadata": {},
   "source": [
    "### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03503052",
   "metadata": {},
   "outputs": [],
   "source": [
    "india_cases_multi_df = india_cases_df[[\"Date\",\"Confirmed\",\"Deaths\",\"Recovered\",\"Active\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd4455",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d328699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "    Confirmed\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "5        0.0 \n",
      "\n",
      "USA Cases:\n",
      "    Confirmed\n",
      "1    25322.0\n",
      "2    26713.0\n",
      "3    29380.0\n",
      "4    31542.0\n",
      "5    32022.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select only the Confirmed column for univariate analysis\n",
    "# Selecting from the first index because the 0th index is NaN\n",
    "india_cases_df = india_cases_df[[\"Confirmed\"]][1:]\n",
    "usa_cases_df = usa_cases_df[[\"Confirmed\"]][1:]\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1dcbb1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "    Confirmed\n",
      "1  -0.687995\n",
      "2  -0.687995\n",
      "3  -0.687983\n",
      "4  -0.687983\n",
      "5  -0.687995 \n",
      "\n",
      "USA Cases:\n",
      "    Confirmed\n",
      "1  -0.817861\n",
      "2  -0.797170\n",
      "3  -0.757499\n",
      "4  -0.725340\n",
      "5  -0.718200 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "india_cases_mean = india_cases_df.mean()\n",
    "india_cases_std = india_cases_df.std()\n",
    "\n",
    "usa_cases_mean = usa_cases_df.mean()\n",
    "usa_cases_std = usa_cases_df.std()\n",
    "\n",
    "\n",
    "india_cases_normalized_df = (india_cases_df-india_cases_mean)/india_cases_std\n",
    "usa_cases_normalized_df = (usa_cases_df-usa_cases_mean)/usa_cases_std\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_normalized_df.head(),'\\n')\n",
    "print('USA Cases:\\n',usa_cases_normalized_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "285d674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "      Confirmed\n",
      "1    -0.687995\n",
      "2    -0.687995\n",
      "3    -0.687983\n",
      "4    -0.687983\n",
      "5    -0.687995\n",
      "..         ...\n",
      "492   0.750239\n",
      "493   0.576535\n",
      "494   0.398886\n",
      "495   0.475509\n",
      "496   0.486403\n",
      "\n",
      "[496 rows x 1 columns] \n",
      "\n",
      "USA Cases:\n",
      "      Confirmed\n",
      "1    -0.817861\n",
      "2    -0.797170\n",
      "3    -0.757499\n",
      "4    -0.725340\n",
      "5    -0.718200\n",
      "..         ...\n",
      "434  -1.128237\n",
      "435  -1.020678\n",
      "436  -1.035523\n",
      "437  -1.001267\n",
      "438  -0.989828\n",
      "\n",
      "[438 rows x 1 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create train test splits\n",
    "india_cases_train, india_cases_test = train_test_split(india_cases_normalized_df, test_size=0.2, shuffle=False)\n",
    "india_vacc_train, india_vacc_test = train_test_split(india_vacc_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "usa_cases_train, usa_cases_test = train_test_split(usa_cases_normalized_df, test_size=0.2, shuffle=False)\n",
    "usa_vacc_train, usa_vacc_test = train_test_split(usa_vacc_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Visualize splits\n",
    "print('India Cases:\\n',india_cases_train,'\\n')\n",
    "print('USA Cases:\\n',usa_cases_train,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17fa1445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      " [-6.87995117e-01 -6.87995117e-01 -6.87982552e-01 -6.87982552e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87969986e-01\n",
      " -6.87995117e-01 -6.87706113e-01 -6.87969986e-01 -6.87982552e-01\n",
      " -6.87957421e-01 -6.87932290e-01 -6.87944855e-01 -6.87831767e-01\n",
      " -6.87919725e-01 -6.87856898e-01 -6.87882028e-01 -6.87743809e-01\n",
      " -6.87856898e-01 -6.87919725e-01 -6.87706113e-01 -6.87819202e-01\n",
      " -6.87517632e-01 -6.87366848e-01 -6.86914494e-01 -6.87165802e-01\n",
      " -6.86700882e-01 -6.87530198e-01 -6.86474705e-01 -6.87115540e-01\n",
      " -6.85984655e-01 -6.86738578e-01 -6.87530198e-01 -6.85142775e-01\n",
      " -6.86160571e-01 -6.80443321e-01 -6.81146982e-01 -6.87693548e-01\n",
      " -6.81523944e-01 -6.81637032e-01 -6.73042309e-01 -6.81297767e-01\n",
      " -6.80393059e-01 -6.77829721e-01 -6.77025536e-01 -6.77339671e-01\n",
      " -6.78457990e-01 -6.72313517e-01 -6.75002509e-01 -6.77503021e-01\n",
      " -6.74072671e-01 -6.76409832e-01 -6.70780540e-01 -6.64208844e-01\n",
      " -6.76384701e-01 -6.68631859e-01 -6.71785771e-01 -6.66546005e-01\n",
      " -6.69737613e-01 -6.65967998e-01 -6.67802544e-01 -6.68380551e-01\n",
      " -6.64460151e-01 -6.66156478e-01 -6.65364859e-01 -6.57913586e-01\n",
      " -6.57310448e-01 -6.52736648e-01 -6.38588024e-01 -6.50763882e-01\n",
      " -6.42923082e-01 -6.45725163e-01 -6.45976471e-01 -6.48879074e-01\n",
      " -6.33297997e-01 -6.42671774e-01 -6.43714701e-01 -6.40711574e-01\n",
      " -6.38462371e-01 -6.40410005e-01 -6.26877086e-01 -6.24539924e-01\n",
      " -6.29817386e-01 -6.10755697e-01 -6.18219536e-01 -6.10114863e-01\n",
      " -6.05465670e-01 -6.04699182e-01 -5.98617536e-01 -6.07400740e-01\n",
      " -6.14575574e-01 -5.96355767e-01 -5.96267809e-01 -5.86152674e-01\n",
      " -5.83250070e-01 -5.77645909e-01 -5.90475167e-01 -5.77155859e-01\n",
      " -5.66952766e-01 -5.63736028e-01 -5.68988359e-01 -5.56837632e-01\n",
      " -5.51484778e-01 -5.81918140e-01 -5.59602016e-01 -6.82504044e-01\n",
      " -4.24725177e-01 -6.87995117e-01 -5.44020939e-01 -5.38102643e-01\n",
      " -4.09433104e-01 -5.50102586e-01 -5.26140397e-01 -5.17281801e-01\n",
      " -5.05595993e-01 -4.94324843e-01 -5.01763551e-01 -5.00356228e-01\n",
      " -4.87351055e-01 -4.75363678e-01 -4.70664224e-01 -4.54882101e-01\n",
      " -4.37868570e-01 -4.43485297e-01 -4.55259062e-01 -4.53612997e-01\n",
      " -4.47393131e-01 -4.25340881e-01 -4.01868743e-01 -3.75745308e-01\n",
      " -3.83309669e-01 -4.08402743e-01 -4.02094920e-01 -3.75380912e-01\n",
      " -3.54937031e-01 -3.47297277e-01 -3.28549723e-01 -3.26966485e-01\n",
      " -3.29906785e-01 -3.18208412e-01 -2.77408608e-01 -2.48520788e-01\n",
      " -2.45040177e-01 -2.01752426e-01 -1.80039442e-01 -2.21417253e-01\n",
      " -2.13777500e-01 -1.13505730e-01 -6.83959989e-02 -7.33467605e-02\n",
      " -7.71792028e-02 -5.99646258e-02 -1.29375811e-01 -6.49256036e-01\n",
      "  5.53552846e-01 -2.47564180e-02  8.15341709e-02 -2.28787121e-04\n",
      " -2.23815603e-02 -3.39668450e-02 -2.81993334e-02  1.92098630e-02\n",
      "  9.78189094e-02  8.52409594e-02  1.21203090e-01  9.18629171e-02\n",
      " -1.44779333e-02  7.80284286e-02  1.53873090e-01  1.23138160e-01\n",
      "  1.25387363e-01  1.16566463e-01  3.71657977e-02  3.32721674e-03\n",
      "  1.23376902e-01  1.87460364e-01  1.77759887e-01  1.90023702e-01\n",
      "  1.82019552e-01  8.36200248e-02  7.81792132e-02  3.10464553e-02\n",
      "  3.88694999e-01  2.82881895e-01  2.72904979e-01  3.01667145e-01\n",
      "  2.98538364e-01  1.90589144e-01  2.96590730e-01  3.66027045e-01\n",
      "  3.59216607e-01  3.98056211e-01  4.50830826e-01  4.52966942e-01\n",
      "  2.64574129e-01  4.39195280e-01  5.14951984e-01  5.25205338e-01\n",
      "  5.38009465e-01  4.97825365e-01  4.68912415e-01 -6.87995117e-01\n",
      "  1.49752737e+00  5.42080650e-01  5.23609534e-01  4.84820192e-01\n",
      "  4.75622330e-01  4.04703299e-01  2.55451660e-01  3.59291999e-01\n",
      "  3.99011180e-01  3.93281365e-01  3.84611249e-01  4.25297965e-01\n",
      "  3.44502541e-01  1.98982821e-01  3.23166518e-01  4.02944145e-01\n",
      "  2.41114556e-01  4.05419526e-01  2.64825437e-01  2.47397249e-01\n",
      "  8.18483055e-02  2.17328283e-01  2.98689149e-01  1.97814241e-01\n",
      "  2.32695748e-01  2.46655891e-01  1.50518133e-01  7.39840138e-03\n",
      "  1.10019898e-01  1.62781948e-01  1.08285875e-01  9.37225940e-02\n",
      "  8.94377979e-02  1.21732475e-02 -1.00060768e-01 -8.91146793e-03\n",
      "  1.36433976e-02 -4.86541407e-03 -1.73805372e-02 -5.81049489e-02\n",
      " -1.20693130e-01 -2.29735538e-01 -1.36462688e-01 -6.12211643e-02\n",
      " -7.67142836e-02 -8.14891298e-02 -9.78869568e-02 -1.19650203e-01\n",
      " -2.06615230e-01 -1.06808380e-01 -5.70871527e-02 -8.94053221e-02\n",
      " -5.52526066e-02 -1.14083738e-01 -1.11206265e-01 -2.09593226e-01\n",
      " -1.31587318e-01 -8.60503644e-02 -1.24073218e-01 -1.26523468e-01\n",
      " -1.71557807e-01 -3.04147746e-01 -3.30962277e-01 -1.93346184e-01\n",
      " -1.15315145e-01 -1.11470138e-01 -1.07072253e-01 -1.19926641e-01\n",
      " -1.34376834e-01 -2.10824634e-01 -1.30393607e-01 -1.28973718e-01\n",
      " -1.46653215e-01 -1.68768292e-01 -1.62636384e-01 -2.00810023e-01\n",
      " -2.96985477e-01 -2.28051777e-01 -2.41283127e-01 -2.28164865e-01\n",
      " -2.27448638e-01 -2.35503050e-01 -2.73576165e-01 -3.54170542e-01\n",
      " -2.84897577e-01 -2.91921627e-01 -3.18912073e-01 -3.10644050e-01\n",
      " -3.07841969e-01 -3.47837589e-01 -4.10739904e-01 -3.56495139e-01\n",
      " -3.86300231e-01 -4.00373462e-01 -3.71950562e-01 -3.53454316e-01\n",
      " -3.82191350e-01 -4.42266454e-01 -3.87054154e-01 -3.77479331e-01\n",
      " -3.98149389e-01 -4.08126304e-01 -4.52620331e-01 -4.36423550e-01\n",
      " -4.81520716e-01 -4.29789027e-01 -4.13793293e-01 -4.36247635e-01\n",
      " -1.96512661e-01 -7.11341602e-01 -4.80616008e-01 -4.82236943e-01\n",
      " -4.60712439e-01 -4.32339800e-01 -4.60071604e-01 -6.87995117e-01\n",
      " -2.24747080e-01 -4.83041128e-01 -5.29872316e-01 -4.87351055e-01\n",
      " -4.75062108e-01 -4.92100770e-01 -4.97529016e-01 -4.97704932e-01\n",
      " -5.14743593e-01 -5.61713001e-01 -5.14391762e-01 -4.96448393e-01\n",
      " -5.05231597e-01 -5.08862993e-01 -5.01411720e-01 -5.22094343e-01\n",
      " -5.73624986e-01 -5.28552951e-01 -5.41407339e-01 -4.51074789e-01\n",
      " -5.23614755e-01 -5.24092239e-01 -5.44297378e-01 -5.79493020e-01\n",
      " -5.49285836e-01 -5.25914220e-01 -5.32083824e-01 -5.40816766e-01\n",
      " -5.36469143e-01 -5.39334051e-01 -5.73524463e-01 -5.48934005e-01\n",
      " -5.25612651e-01 -5.71023951e-01 -5.35413651e-01 -5.34772816e-01\n",
      " -5.41620951e-01 -5.73386243e-01 -5.42111001e-01 -5.26140397e-01\n",
      " -5.22219997e-01 -5.12167689e-01 -5.08762470e-01 -5.09579220e-01\n",
      " -5.55003086e-01 -5.15321601e-01 -4.77675708e-01 -4.79698735e-01\n",
      " -4.80817055e-01 -4.77499793e-01 -4.93106001e-01 -5.33616801e-01\n",
      " -4.99652566e-01 -4.69269466e-01 -4.76419170e-01 -4.58249624e-01\n",
      " -4.52343893e-01 -4.54291527e-01 -4.94638978e-01 -4.62810858e-01\n",
      " -4.00825816e-01 -3.95410135e-01 -3.75343216e-01 -3.69839577e-01\n",
      " -3.57638589e-01 -3.80243716e-01 -3.24817804e-01 -2.37262204e-01\n",
      " -1.88822646e-01 -1.73404919e-01 -1.37053261e-01 -9.80377414e-02\n",
      " -1.76395480e-01 -9.41299067e-02 -1.60486064e-02  5.48452939e-02\n",
      "  9.43006017e-02  1.00030417e-01  1.66702348e-01  1.83177207e-02\n",
      " -1.59983449e-02  2.20859156e-01  3.35656510e-01  4.31945053e-01\n",
      "  4.83714438e-01  6.13250989e-01  5.30621019e-01  7.66272243e-01\n",
      "  9.05157440e-01  9.70233567e-01  1.13881077e+00  1.23298833e+00\n",
      "  1.43444914e+00  1.34427994e+00  1.62870999e+00  1.83436764e+00\n",
      "  2.04312894e+00  2.26100014e+00  2.59652104e+00  2.75243234e+00\n",
      "  2.56853793e+00  3.02077869e+00  3.26562778e+00  3.49528531e+00\n",
      "  3.66950437e+00  3.70600681e+00  3.74747258e+00  3.37091313e+00\n",
      "  3.84719148e+00  4.07815581e+00  4.16921715e+00  4.36320156e+00\n",
      "  4.24376758e+00  3.93682036e+00  3.80181787e+00  4.11381637e+00\n",
      "  4.49435905e+00  4.51643643e+00  4.35170423e+00  4.38094389e+00\n",
      "  3.91714297e+00  3.45785303e+00  3.69004877e+00  3.86980917e+00\n",
      "  3.62374124e+00  3.40955169e+00  3.22197563e+00  2.84772821e+00\n",
      "  2.62339840e+00  2.67115943e+00  2.78143324e+00  2.57336304e+00\n",
      "  2.54506579e+00  2.33827726e+00  2.10547838e+00  1.78018570e+00\n",
      "  1.93717761e+00  1.96704553e+00  1.65374023e+00  1.49574308e+00\n",
      "  1.39224201e+00  1.23116634e+00  9.14217082e-01  9.80537182e-01\n",
      "  9.97701498e-01  9.75209459e-01  8.26498132e-01  7.50238812e-01\n",
      "  5.76534935e-01  3.98885526e-01  4.75509242e-01  4.86403430e-01] \n",
      "\n",
      "USA Cases:\n",
      " [-8.17861165e-01 -7.97170404e-01 -7.57499478e-01 -7.25340295e-01\n",
      " -7.18200420e-01 -7.11060546e-01 -7.99029746e-01 -8.18233033e-01\n",
      " -7.77149007e-01 -7.67703548e-01 -7.71035490e-01 -6.55875268e-01\n",
      " -7.04500787e-01 -7.87263829e-01 -8.57204847e-01 -8.28318106e-01\n",
      " -7.85449111e-01 -7.56978862e-01 -6.85832991e-01 -7.64029488e-01\n",
      " -8.18322282e-01 -8.58528698e-01 -8.36469462e-01 -8.34654744e-01\n",
      " -7.69339770e-01 -7.88037315e-01 -8.16135695e-01 -9.00817578e-01\n",
      " -9.23888297e-01 -8.64389345e-01 -8.84693362e-01 -7.93927711e-01\n",
      " -8.21654223e-01 -8.19869254e-01 -9.06767474e-01 -8.73537309e-01\n",
      " -8.93023216e-01 -8.49618730e-01 -8.15258086e-01 -8.38730422e-01\n",
      " -8.76839501e-01 -8.86314709e-01 -9.13907348e-01 -9.22638819e-01\n",
      " -9.07213716e-01 -8.67096547e-01 -8.28392479e-01 -8.25834024e-01\n",
      " -8.98392996e-01 -8.91297746e-01 -8.81867162e-01 -8.99062359e-01\n",
      " -8.75322277e-01 -7.51430585e-01 -8.51582196e-01 -9.17581408e-01\n",
      " -9.45679788e-01 -9.28082973e-01 -8.72555576e-01 -8.65966067e-01\n",
      " -8.07880216e-01 -8.12089766e-01 -9.02528173e-01 -9.17804529e-01\n",
      " -8.37674316e-01 -7.91919622e-01 -7.77506001e-01 -7.20104387e-01\n",
      " -7.02091079e-01 -8.03789663e-01 -7.25786537e-01 -6.53108567e-01\n",
      " -6.51011229e-01 -5.93550116e-01 -5.06294903e-01 -5.67697822e-01\n",
      " -5.69096047e-01 -6.02370836e-01 -4.90527681e-01 -4.35744021e-01\n",
      " -3.78387032e-01 -3.85512031e-01 -4.81736711e-01 -4.51793863e-01\n",
      " -5.10787074e-01 -3.14232287e-01 -3.14009166e-01 -2.90209585e-01\n",
      " -1.84539446e-01 -2.83039961e-01 -2.98732810e-01 -3.36975761e-01\n",
      " -1.92066064e-01 -1.84807192e-01 -6.52291732e-02 -1.32105995e-01\n",
      " -2.22574151e-01 -2.73029263e-01 -3.02972110e-01 -2.12518829e-01\n",
      " -1.51696025e-01 -1.76209593e-01 -8.52654453e-02 -2.20640435e-01\n",
      " -3.36291523e-01 -3.50258902e-01 -2.50598158e-01 -1.73234646e-01\n",
      " -1.76730209e-01 -1.77548320e-01 -3.10379730e-01 -4.97503933e-01\n",
      " -5.10623452e-01 -3.66323619e-01 -3.78089537e-01 -3.36440271e-01\n",
      " -2.91191318e-01 -3.61816573e-01 -4.62191305e-01 -5.11203567e-01\n",
      " -4.11170954e-01 -4.17343970e-01 -4.30850232e-01 -2.23139391e-01\n",
      " -4.49458530e-01 -5.89563686e-01 -6.70497136e-01 -5.54474180e-01\n",
      " -5.43570997e-01 -5.32310820e-01 -4.58591619e-01 -5.26063430e-01\n",
      " -6.78038628e-01 -6.68578295e-01 -5.88909198e-01 -5.64514628e-01\n",
      " -5.06964267e-01 -4.98619539e-01 -5.17436082e-01 -6.76610653e-01\n",
      " -6.75733043e-01 -5.45236967e-01 -6.02608832e-01 -6.44124225e-01\n",
      " -4.34851537e-01 -5.42291769e-01 -7.29817591e-01 -8.30698064e-01\n",
      " -8.17266175e-01 -6.70110393e-01 -6.78782365e-01 -4.77512285e-01\n",
      " -5.65555859e-01 -6.83988523e-01 -6.95620568e-01 -6.08573602e-01\n",
      " -6.24325949e-01 -5.19191301e-01 -4.60748456e-01 -5.50710871e-01\n",
      " -6.00719740e-01 -4.39358582e-01 -5.92761755e-01 -6.34663892e-01\n",
      " -4.83551429e-01 -4.03525339e-01 -5.16945216e-01 -6.15609353e-01\n",
      " -7.06434503e-01 -5.34720528e-01 -5.93713738e-01 -5.09701218e-01\n",
      " -3.70339798e-01 -4.52864845e-01 -6.64115873e-01 -6.19238789e-01\n",
      " -5.16781594e-01 -4.50246891e-01 -3.14157913e-01 -3.47566575e-01\n",
      " -3.66293870e-01 -5.00716877e-01 -5.68471308e-01 -4.25078834e-01\n",
      " -3.14024040e-01 -2.23258389e-01 -1.64756045e-01 -3.41378684e-01\n",
      " -4.36279512e-01 -1.91352076e-01 -2.73416006e-01 -2.64119295e-01\n",
      " -5.92644033e-02  4.50818835e-02  4.67627289e-02 -2.59984117e-01\n",
      " -1.98462201e-01 -3.23857518e-02 -2.38774017e-02  1.65626760e-01\n",
      "  2.99425028e-01  1.50067784e-01  3.72281495e-01  6.54007756e-02\n",
      "  7.12957618e-01  3.44852478e-01  7.39018159e-01  7.11767639e-01\n",
      "  7.64468836e-01  6.45575055e-01 -5.22286522e-02  9.60116264e-01\n",
      "  1.00725431e+00  1.23089599e+00  1.49825453e+00  1.34928403e+00\n",
      "  8.41281983e-01  1.19635685e+00  1.24075795e+00  1.38490903e+00\n",
      "  1.65626888e+00  1.80541787e+00  1.49548783e+00  9.79379050e-01\n",
      "  1.38065486e+00  1.44241477e+00  1.55504628e+00  5.33538529e-01\n",
      "  1.85448963e+00  1.14988817e+00  8.93432814e-01  1.13767601e+00\n",
      "  1.68877018e+00  1.84208410e+00  2.14497839e+00  2.29667097e+00\n",
      "  2.08858826e+00  1.46196017e+00  1.65467728e+00  2.23446482e+00\n",
      "  2.10074092e+00  2.28994759e+00  2.38614252e+00  2.07860731e+00\n",
      "  1.58525688e+00  1.80938943e+00  2.09958069e+00  2.38184372e+00\n",
      "  2.33842436e+00  2.50173411e+00  1.79744501e+00  1.56200766e+00\n",
      "  1.65060160e+00  1.79841187e+00  2.15860365e+00  1.85892231e+00\n",
      "  4.11729300e-01  2.05550684e+00  1.10327074e+00  1.30385658e+00\n",
      "  1.79832262e+00  2.10407286e+00  2.65531578e+00  1.25509719e+00\n",
      "  3.21529016e+00  1.82595989e+00  1.52238136e+00  2.24486226e+00\n",
      "  2.61798018e+00  3.09953495e+00  3.31264532e+00  2.65954020e+00\n",
      "  1.96932261e+00  1.95904417e+00  2.05461436e+00  2.21911409e+00\n",
      "  2.35499482e+00  2.46752221e+00  1.90079469e+00  1.42997949e+00\n",
      "  8.99114964e-01  1.26600038e+00  1.56171017e+00  1.66120729e+00\n",
      "  1.62208673e+00  1.39732944e+00  8.52110792e-01  9.31155149e-01\n",
      "  9.52678895e-01  1.11548290e+00  1.28325507e+00  1.28591765e+00\n",
      "  9.57870179e-01  5.18396046e-01  7.33722752e-01  5.04532790e-01\n",
      "  6.36025473e-01  6.49189616e-01  7.58459442e-01  4.52486082e-01\n",
      "  1.66638242e-01  8.34438327e-02  2.06621538e-01  2.31194605e-01\n",
      "  3.84211034e-01  2.90396062e-01  1.23248632e-01 -2.08353902e-01\n",
      " -3.84173305e-01 -3.14500032e-01 -1.52871129e-01 -1.33816590e-01\n",
      " -3.22816286e-02 -1.06744567e-01 -3.35518037e-01 -3.74311353e-01\n",
      " -1.24624002e-01 -7.87949342e-02 -3.44384656e-02 -3.90347597e-02\n",
      " -2.16713505e-01 -4.21137028e-01 -3.70116677e-01 -3.47908693e-01\n",
      " -1.94951763e-01 -1.79437411e-01 -1.99027441e-01 -3.19393821e-01\n",
      " -5.69408417e-01 -5.29975486e-01 -3.62277690e-01 -3.29151649e-01\n",
      " -2.60668355e-01 -2.78131298e-01 -3.97858064e-01 -6.18837171e-01\n",
      " -3.72883379e-01 -3.86553263e-01 -3.11584583e-01 -2.97051964e-01\n",
      " -2.72761517e-01 -3.52222368e-01 -6.79823596e-01 -4.49146160e-01\n",
      " -4.00580141e-01  9.78277043e-02 -1.85179060e-01 -4.22625778e-02\n",
      " -2.45183753e-01 -5.45430339e-01 -1.78143309e-01 -2.83977070e-01\n",
      " -2.00395917e-01 -1.74068907e-02 -1.39811109e-01 -2.46195235e-01\n",
      " -6.56604130e-01 -8.08922723e-02 -2.88707236e-01 -7.90180553e-02\n",
      " -2.75527377e-03  5.77551603e-02 -1.73428017e-01 -5.09284726e-01\n",
      " -1.79496910e-01 -3.33674845e-02 -6.97064693e-02 -9.43241607e-02\n",
      " -1.02980418e-03 -4.01026383e-01 -5.61257060e-01 -1.95710375e-01\n",
      " -2.90849199e-01 -2.45674619e-01 -2.05602075e-01 -2.56384431e-01\n",
      " -3.96653210e-01 -7.03950421e-01 -5.03096835e-01 -4.44088749e-01\n",
      " -3.72675132e-01 -3.24361983e-01 -3.30311878e-01 -5.07068390e-01\n",
      " -7.51861952e-01 -4.57684260e-01 -5.98265408e-01 -5.22181123e-01\n",
      " -4.83447306e-01 -4.87136241e-01 -6.84330642e-01 -8.69387257e-01\n",
      " -6.61676416e-01 -6.94817332e-01 -6.60322815e-01 -6.15311858e-01\n",
      " -5.75551683e-01 -7.58049843e-01 -9.38346542e-01 -7.72493214e-01\n",
      " -7.86564716e-01 -7.59329071e-01 -7.45391441e-01 -7.75483036e-01\n",
      " -8.90598633e-01 -9.97116632e-01 -8.22026091e-01 -8.58082456e-01\n",
      " -8.31828544e-01 -7.88438933e-01 -8.70562361e-01 -1.00904617e+00\n",
      " -1.09149684e+00 -1.10665420e+00 -8.65504950e-01 -9.43165957e-01\n",
      " -9.09370553e-01 -9.42972586e-01 -9.81751028e-01 -1.11012002e+00\n",
      " -9.69062876e-01 -1.00318553e+00 -9.13327233e-01 -9.79966059e-01\n",
      " -8.26667010e-01 -1.06528756e+00 -1.11781026e+00 -1.01083114e+00\n",
      " -1.03338124e+00 -1.00785619e+00 -1.03634132e+00 -8.79264083e-01\n",
      " -1.06830713e+00 -1.12823745e+00 -1.02067822e+00 -1.03552321e+00\n",
      " -1.00126668e+00 -9.89828010e-01] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "india_cases_train, india_cases_test = india_cases_train.to_numpy().flatten(), india_cases_test.to_numpy()\n",
    "usa_cases_train, usa_cases_test = usa_cases_train.to_numpy().flatten(), usa_cases_test.to_numpy()\n",
    "\n",
    "# Visualize outputs\n",
    "print('India Cases:\\n',india_cases_train,'\\n')\n",
    "print('USA Cases:\\n',usa_cases_train,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80961213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate data preparation\n",
    "from numpy import array\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a9fb009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68799512 -0.68799512 -0.68798255] -0.687982551549953\n",
      "[-0.68799512 -0.68798255 -0.68798255] -0.6879951169346211\n",
      "[-0.68798255 -0.68798255 -0.68799512] -0.6879951169346211\n",
      "[-0.68798255 -0.68799512 -0.68799512] -0.6879951169346211\n",
      "[-0.68799512 -0.68799512 -0.68799512] -0.6879951169346211\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "india_cases_train_X, india_cases_train_y = split_sequence(india_cases_train, n_steps)\n",
    "india_cases_test_X, india_cases_test_y = split_sequence(india_cases_test, n_steps)\n",
    "\n",
    "\n",
    "# summarize the data\n",
    "for i in range(0,5):\n",
    "    print(india_cases_train_X[i], india_cases_train_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f0269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      " [[[-0.68799512]\n",
      "  [-0.68799512]\n",
      "  [-0.68798255]]\n",
      "\n",
      " [[-0.68799512]\n",
      "  [-0.68798255]\n",
      "  [-0.68798255]]\n",
      "\n",
      " [[-0.68798255]\n",
      "  [-0.68798255]\n",
      "  [-0.68799512]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.82649813]\n",
      "  [ 0.75023881]\n",
      "  [ 0.57653493]]\n",
      "\n",
      " [[ 0.75023881]\n",
      "  [ 0.57653493]\n",
      "  [ 0.39888553]]\n",
      "\n",
      " [[ 0.57653493]\n",
      "  [ 0.39888553]\n",
      "  [ 0.47550924]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data into [samples, timesteps, features]\n",
    "# univariate\n",
    "n_features = 1\n",
    "\n",
    "india_cases_train_X = india_cases_train_X.reshape((india_cases_train_X.shape[0], \n",
    "                                                   india_cases_train_X.shape[1], n_features))\n",
    "india_cases_test_X = india_cases_test_X.reshape((india_cases_test_X.shape[0], \n",
    "                                                 india_cases_test_X.shape[1], n_features))\n",
    "\n",
    "# Visualize outputs\n",
    "print('India Cases:\\n',india_cases_train_X,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a237a15",
   "metadata": {},
   "source": [
    "<a name=model></a>\n",
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0500ceb",
   "metadata": {},
   "source": [
    "### Univariate non-stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6209e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.losses import MeanAbsolutePercentageError, MeanAbsoluteError\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a3bf1a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_univariate_non_stacked(optimizer=\"adam\", lstm_nparams=100, n_steps=3, n_features=1):\n",
    "    model_uni = Sequential()\n",
    "    model_uni.add(LSTM(lstm_nparams, activation='relu', input_shape=(n_steps, n_features)))\n",
    "    model_uni.add(Dense(1))\n",
    "    model_uni.compile(optimizer=optimizer,loss='mae', metrics=[\"mae\"])\n",
    "    model_uni.summary()\n",
    "    return model_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3174c71e",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6dd043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KerasClassifier wrapper \n",
    "keras_estimator = KerasRegressor(build_fn=build_univariate_non_stacked, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for the gridserach\n",
    "param_grid = {\n",
    "#     'epochs': [10,100,300,],\n",
    "    'lstm_nparams':[15,50],\n",
    "#     'n_steps': [3, 6, 15],\n",
    "#     'optimizer': ['RMSprop','Adam','Adamax','sgd']\n",
    "}\n",
    "\n",
    "kfold_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GridSearch\n",
    "grid = GridSearchCV(estimator=keras_estimator,\n",
    "                    verbose=-1,\n",
    "                    return_train_score=True,\n",
    "                    cv=kfold_splits,\n",
    "                    param_grid=param_grid,\n",
    "#                     scoring=\"neg_mean_absolute_error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc73262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting GridSearch\n",
    "grid_result = grid.fit(india_cases_train_X, india_cases_train_y, )\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the gridsearch results to file\n",
    "file1 = open(\"univariate_non_stacked_india.txt\", \"w\")\n",
    "file1.write(\"mean,stdev,pram\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    file1.write(\"%f,%f,%r\" % (mean, stdev, param))\n",
    "    file1.write(\"\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc006cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(grid_result.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab879991",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.cv_results_['split2_train_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70513f80",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fca1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_univariate_stacked(optimizer=\"adam\",lstm_nparams_l1=100, lstm_nparams_l2=150, n_steps=3, n_features=1):\n",
    "    model_uni_stacked = Sequential()\n",
    "    model_uni_stacked.add(LSTM(lstm_nparams_l1, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    model_uni_stacked.add(LSTM(lstm_nparams_l2, activation='relu'))\n",
    "    model_uni_stacked.add(Dense(1))\n",
    "    model_uni_stacked.compile(optimizer=optimizer,loss='mae')\n",
    "    model_uni_stacked.summary()\n",
    "    return model_uni_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31103e54",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d090ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KerasClassifier wrapper \n",
    "keras_estimator = KerasRegressor(build_fn=build_univariate_stacked, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5796d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for the gridserach\n",
    "param_grid = {\n",
    "    'epochs': [10,100,300,],\n",
    "    'lstm_nparams_l1':[15,50,100,150],\n",
    "    'lstm_nparams_l2':[15,50,100,150],\n",
    "    'n_steps': [3, 6, 15],\n",
    "#     'optimizer': ['RMSprop','Adam','Adamax','sgd']\n",
    "}\n",
    "\n",
    "kfold_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac03a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GridSearch\n",
    "grid = GridSearchCV(estimator=keras_estimator,\n",
    "                    verbose=-1,\n",
    "                    return_train_score=True,\n",
    "                    cv=kfold_splits,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring=\"neg_mean_absolute_error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1044188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting GridSearch\n",
    "grid_result = grid.fit(india_cases_train_X, india_cases_train_y, )\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the gridsearch results to file\n",
    "file1 = open(\"univariate_stacked_india.txt\", \"w\")\n",
    "file1.write(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "file1.write(\"\\n\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    file1.write(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    file1.write(\"\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f9fbe",
   "metadata": {},
   "source": [
    "## Multivariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "826f821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 150)               91200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 91,351\n",
      "Trainable params: 91,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model_uni = Sequential()\n",
    "model_uni.add(LSTM(150, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model_uni.add(Dense(1))\n",
    "model_uni.compile(optimizer='adam',loss='mae')\n",
    "model_uni.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8629c",
   "metadata": {},
   "source": [
    "<a name=train></a>\n",
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c1eb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard callback\n",
    "logdir = os.path.join(parentDir+\"/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a390c1c",
   "metadata": {},
   "source": [
    "### Univariate non-stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e165ffb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 2s 29ms/step - loss: 0.6528 - mae: 0.6528 - val_loss: 0.1765 - val_mae: 0.1765\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5165 - mae: 0.5165 - val_loss: 0.1186 - val_mae: 0.1186\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3137 - mae: 0.3137 - val_loss: 0.0797 - val_mae: 0.0797\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1403 - mae: 0.1403 - val_loss: 0.0801 - val_mae: 0.0801\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1036 - mae: 0.1036 - val_loss: 0.0793 - val_mae: 0.0793\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0972 - mae: 0.0972 - val_loss: 0.0767 - val_mae: 0.0767\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.0745 - val_mae: 0.0745\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0910 - mae: 0.0910 - val_loss: 0.0739 - val_mae: 0.0739\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0906 - mae: 0.0906 - val_loss: 0.0734 - val_mae: 0.0734\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0873 - mae: 0.0873 - val_loss: 0.0716 - val_mae: 0.0716\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0892 - mae: 0.0892 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0891 - mae: 0.0891 - val_loss: 0.0725 - val_mae: 0.0725\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0861 - mae: 0.0861 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0858 - mae: 0.0858 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0859 - mae: 0.0859 - val_loss: 0.0745 - val_mae: 0.0745\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0821 - mae: 0.0821 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0829 - mae: 0.0829 - val_loss: 0.0729 - val_mae: 0.0729\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0796 - mae: 0.0796 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0779 - mae: 0.0779 - val_loss: 0.0737 - val_mae: 0.0737\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0802 - mae: 0.0802 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0799 - mae: 0.0799 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0774 - mae: 0.0774 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0806 - mae: 0.0806 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0798 - mae: 0.0798 - val_loss: 0.0729 - val_mae: 0.0729\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0769 - mae: 0.0769 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0771 - mae: 0.0771 - val_loss: 0.0714 - val_mae: 0.0714\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0771 - mae: 0.0771 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0744 - mae: 0.0744 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0777 - mae: 0.0777 - val_loss: 0.0715 - val_mae: 0.0715\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0743 - mae: 0.0743 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0722 - mae: 0.0722 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0725 - mae: 0.0725 - val_loss: 0.0704 - val_mae: 0.0704\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0714 - mae: 0.0714 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0725 - mae: 0.0725 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0742 - mae: 0.0742 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0711 - mae: 0.0711 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0710 - mae: 0.0710 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.0641 - val_mae: 0.0641\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0713 - mae: 0.0713 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0689 - mae: 0.0689 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0703 - val_mae: 0.0703\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0705 - mae: 0.0705 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0703 - val_mae: 0.0703\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0756 - mae: 0.0756 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0706 - mae: 0.0706 - val_loss: 0.0697 - val_mae: 0.0697\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0751 - mae: 0.0751 - val_loss: 0.0716 - val_mae: 0.0716\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0771 - mae: 0.0771 - val_loss: 0.0703 - val_mae: 0.0703\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0688 - mae: 0.0688 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0684 - mae: 0.0684 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0684 - mae: 0.0684 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0684 - mae: 0.0684 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0722 - mae: 0.0722 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0687 - mae: 0.0687 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0712 - mae: 0.0712 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0676 - mae: 0.0676 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0712 - mae: 0.0712 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0704 - mae: 0.0704 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.0713 - val_mae: 0.0713\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0685 - mae: 0.0685 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0706 - mae: 0.0706 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0698 - mae: 0.0698 - val_loss: 0.0696 - val_mae: 0.0696\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0720 - mae: 0.0720 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0706 - mae: 0.0706 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0742 - mae: 0.0742 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0714 - mae: 0.0714 - val_loss: 0.0711 - val_mae: 0.0711\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0746 - mae: 0.0746 - val_loss: 0.0709 - val_mae: 0.0709\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0685 - mae: 0.0685 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0670 - mae: 0.0670 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0687 - mae: 0.0687 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0661 - mae: 0.0661 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0680 - mae: 0.0680 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0702 - mae: 0.0702 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0703 - mae: 0.0703 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0677 - mae: 0.0677 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0719 - mae: 0.0719 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0714 - mae: 0.0714 - val_loss: 0.0676 - val_mae: 0.0676\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0661 - mae: 0.0661 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.0706 - val_mae: 0.0706\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0628 - val_mae: 0.0628\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0663 - mae: 0.0663 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0707 - mae: 0.0707 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0701 - mae: 0.0701 - val_loss: 0.0720 - val_mae: 0.0720\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0687 - mae: 0.0687 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0713 - val_mae: 0.0713\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0657 - mae: 0.0657 - val_loss: 0.0628 - val_mae: 0.0628\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0660 - mae: 0.0660 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0654 - mae: 0.0654 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0672 - mae: 0.0672 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0658 - mae: 0.0658 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0676 - mae: 0.0676 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0698 - val_mae: 0.0698\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0691 - mae: 0.0691 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0648 - mae: 0.0648 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0657 - mae: 0.0657 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0680 - mae: 0.0680 - val_loss: 0.0676 - val_mae: 0.0676\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0650 - mae: 0.0650 - val_loss: 0.0643 - val_mae: 0.0643\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0661 - mae: 0.0661 - val_loss: 0.0634 - val_mae: 0.0634\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0658 - mae: 0.0658 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0733 - mae: 0.0733 - val_loss: 0.0714 - val_mae: 0.0714\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0744 - mae: 0.0744 - val_loss: 0.0630 - val_mae: 0.0630\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0698 - val_mae: 0.0698\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0688 - mae: 0.0688 - val_loss: 0.0626 - val_mae: 0.0626\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0644 - mae: 0.0644 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0637 - mae: 0.0637 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0650 - mae: 0.0650 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0660 - mae: 0.0660 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0638 - mae: 0.0638 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0631 - mae: 0.0631 - val_loss: 0.0686 - val_mae: 0.0686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0632 - val_mae: 0.0632\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0614 - val_mae: 0.0614\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0632 - mae: 0.0632 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0646 - mae: 0.0646 - val_loss: 0.0630 - val_mae: 0.0630\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0632 - mae: 0.0632 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0622 - mae: 0.0622 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0636 - mae: 0.0636 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0630 - mae: 0.0630 - val_loss: 0.0631 - val_mae: 0.0631\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0643 - mae: 0.0643 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0625 - mae: 0.0625 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0627 - mae: 0.0627 - val_loss: 0.0620 - val_mae: 0.0620\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0621 - mae: 0.0621 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0642 - mae: 0.0642 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0653 - mae: 0.0653 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0607 - val_mae: 0.0607\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0646 - mae: 0.0646 - val_loss: 0.0701 - val_mae: 0.0701\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0612 - val_mae: 0.0612\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0614 - val_mae: 0.0614\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0636 - mae: 0.0636 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0632 - val_mae: 0.0632\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0635 - mae: 0.0635 - val_loss: 0.0621 - val_mae: 0.0621\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0620 - mae: 0.0620 - val_loss: 0.0629 - val_mae: 0.0629\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0621 - val_mae: 0.0621\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0637 - mae: 0.0637 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0629 - val_mae: 0.0629\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0631 - mae: 0.0631 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0602 - mae: 0.0602 - val_loss: 0.0627 - val_mae: 0.0627\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0626 - mae: 0.0626 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0611 - mae: 0.0611 - val_loss: 0.0623 - val_mae: 0.0623\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0614 - mae: 0.0614 - val_loss: 0.0615 - val_mae: 0.0615\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0635 - mae: 0.0635 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0607 - mae: 0.0607 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0611 - mae: 0.0611 - val_loss: 0.0621 - val_mae: 0.0621\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0597 - mae: 0.0597 - val_loss: 0.0634 - val_mae: 0.0634\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0603 - mae: 0.0603 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0642 - mae: 0.0642 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0608 - mae: 0.0608 - val_loss: 0.0591 - val_mae: 0.0591\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0605 - val_mae: 0.0605\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0626 - mae: 0.0626 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0587 - val_mae: 0.0587\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0603 - mae: 0.0603 - val_loss: 0.0610 - val_mae: 0.0610\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0604 - mae: 0.0604 - val_loss: 0.0620 - val_mae: 0.0620\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0600 - mae: 0.0600 - val_loss: 0.0604 - val_mae: 0.0604\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0599 - mae: 0.0599 - val_loss: 0.0606 - val_mae: 0.0606\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0598 - mae: 0.0598 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 242/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0615 - mae: 0.0615 - val_loss: 0.0619 - val_mae: 0.0619\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0616 - mae: 0.0616 - val_loss: 0.0590 - val_mae: 0.0590\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0592 - mae: 0.0592 - val_loss: 0.0631 - val_mae: 0.0631\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0601 - mae: 0.0601 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0607 - mae: 0.0607 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0608 - mae: 0.0608 - val_loss: 0.0587 - val_mae: 0.0587\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0598 - mae: 0.0598 - val_loss: 0.0578 - val_mae: 0.0578\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0601 - mae: 0.0601 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0597 - mae: 0.0597 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0740 - mae: 0.0740 - val_loss: 0.0561 - val_mae: 0.0561\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0611 - mae: 0.0611 - val_loss: 0.0615 - val_mae: 0.0615\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0615 - mae: 0.0615 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0600 - mae: 0.0600 - val_loss: 0.0590 - val_mae: 0.0590\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0590 - mae: 0.0590 - val_loss: 0.0612 - val_mae: 0.0612\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0586 - mae: 0.0586 - val_loss: 0.0596 - val_mae: 0.0596\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0576 - val_mae: 0.0576\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0623 - mae: 0.0623 - val_loss: 0.0595 - val_mae: 0.0595\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0624 - mae: 0.0624 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0622 - mae: 0.0622 - val_loss: 0.0585 - val_mae: 0.0585\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0589 - mae: 0.0589 - val_loss: 0.0593 - val_mae: 0.0593\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0596 - mae: 0.0596 - val_loss: 0.0614 - val_mae: 0.0614\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0586 - mae: 0.0586 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0587 - mae: 0.0587 - val_loss: 0.0609 - val_mae: 0.0609\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0613 - mae: 0.0613 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0648 - mae: 0.0648 - val_loss: 0.0585 - val_mae: 0.0585\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0609 - val_mae: 0.0609\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0592 - mae: 0.0592 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0567 - val_mae: 0.0567\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0576 - mae: 0.0576 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0609 - mae: 0.0609 - val_loss: 0.0592 - val_mae: 0.0592\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0593 - val_mae: 0.0593\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0587 - mae: 0.0587 - val_loss: 0.0613 - val_mae: 0.0613\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0587 - mae: 0.0587 - val_loss: 0.0570 - val_mae: 0.0570\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0589 - mae: 0.0589 - val_loss: 0.0553 - val_mae: 0.0553\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0610 - mae: 0.0610 - val_loss: 0.0624 - val_mae: 0.0624\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0599 - mae: 0.0599 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0572 - mae: 0.0572 - val_loss: 0.0598 - val_mae: 0.0598\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0586 - mae: 0.0586 - val_loss: 0.0602 - val_mae: 0.0602\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0566 - mae: 0.0566 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0571 - mae: 0.0571 - val_loss: 0.0544 - val_mae: 0.0544\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0617 - mae: 0.0617 - val_loss: 0.0555 - val_mae: 0.0555\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0567 - mae: 0.0567 - val_loss: 0.0581 - val_mae: 0.0581\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0591 - mae: 0.0591 - val_loss: 0.0618 - val_mae: 0.0618\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0582 - mae: 0.0582 - val_loss: 0.0540 - val_mae: 0.0540\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0590 - mae: 0.0590 - val_loss: 0.0547 - val_mae: 0.0547\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0569 - mae: 0.0569 - val_loss: 0.0611 - val_mae: 0.0611\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0563 - mae: 0.0563 - val_loss: 0.0564 - val_mae: 0.0564\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0571 - mae: 0.0571 - val_loss: 0.0574 - val_mae: 0.0574\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0579 - val_mae: 0.0579\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0604 - mae: 0.0604 - val_loss: 0.0570 - val_mae: 0.0570\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0607 - mae: 0.0607 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0574 - mae: 0.0574 - val_loss: 0.0545 - val_mae: 0.0545\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0578 - mae: 0.0578 - val_loss: 0.0561 - val_mae: 0.0561\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0560 - val_mae: 0.0560\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0572 - mae: 0.0572 - val_loss: 0.0603 - val_mae: 0.0603\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0580 - val_mae: 0.0580\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0582 - mae: 0.0582 - val_loss: 0.0558 - val_mae: 0.0558\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni = build_univariate_non_stacked()\n",
    "model_uni.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni.save('univar_1_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee706d9a",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a63fe62b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_uni_stacked' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bf62f649533f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_uni_stacked.fit(india_cases_train_X,\n\u001b[0m\u001b[1;32m      3\u001b[0m           \u001b[0mindia_cases_train_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindia_cases_test_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindia_cases_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_uni_stacked' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni_stacked.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni_stacked.save('univar_2_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cdc896",
   "metadata": {},
   "source": [
    "<a name=predict></a>\n",
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1df6917e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 3, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_cases_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0cd8ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_cases_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4df1259b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 3, 1)\n",
      "(122, 1)\n"
     ]
    }
   ],
   "source": [
    "x_input = np.array(india_cases_test_X)\n",
    "print(x_input.shape)\n",
    "yhat = model_uni.predict(x_input)\n",
    "print(yhat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73816cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "# Reversing Z-score normalization\n",
    "\n",
    "casted_mean = india_cases_mean.to_numpy()\n",
    "casted_std = india_cases_std.to_numpy()\n",
    "\n",
    "india_cases_test_scaled = (india_cases_test*india_cases_std[0])+india_cases_mean[0]\n",
    "yhat_scaled = (india_cases_std[0]*yhat)+india_cases_mean[0]\n",
    "\n",
    "print(x_input_scaled.size)\n",
    "print(yhat_scaled.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc16329",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4246121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fore_test(test, fore, title):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(12, 8)\n",
    "\n",
    "    ax.plot(test, color='blue', label='Test')\n",
    "    ax.plot(fore, color='red', label='Forecast')\n",
    "    ax.legend(loc='best')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4dae349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fore_test(india_cases_test_scaled, yhat_scaled, title='Daily cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18962bf2",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4586548b",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abe239cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.4716768 ]\n",
      "  [ 0.3716689 ]\n",
      "  [ 0.32771519]]\n",
      "\n",
      " [[ 0.3716689 ]\n",
      "  [ 0.32771519]\n",
      "  [ 0.19687184]]\n",
      "\n",
      " [[ 0.32771519]\n",
      "  [ 0.19687184]\n",
      "  [ 0.07184626]]\n",
      "\n",
      " [[ 0.19687184]\n",
      "  [ 0.07184626]\n",
      "  [ 0.09387338]]\n",
      "\n",
      " [[ 0.07184626]\n",
      "  [ 0.09387338]\n",
      "  [ 0.15649926]]\n",
      "\n",
      " [[ 0.09387338]\n",
      "  [ 0.15649926]\n",
      "  [ 0.09709012]]\n",
      "\n",
      " [[ 0.15649926]\n",
      "  [ 0.09709012]\n",
      "  [ 0.0753897 ]]\n",
      "\n",
      " [[ 0.09709012]\n",
      "  [ 0.0753897 ]\n",
      "  [ 0.04363697]]\n",
      "\n",
      " [[ 0.0753897 ]\n",
      "  [ 0.04363697]\n",
      "  [-0.01638787]]\n",
      "\n",
      " [[ 0.04363697]\n",
      "  [-0.01638787]\n",
      "  [-0.15220711]]\n",
      "\n",
      " [[-0.01638787]\n",
      "  [-0.15220711]\n",
      "  [-0.04907044]]\n",
      "\n",
      " [[-0.15220711]\n",
      "  [-0.04907044]\n",
      "  [-0.00859733]]\n",
      "\n",
      " [[-0.04907044]\n",
      "  [-0.00859733]\n",
      "  [-0.03877939]]\n",
      "\n",
      " [[-0.00859733]\n",
      "  [-0.03877939]\n",
      "  [-0.07608601]]\n",
      "\n",
      " [[-0.03877939]\n",
      "  [-0.07608601]\n",
      "  [-0.05922327]]\n",
      "\n",
      " [[-0.07608601]\n",
      "  [-0.05922327]\n",
      "  [-0.10812775]]\n",
      "\n",
      " [[-0.05922327]\n",
      "  [-0.10812775]\n",
      "  [-0.21596388]]\n",
      "\n",
      " [[-0.10812775]\n",
      "  [-0.21596388]\n",
      "  [-0.11060313]]\n",
      "\n",
      " [[-0.21596388]\n",
      "  [-0.11060313]\n",
      "  [-0.07498026]]\n",
      "\n",
      " [[-0.11060313]\n",
      "  [-0.07498026]\n",
      "  [-0.10223458]]\n",
      "\n",
      " [[-0.07498026]\n",
      "  [-0.10223458]\n",
      "  [-0.13372343]]\n",
      "\n",
      " [[-0.10223458]\n",
      "  [-0.13372343]\n",
      "  [-0.14679143]]\n",
      "\n",
      " [[-0.13372343]\n",
      "  [-0.14679143]\n",
      "  [-0.18794307]]\n",
      "\n",
      " [[-0.14679143]\n",
      "  [-0.18794307]\n",
      "  [-0.25193857]]\n",
      "\n",
      " [[-0.18794307]\n",
      "  [-0.25193857]\n",
      "  [-0.13847315]]\n",
      "\n",
      " [[-0.25193857]\n",
      "  [-0.13847315]\n",
      "  [-0.11134448]]\n",
      "\n",
      " [[-0.13847315]\n",
      "  [-0.11134448]\n",
      "  [-0.14274538]]\n",
      "\n",
      " [[-0.11134448]\n",
      "  [-0.14274538]\n",
      "  [-0.15062388]]\n",
      "\n",
      " [[-0.14274538]\n",
      "  [-0.15062388]\n",
      "  [-0.16645626]]\n",
      "\n",
      " [[-0.15062388]\n",
      "  [-0.16645626]\n",
      "  [-0.22114081]]\n",
      "\n",
      " [[-0.16645626]\n",
      "  [-0.22114081]\n",
      "  [-0.27451857]]\n",
      "\n",
      " [[-0.22114081]\n",
      "  [-0.27451857]\n",
      "  [-0.19964144]]\n",
      "\n",
      " [[-0.27451857]\n",
      "  [-0.19964144]\n",
      "  [-0.16360392]]\n",
      "\n",
      " [[-0.19964144]\n",
      "  [-0.16360392]\n",
      "  [-0.19858595]]\n",
      "\n",
      " [[-0.16360392]\n",
      "  [-0.19858595]\n",
      "  [-0.20951783]]\n",
      "\n",
      " [[-0.19858595]\n",
      "  [-0.20951783]\n",
      "  [-0.17084158]]\n",
      "\n",
      " [[-0.20951783]\n",
      "  [-0.17084158]\n",
      "  [-0.20844978]]\n",
      "\n",
      " [[-0.17084158]\n",
      "  [-0.20844978]\n",
      "  [-0.309865  ]]\n",
      "\n",
      " [[-0.20844978]\n",
      "  [-0.309865  ]\n",
      "  [-0.16006048]]\n",
      "\n",
      " [[-0.309865  ]\n",
      "  [-0.16006048]\n",
      "  [-0.1680018 ]]\n",
      "\n",
      " [[-0.16006048]\n",
      "  [-0.1680018 ]\n",
      "  [-0.24390929]]\n",
      "\n",
      " [[-0.1680018 ]\n",
      "  [-0.24390929]\n",
      "  [-0.68799512]]\n",
      "\n",
      " [[-0.24390929]\n",
      "  [-0.68799512]\n",
      "  [ 0.30264724]]\n",
      "\n",
      " [[-0.68799512]\n",
      "  [ 0.30264724]\n",
      "  [-0.19340901]]\n",
      "\n",
      " [[ 0.30264724]\n",
      "  [-0.19340901]\n",
      "  [-0.31494141]]\n",
      "\n",
      " [[-0.19340901]\n",
      "  [-0.31494141]\n",
      "  [-0.13946581]]\n",
      "\n",
      " [[-0.31494141]\n",
      "  [-0.13946581]\n",
      "  [-0.1412878 ]]\n",
      "\n",
      " [[-0.13946581]\n",
      "  [-0.1412878 ]\n",
      "  [-0.13222815]]\n",
      "\n",
      " [[-0.1412878 ]\n",
      "  [-0.13222815]\n",
      "  [-0.16465941]]\n",
      "\n",
      " [[-0.13222815]\n",
      "  [-0.16465941]\n",
      "  [-0.16237251]]\n",
      "\n",
      " [[-0.16465941]\n",
      "  [-0.16237251]\n",
      "  [-0.18369597]]\n",
      "\n",
      " [[-0.16237251]\n",
      "  [-0.18369597]\n",
      "  [-0.30413518]]\n",
      "\n",
      " [[-0.18369597]\n",
      "  [-0.30413518]\n",
      "  [-0.1523956 ]]\n",
      "\n",
      " [[-0.30413518]\n",
      "  [-0.1523956 ]\n",
      "  [-0.14790975]]\n",
      "\n",
      " [[-0.1523956 ]\n",
      "  [-0.14790975]\n",
      "  [-0.12703865]]\n",
      "\n",
      " [[-0.14790975]\n",
      "  [-0.12703865]\n",
      "  [-0.20261944]]\n",
      "\n",
      " [[-0.12703865]\n",
      "  [-0.20261944]\n",
      "  [-0.19706554]]\n",
      "\n",
      " [[-0.20261944]\n",
      "  [-0.19706554]\n",
      "  [-0.24193653]]\n",
      "\n",
      " [[-0.19706554]\n",
      "  [-0.24193653]\n",
      "  [-0.33360101]]\n",
      "\n",
      " [[-0.24193653]\n",
      "  [-0.33360101]\n",
      "  [-0.20607492]]\n",
      "\n",
      " [[-0.33360101]\n",
      "  [-0.20607492]\n",
      "  [-0.1703641 ]]\n",
      "\n",
      " [[-0.20607492]\n",
      "  [-0.1703641 ]\n",
      "  [-0.18387188]]\n",
      "\n",
      " [[-0.1703641 ]\n",
      "  [-0.18387188]\n",
      "  [-0.20212939]]\n",
      "\n",
      " [[-0.18387188]\n",
      "  [-0.20212939]\n",
      "  [-0.23459834]]\n",
      "\n",
      " [[-0.20212939]\n",
      "  [-0.23459834]\n",
      "  [-0.27412904]]\n",
      "\n",
      " [[-0.23459834]\n",
      "  [-0.27412904]\n",
      "  [-0.37177465]]\n",
      "\n",
      " [[-0.27412904]\n",
      "  [-0.37177465]\n",
      "  [-0.24597002]]\n",
      "\n",
      " [[-0.37177465]\n",
      "  [-0.24597002]\n",
      "  [-0.23060255]]\n",
      "\n",
      " [[-0.24597002]\n",
      "  [-0.23060255]\n",
      "  [-0.22846643]]\n",
      "\n",
      " [[-0.23060255]\n",
      "  [-0.22846643]\n",
      "  [-0.25502966]]\n",
      "\n",
      " [[-0.22846643]\n",
      "  [-0.25502966]\n",
      "  [-0.29912159]]\n",
      "\n",
      " [[-0.25502966]\n",
      "  [-0.29912159]\n",
      "  [-0.37295579]]\n",
      "\n",
      " [[-0.29912159]\n",
      "  [-0.37295579]\n",
      "  [-0.36799247]]\n",
      "\n",
      " [[-0.37295579]\n",
      "  [-0.36799247]\n",
      "  [-0.21562461]]\n",
      "\n",
      " [[-0.36799247]\n",
      "  [-0.21562461]\n",
      "  [-0.1079267 ]]\n",
      "\n",
      " [[-0.21562461]\n",
      "  [-0.1079267 ]\n",
      "  [-0.12685017]]\n",
      "\n",
      " [[-0.1079267 ]\n",
      "  [-0.12685017]\n",
      "  [-0.1004503 ]]\n",
      "\n",
      " [[-0.12685017]\n",
      "  [-0.1004503 ]\n",
      "  [-0.12150988]]\n",
      "\n",
      " [[-0.1004503 ]\n",
      "  [-0.12150988]\n",
      "  [-0.14882703]]\n",
      "\n",
      " [[-0.12150988]\n",
      "  [-0.14882703]\n",
      "  [-0.29920955]]\n",
      "\n",
      " [[-0.14882703]\n",
      "  [-0.29920955]\n",
      "  [-0.16068875]]\n",
      "\n",
      " [[-0.29920955]\n",
      "  [-0.16068875]\n",
      "  [-0.09626602]]\n",
      "\n",
      " [[-0.16068875]\n",
      "  [-0.09626602]\n",
      "  [-0.11812979]]\n",
      "\n",
      " [[-0.09626602]\n",
      "  [-0.11812979]\n",
      "  [-0.15248355]]\n",
      "\n",
      " [[-0.11812979]\n",
      "  [-0.15248355]\n",
      "  [-0.15062388]]\n",
      "\n",
      " [[-0.15248355]\n",
      "  [-0.15062388]\n",
      "  [-0.19859851]]\n",
      "\n",
      " [[-0.15062388]\n",
      "  [-0.19859851]\n",
      "  [-0.29567868]]\n",
      "\n",
      " [[-0.19859851]\n",
      "  [-0.29567868]\n",
      "  [-0.21208117]]\n",
      "\n",
      " [[-0.29567868]\n",
      "  [-0.21208117]\n",
      "  [-0.14437888]]\n",
      "\n",
      " [[-0.21208117]\n",
      "  [-0.14437888]\n",
      "  [-0.24854592]]\n",
      "\n",
      " [[-0.14437888]\n",
      "  [-0.24854592]\n",
      "  [-0.26861284]]\n",
      "\n",
      " [[-0.24854592]\n",
      "  [-0.26861284]\n",
      "  [-0.3287382 ]]\n",
      "\n",
      " [[-0.26861284]\n",
      "  [-0.3287382 ]\n",
      "  [-0.34553812]]\n",
      "\n",
      " [[-0.3287382 ]\n",
      "  [-0.34553812]\n",
      "  [-0.36878408]]\n",
      "\n",
      " [[-0.34553812]\n",
      "  [-0.36878408]\n",
      "  [-0.34651822]]\n",
      "\n",
      " [[-0.36878408]\n",
      "  [-0.34651822]\n",
      "  [-0.30387131]]\n",
      "\n",
      " [[-0.34651822]\n",
      "  [-0.30387131]\n",
      "  [-0.25570819]]\n",
      "\n",
      " [[-0.30387131]\n",
      "  [-0.25570819]\n",
      "  [-0.23988837]]\n",
      "\n",
      " [[-0.25570819]\n",
      "  [-0.23988837]\n",
      "  [-0.30132053]]\n",
      "\n",
      " [[-0.23988837]\n",
      "  [-0.30132053]\n",
      "  [-0.30781684]]\n",
      "\n",
      " [[-0.30132053]\n",
      "  [-0.30781684]\n",
      "  [-0.3598501 ]]\n",
      "\n",
      " [[-0.30781684]\n",
      "  [-0.3598501 ]\n",
      "  [-0.34918208]]\n",
      "\n",
      " [[-0.3598501 ]\n",
      "  [-0.34918208]\n",
      "  [-0.28687034]]\n",
      "\n",
      " [[-0.34918208]\n",
      "  [-0.28687034]\n",
      "  [-0.29366822]]\n",
      "\n",
      " [[-0.28687034]\n",
      "  [-0.29366822]\n",
      "  [-0.31585868]]\n",
      "\n",
      " [[-0.29366822]\n",
      "  [-0.31585868]\n",
      "  [-0.33206803]]\n",
      "\n",
      " [[-0.31585868]\n",
      "  [-0.33206803]\n",
      "  [-0.36077993]]\n",
      "\n",
      " [[-0.33206803]\n",
      "  [-0.36077993]\n",
      "  [-0.45182871]]\n",
      "\n",
      " [[-0.36077993]\n",
      "  [-0.45182871]\n",
      "  [-0.45088631]]\n",
      "\n",
      " [[-0.45182871]\n",
      "  [-0.45088631]\n",
      "  [-0.39234418]]\n",
      "\n",
      " [[-0.45088631]\n",
      "  [-0.39234418]\n",
      "  [-0.35216008]]\n",
      "\n",
      " [[-0.39234418]\n",
      "  [-0.35216008]\n",
      "  [-0.38197774]]\n",
      "\n",
      " [[-0.35216008]\n",
      "  [-0.38197774]\n",
      "  [-0.4009766 ]]\n",
      "\n",
      " [[-0.38197774]\n",
      "  [-0.4009766 ]\n",
      "  [-0.42664768]]\n",
      "\n",
      " [[-0.4009766 ]\n",
      "  [-0.42664768]\n",
      "  [-0.45747057]]\n",
      "\n",
      " [[-0.42664768]\n",
      "  [-0.45747057]\n",
      "  [-0.45135123]]\n",
      "\n",
      " [[-0.45747057]\n",
      "  [-0.45135123]\n",
      "  [-0.40614097]]\n",
      "\n",
      " [[-0.45135123]\n",
      "  [-0.40614097]\n",
      "  [-0.42089274]]\n",
      "\n",
      " [[-0.40614097]\n",
      "  [-0.42089274]\n",
      "  [-0.43995442]]\n",
      "\n",
      " [[-0.42089274]\n",
      "  [-0.43995442]\n",
      "  [-0.45973234]]\n",
      "\n",
      " [[-0.43995442]\n",
      "  [-0.45973234]\n",
      "  [-0.46015956]]\n",
      "\n",
      " [[-0.45973234]\n",
      "  [-0.46015956]\n",
      "  [-0.50814677]]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_uni_stacked' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-48d5b64d446d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindia_cases_test_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0myhat_stacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_uni_stacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_uni_stacked' is not defined"
     ]
    }
   ],
   "source": [
    "x_input = np.array(india_cases_test_X)\n",
    "print(x_input)\n",
    "yhat_stacked = model_uni_stacked.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82a69f",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c938009",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca77a056",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.146946"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape = MeanAbsolutePercentageError()\n",
    "mape(india_cases_test_y, yhat).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f109939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05580243"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = MeanAbsoluteError()\n",
    "mae(india_cases_test_y, yhat).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd2334e",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf4366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mape(india_cases_test_y, yhat_stacked).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
