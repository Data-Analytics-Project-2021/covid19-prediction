{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da7f88f7",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b493ee8",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. [Imports](#imports)\n",
    "2. [Data](#data)\n",
    "3. [Model](#model)\n",
    "5. [Train](#train)\n",
    "6. [Predict](#predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184bbb54",
   "metadata": {},
   "source": [
    "<a name=imports></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f68681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68972792",
   "metadata": {},
   "source": [
    "<a name=data></a>\n",
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8f3b4",
   "metadata": {},
   "source": [
    "### Ingestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6ed14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Directory /covid19-prediction/models\n",
      "Path: /covid19-prediction/models/../cleaned_datasets/india/daily_cases_india.csv\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "# Get the path of the current working directory\n",
    "curPath = os.getcwd()\n",
    "# Appened the parent directory to the current path to step out of the current folder\n",
    "parentDir = os.path.abspath(os.path.join(curPath, os.pardir))\n",
    "print(\"Parent Directory\", parentDir)\n",
    "# Save the path to all of the datasets\n",
    "india_cases_path = os.path.join(parentDir, \"../cleaned_datasets/india/daily_cases_india.csv\")\n",
    "india_vacc_path = os.path.join(parentDir, \"../cleaned_datasets/india/daily_vacc_india.csv\")\n",
    "usa_cases_path = os.path.join(parentDir, \"../cleaned_datasets/usa/daily_cases_usa.csv\")\n",
    "usa_vacc_path = os.path.join(parentDir, \"../cleaned_datasets/usa/vacc_usa.csv\")\n",
    "\n",
    "# Quick check to make sure the path exists\n",
    "print(\"Path:\", india_cases_path)\n",
    "print(\"Exists:\", os.path.exists(india_cases_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c18b18a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "    Unnamed: 0        Date  Confirmed  Deaths  Recovered  Active\n",
      "0           0  2020-01-30        1.0     0.0        0.0     0.0\n",
      "1           1  2020-01-31        0.0     0.0        0.0     0.0\n",
      "2           2  2020-02-01        0.0     0.0        0.0     0.0\n",
      "3           3  2020-02-02        1.0     0.0        0.0     0.0\n",
      "4           4  2020-02-03        1.0     0.0        0.0     0.0 \n",
      "\n",
      "India Vacc:\n",
      "    Updated On  Total_Doses  First_Dose  Second_Dose\n",
      "0  2021-01-16          NaN         NaN          NaN\n",
      "1  2021-01-17      20656.0     20656.0          0.0\n",
      "2  2021-01-18      81690.0     81690.0          0.0\n",
      "3  2021-01-19     192152.0    192152.0          0.0\n",
      "4  2021-01-20     111510.0    111510.0          0.0 \n",
      "\n",
      "USA Cases:\n",
      "          Date  Confirmed  Deaths  Recovered\n",
      "0  2020-04-12        NaN     NaN        NaN\n",
      "1  2020-04-13    25322.0  1546.0    11785.0\n",
      "2  2020-04-14    26713.0  2305.0     6484.0\n",
      "3  2020-04-15    29380.0  2478.0     6093.0\n",
      "4  2020-04-16    31542.0  4616.0     5234.0 \n",
      "\n",
      "USA Vacc:\n",
      "          date  total_doses  people_vacc  people_fully_vacc  daily_vacc\n",
      "0  2020-12-20     556208.0          0.0                0.0         0.0\n",
      "1  2020-12-21     614117.0          0.0                0.0     57909.0\n",
      "2  2020-12-22          0.0          0.0                0.0    127432.0\n",
      "3  2020-12-23    1008025.0          0.0                0.0    150606.0\n",
      "4  2020-12-24          0.0          0.0                0.0    191001.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data as a pandas dataframe\n",
    "india_cases_df = pd.read_csv(india_cases_path)\n",
    "india_vacc_df =  pd.read_csv(india_vacc_path)\n",
    "\n",
    "usa_cases_df = pd.read_csv(usa_cases_path)\n",
    "usa_vacc_df = pd.read_csv(usa_vacc_path)\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('India Vacc:\\n',india_vacc_df.head(),'\\n')\n",
    "\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')\n",
    "print('USA Vacc:\\n',usa_vacc_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f3fa3",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897297ae",
   "metadata": {},
   "source": [
    "### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03503052",
   "metadata": {},
   "outputs": [],
   "source": [
    "india_cases_multi_df = india_cases_df[[\"Date\",\"Confirmed\",\"Deaths\",\"Recovered\",\"Active\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd4455",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d328699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "    Confirmed\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "5        0.0 \n",
      "\n",
      "USA Cases:\n",
      "    Confirmed\n",
      "1    25322.0\n",
      "2    26713.0\n",
      "3    29380.0\n",
      "4    31542.0\n",
      "5    32022.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select only the Confirmed column for univariate analysis\n",
    "# Selecting from the first index because the 0th index is NaN\n",
    "india_cases_df = india_cases_df[[\"Confirmed\"]][1:]\n",
    "usa_cases_df = usa_cases_df[[\"Confirmed\"]][1:]\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dcbb1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "    Confirmed\n",
      "1  -0.687995\n",
      "2  -0.687995\n",
      "3  -0.687983\n",
      "4  -0.687983\n",
      "5  -0.687995 \n",
      "\n",
      "USA Cases:\n",
      "    Confirmed\n",
      "1  -0.817861\n",
      "2  -0.797170\n",
      "3  -0.757499\n",
      "4  -0.725340\n",
      "5  -0.718200 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "india_cases_mean = india_cases_df.mean()\n",
    "india_cases_std = india_cases_df.std()\n",
    "\n",
    "usa_cases_mean = usa_cases_df.mean()\n",
    "usa_cases_std = usa_cases_df.std()\n",
    "\n",
    "\n",
    "india_cases_df = (india_cases_df-india_cases_mean)/india_cases_std\n",
    "usa_cases_df = (usa_cases_df-usa_cases_mean)/usa_cases_std\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285d674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "      Confirmed\n",
      "1    -0.687995\n",
      "2    -0.687995\n",
      "3    -0.687983\n",
      "4    -0.687983\n",
      "5    -0.687995\n",
      "..         ...\n",
      "492   0.750239\n",
      "493   0.576535\n",
      "494   0.398886\n",
      "495   0.475509\n",
      "496   0.486403\n",
      "\n",
      "[496 rows x 1 columns] \n",
      "\n",
      "USA Cases:\n",
      "      Confirmed\n",
      "1    -0.817861\n",
      "2    -0.797170\n",
      "3    -0.757499\n",
      "4    -0.725340\n",
      "5    -0.718200\n",
      "..         ...\n",
      "434  -1.128237\n",
      "435  -1.020678\n",
      "436  -1.035523\n",
      "437  -1.001267\n",
      "438  -0.989828\n",
      "\n",
      "[438 rows x 1 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create train test splits\n",
    "india_cases_train, india_cases_test = train_test_split(india_cases_df, test_size=0.2, shuffle=False)\n",
    "india_vacc_train, india_vacc_test = train_test_split(india_vacc_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "usa_cases_train, usa_cases_test = train_test_split(usa_cases_df, test_size=0.2, shuffle=False)\n",
    "usa_vacc_train, usa_vacc_test = train_test_split(usa_vacc_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Visualize splits\n",
    "print('India Cases:\\n',india_cases_train,'\\n')\n",
    "print('USA Cases:\\n',usa_cases_train,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17fa1445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      " [-6.87995117e-01 -6.87995117e-01 -6.87982552e-01 -6.87982552e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87969986e-01\n",
      " -6.87995117e-01 -6.87706113e-01 -6.87969986e-01 -6.87982552e-01\n",
      " -6.87957421e-01 -6.87932290e-01 -6.87944855e-01 -6.87831767e-01\n",
      " -6.87919725e-01 -6.87856898e-01 -6.87882028e-01 -6.87743809e-01\n",
      " -6.87856898e-01 -6.87919725e-01 -6.87706113e-01 -6.87819202e-01\n",
      " -6.87517632e-01 -6.87366848e-01 -6.86914494e-01 -6.87165802e-01\n",
      " -6.86700882e-01 -6.87530198e-01 -6.86474705e-01 -6.87115540e-01\n",
      " -6.85984655e-01 -6.86738578e-01 -6.87530198e-01 -6.85142775e-01\n",
      " -6.86160571e-01 -6.80443321e-01 -6.81146982e-01 -6.87693548e-01\n",
      " -6.81523944e-01 -6.81637032e-01 -6.73042309e-01 -6.81297767e-01\n",
      " -6.80393059e-01 -6.77829721e-01 -6.77025536e-01 -6.77339671e-01\n",
      " -6.78457990e-01 -6.72313517e-01 -6.75002509e-01 -6.77503021e-01\n",
      " -6.74072671e-01 -6.76409832e-01 -6.70780540e-01 -6.64208844e-01\n",
      " -6.76384702e-01 -6.68631859e-01 -6.71785771e-01 -6.66546005e-01\n",
      " -6.69737613e-01 -6.65967998e-01 -6.67802544e-01 -6.68380551e-01\n",
      " -6.64460151e-01 -6.66156478e-01 -6.65364859e-01 -6.57913586e-01\n",
      " -6.57310448e-01 -6.52736648e-01 -6.38588024e-01 -6.50763882e-01\n",
      " -6.42923082e-01 -6.45725163e-01 -6.45976471e-01 -6.48879074e-01\n",
      " -6.33297997e-01 -6.42671774e-01 -6.43714701e-01 -6.40711574e-01\n",
      " -6.38462371e-01 -6.40410005e-01 -6.26877086e-01 -6.24539924e-01\n",
      " -6.29817386e-01 -6.10755697e-01 -6.18219536e-01 -6.10114863e-01\n",
      " -6.05465670e-01 -6.04699182e-01 -5.98617536e-01 -6.07400740e-01\n",
      " -6.14575574e-01 -5.96355767e-01 -5.96267809e-01 -5.86152674e-01\n",
      " -5.83250070e-01 -5.77645909e-01 -5.90475167e-01 -5.77155859e-01\n",
      " -5.66952766e-01 -5.63736028e-01 -5.68988359e-01 -5.56837632e-01\n",
      " -5.51484778e-01 -5.81918140e-01 -5.59602016e-01 -6.82504044e-01\n",
      " -4.24725177e-01 -6.87995117e-01 -5.44020939e-01 -5.38102643e-01\n",
      " -4.09433104e-01 -5.50102586e-01 -5.26140397e-01 -5.17281801e-01\n",
      " -5.05595993e-01 -4.94324843e-01 -5.01763551e-01 -5.00356228e-01\n",
      " -4.87351055e-01 -4.75363678e-01 -4.70664224e-01 -4.54882101e-01\n",
      " -4.37868570e-01 -4.43485297e-01 -4.55259062e-01 -4.53612997e-01\n",
      " -4.47393131e-01 -4.25340881e-01 -4.01868743e-01 -3.75745308e-01\n",
      " -3.83309670e-01 -4.08402743e-01 -4.02094920e-01 -3.75380912e-01\n",
      " -3.54937031e-01 -3.47297277e-01 -3.28549723e-01 -3.26966485e-01\n",
      " -3.29906785e-01 -3.18208412e-01 -2.77408608e-01 -2.48520788e-01\n",
      " -2.45040177e-01 -2.01752426e-01 -1.80039442e-01 -2.21417253e-01\n",
      " -2.13777500e-01 -1.13505730e-01 -6.83959989e-02 -7.33467605e-02\n",
      " -7.71792028e-02 -5.99646258e-02 -1.29375811e-01 -6.49256036e-01\n",
      "  5.53552846e-01 -2.47564180e-02  8.15341709e-02 -2.28787125e-04\n",
      " -2.23815603e-02 -3.39668450e-02 -2.81993334e-02  1.92098630e-02\n",
      "  9.78189094e-02  8.52409594e-02  1.21203090e-01  9.18629171e-02\n",
      " -1.44779333e-02  7.80284286e-02  1.53873090e-01  1.23138160e-01\n",
      "  1.25387363e-01  1.16566463e-01  3.71657976e-02  3.32721674e-03\n",
      "  1.23376902e-01  1.87460364e-01  1.77759887e-01  1.90023702e-01\n",
      "  1.82019552e-01  8.36200248e-02  7.81792132e-02  3.10464553e-02\n",
      "  3.88694999e-01  2.82881895e-01  2.72904979e-01  3.01667145e-01\n",
      "  2.98538364e-01  1.90589144e-01  2.96590730e-01  3.66027045e-01\n",
      "  3.59216607e-01  3.98056211e-01  4.50830826e-01  4.52966942e-01\n",
      "  2.64574129e-01  4.39195280e-01  5.14951984e-01  5.25205338e-01\n",
      "  5.38009465e-01  4.97825365e-01  4.68912415e-01 -6.87995117e-01\n",
      "  1.49752737e+00  5.42080650e-01  5.23609534e-01  4.84820192e-01\n",
      "  4.75622330e-01  4.04703299e-01  2.55451660e-01  3.59291999e-01\n",
      "  3.99011180e-01  3.93281365e-01  3.84611249e-01  4.25297965e-01\n",
      "  3.44502541e-01  1.98982821e-01  3.23166518e-01  4.02944145e-01\n",
      "  2.41114556e-01  4.05419526e-01  2.64825437e-01  2.47397249e-01\n",
      "  8.18483055e-02  2.17328283e-01  2.98689149e-01  1.97814241e-01\n",
      "  2.32695748e-01  2.46655891e-01  1.50518133e-01  7.39840137e-03\n",
      "  1.10019898e-01  1.62781948e-01  1.08285875e-01  9.37225940e-02\n",
      "  8.94377979e-02  1.21732475e-02 -1.00060768e-01 -8.91146793e-03\n",
      "  1.36433975e-02 -4.86541407e-03 -1.73805372e-02 -5.81049489e-02\n",
      " -1.20693130e-01 -2.29735538e-01 -1.36462688e-01 -6.12211643e-02\n",
      " -7.67142836e-02 -8.14891298e-02 -9.78869568e-02 -1.19650203e-01\n",
      " -2.06615230e-01 -1.06808380e-01 -5.70871527e-02 -8.94053221e-02\n",
      " -5.52526066e-02 -1.14083738e-01 -1.11206265e-01 -2.09593226e-01\n",
      " -1.31587318e-01 -8.60503644e-02 -1.24073218e-01 -1.26523468e-01\n",
      " -1.71557807e-01 -3.04147746e-01 -3.30962277e-01 -1.93346184e-01\n",
      " -1.15315145e-01 -1.11470138e-01 -1.07072253e-01 -1.19926641e-01\n",
      " -1.34376834e-01 -2.10824634e-01 -1.30393607e-01 -1.28973718e-01\n",
      " -1.46653215e-01 -1.68768292e-01 -1.62636384e-01 -2.00810023e-01\n",
      " -2.96985477e-01 -2.28051777e-01 -2.41283127e-01 -2.28164865e-01\n",
      " -2.27448638e-01 -2.35503050e-01 -2.73576165e-01 -3.54170542e-01\n",
      " -2.84897577e-01 -2.91921627e-01 -3.18912073e-01 -3.10644050e-01\n",
      " -3.07841969e-01 -3.47837589e-01 -4.10739904e-01 -3.56495139e-01\n",
      " -3.86300231e-01 -4.00373462e-01 -3.71950562e-01 -3.53454316e-01\n",
      " -3.82191350e-01 -4.42266454e-01 -3.87054154e-01 -3.77479331e-01\n",
      " -3.98149389e-01 -4.08126304e-01 -4.52620331e-01 -4.36423550e-01\n",
      " -4.81520716e-01 -4.29789027e-01 -4.13793293e-01 -4.36247635e-01\n",
      " -1.96512661e-01 -7.11341602e-01 -4.80616008e-01 -4.82236943e-01\n",
      " -4.60712439e-01 -4.32339800e-01 -4.60071604e-01 -6.87995117e-01\n",
      " -2.24747080e-01 -4.83041128e-01 -5.29872316e-01 -4.87351055e-01\n",
      " -4.75062108e-01 -4.92100770e-01 -4.97529016e-01 -4.97704932e-01\n",
      " -5.14743593e-01 -5.61713001e-01 -5.14391762e-01 -4.96448393e-01\n",
      " -5.05231597e-01 -5.08862993e-01 -5.01411720e-01 -5.22094343e-01\n",
      " -5.73624986e-01 -5.28552951e-01 -5.41407339e-01 -4.51074789e-01\n",
      " -5.23614755e-01 -5.24092239e-01 -5.44297378e-01 -5.79493020e-01\n",
      " -5.49285836e-01 -5.25914220e-01 -5.32083824e-01 -5.40816766e-01\n",
      " -5.36469143e-01 -5.39334051e-01 -5.73524463e-01 -5.48934005e-01\n",
      " -5.25612651e-01 -5.71023951e-01 -5.35413651e-01 -5.34772816e-01\n",
      " -5.41620951e-01 -5.73386243e-01 -5.42111001e-01 -5.26140397e-01\n",
      " -5.22219997e-01 -5.12167689e-01 -5.08762470e-01 -5.09579220e-01\n",
      " -5.55003086e-01 -5.15321601e-01 -4.77675708e-01 -4.79698735e-01\n",
      " -4.80817055e-01 -4.77499793e-01 -4.93106001e-01 -5.33616801e-01\n",
      " -4.99652566e-01 -4.69269466e-01 -4.76419170e-01 -4.58249624e-01\n",
      " -4.52343893e-01 -4.54291527e-01 -4.94638978e-01 -4.62810858e-01\n",
      " -4.00825816e-01 -3.95410135e-01 -3.75343216e-01 -3.69839577e-01\n",
      " -3.57638589e-01 -3.80243716e-01 -3.24817804e-01 -2.37262204e-01\n",
      " -1.88822646e-01 -1.73404919e-01 -1.37053261e-01 -9.80377414e-02\n",
      " -1.76395480e-01 -9.41299067e-02 -1.60486064e-02  5.48452939e-02\n",
      "  9.43006017e-02  1.00030417e-01  1.66702348e-01  1.83177206e-02\n",
      " -1.59983449e-02  2.20859156e-01  3.35656510e-01  4.31945053e-01\n",
      "  4.83714438e-01  6.13250989e-01  5.30621019e-01  7.66272243e-01\n",
      "  9.05157440e-01  9.70233567e-01  1.13881077e+00  1.23298833e+00\n",
      "  1.43444914e+00  1.34427994e+00  1.62870999e+00  1.83436764e+00\n",
      "  2.04312894e+00  2.26100014e+00  2.59652104e+00  2.75243234e+00\n",
      "  2.56853793e+00  3.02077869e+00  3.26562778e+00  3.49528531e+00\n",
      "  3.66950437e+00  3.70600681e+00  3.74747258e+00  3.37091313e+00\n",
      "  3.84719148e+00  4.07815581e+00  4.16921715e+00  4.36320156e+00\n",
      "  4.24376758e+00  3.93682036e+00  3.80181787e+00  4.11381637e+00\n",
      "  4.49435905e+00  4.51643643e+00  4.35170423e+00  4.38094389e+00\n",
      "  3.91714297e+00  3.45785303e+00  3.69004877e+00  3.86980917e+00\n",
      "  3.62374124e+00  3.40955169e+00  3.22197563e+00  2.84772821e+00\n",
      "  2.62339840e+00  2.67115943e+00  2.78143324e+00  2.57336304e+00\n",
      "  2.54506579e+00  2.33827726e+00  2.10547838e+00  1.78018570e+00\n",
      "  1.93717761e+00  1.96704553e+00  1.65374023e+00  1.49574308e+00\n",
      "  1.39224201e+00  1.23116634e+00  9.14217082e-01  9.80537182e-01\n",
      "  9.97701498e-01  9.75209459e-01  8.26498132e-01  7.50238812e-01\n",
      "  5.76534935e-01  3.98885526e-01  4.75509242e-01  4.86403430e-01] \n",
      "\n",
      "USA Cases:\n",
      " [-8.17861165e-01 -7.97170404e-01 -7.57499478e-01 -7.25340295e-01\n",
      " -7.18200420e-01 -7.11060546e-01 -7.99029746e-01 -8.18233033e-01\n",
      " -7.77149007e-01 -7.67703548e-01 -7.71035490e-01 -6.55875268e-01\n",
      " -7.04500787e-01 -7.87263829e-01 -8.57204847e-01 -8.28318106e-01\n",
      " -7.85449111e-01 -7.56978862e-01 -6.85832991e-01 -7.64029488e-01\n",
      " -8.18322282e-01 -8.58528698e-01 -8.36469462e-01 -8.34654744e-01\n",
      " -7.69339770e-01 -7.88037315e-01 -8.16135695e-01 -9.00817578e-01\n",
      " -9.23888297e-01 -8.64389345e-01 -8.84693362e-01 -7.93927711e-01\n",
      " -8.21654223e-01 -8.19869254e-01 -9.06767474e-01 -8.73537309e-01\n",
      " -8.93023216e-01 -8.49618730e-01 -8.15258086e-01 -8.38730422e-01\n",
      " -8.76839501e-01 -8.86314709e-01 -9.13907348e-01 -9.22638819e-01\n",
      " -9.07213716e-01 -8.67096547e-01 -8.28392479e-01 -8.25834024e-01\n",
      " -8.98392996e-01 -8.91297746e-01 -8.81867162e-01 -8.99062359e-01\n",
      " -8.75322278e-01 -7.51430585e-01 -8.51582196e-01 -9.17581408e-01\n",
      " -9.45679788e-01 -9.28082973e-01 -8.72555576e-01 -8.65966067e-01\n",
      " -8.07880216e-01 -8.12089766e-01 -9.02528173e-01 -9.17804529e-01\n",
      " -8.37674316e-01 -7.91919622e-01 -7.77506001e-01 -7.20104387e-01\n",
      " -7.02091079e-01 -8.03789663e-01 -7.25786537e-01 -6.53108567e-01\n",
      " -6.51011229e-01 -5.93550116e-01 -5.06294903e-01 -5.67697822e-01\n",
      " -5.69096047e-01 -6.02370836e-01 -4.90527681e-01 -4.35744021e-01\n",
      " -3.78387032e-01 -3.85512031e-01 -4.81736711e-01 -4.51793863e-01\n",
      " -5.10787074e-01 -3.14232287e-01 -3.14009166e-01 -2.90209585e-01\n",
      " -1.84539446e-01 -2.83039961e-01 -2.98732810e-01 -3.36975761e-01\n",
      " -1.92066064e-01 -1.84807192e-01 -6.52291732e-02 -1.32105995e-01\n",
      " -2.22574151e-01 -2.73029263e-01 -3.02972110e-01 -2.12518829e-01\n",
      " -1.51696025e-01 -1.76209593e-01 -8.52654453e-02 -2.20640435e-01\n",
      " -3.36291523e-01 -3.50258902e-01 -2.50598158e-01 -1.73234646e-01\n",
      " -1.76730209e-01 -1.77548320e-01 -3.10379730e-01 -4.97503933e-01\n",
      " -5.10623452e-01 -3.66323619e-01 -3.78089537e-01 -3.36440271e-01\n",
      " -2.91191318e-01 -3.61816573e-01 -4.62191305e-01 -5.11203567e-01\n",
      " -4.11170954e-01 -4.17343970e-01 -4.30850232e-01 -2.23139391e-01\n",
      " -4.49458530e-01 -5.89563686e-01 -6.70497136e-01 -5.54474180e-01\n",
      " -5.43570997e-01 -5.32310820e-01 -4.58591619e-01 -5.26063430e-01\n",
      " -6.78038628e-01 -6.68578295e-01 -5.88909198e-01 -5.64514628e-01\n",
      " -5.06964267e-01 -4.98619539e-01 -5.17436082e-01 -6.76610653e-01\n",
      " -6.75733043e-01 -5.45236967e-01 -6.02608832e-01 -6.44124225e-01\n",
      " -4.34851537e-01 -5.42291769e-01 -7.29817591e-01 -8.30698064e-01\n",
      " -8.17266175e-01 -6.70110393e-01 -6.78782365e-01 -4.77512285e-01\n",
      " -5.65555859e-01 -6.83988523e-01 -6.95620568e-01 -6.08573602e-01\n",
      " -6.24325949e-01 -5.19191301e-01 -4.60748456e-01 -5.50710871e-01\n",
      " -6.00719740e-01 -4.39358583e-01 -5.92761755e-01 -6.34663892e-01\n",
      " -4.83551429e-01 -4.03525339e-01 -5.16945216e-01 -6.15609353e-01\n",
      " -7.06434503e-01 -5.34720528e-01 -5.93713738e-01 -5.09701218e-01\n",
      " -3.70339798e-01 -4.52864845e-01 -6.64115873e-01 -6.19238789e-01\n",
      " -5.16781594e-01 -4.50246891e-01 -3.14157913e-01 -3.47566575e-01\n",
      " -3.66293870e-01 -5.00716877e-01 -5.68471308e-01 -4.25078834e-01\n",
      " -3.14024040e-01 -2.23258389e-01 -1.64756045e-01 -3.41378684e-01\n",
      " -4.36279512e-01 -1.91352076e-01 -2.73416006e-01 -2.64119295e-01\n",
      " -5.92644033e-02  4.50818835e-02  4.67627289e-02 -2.59984117e-01\n",
      " -1.98462201e-01 -3.23857518e-02 -2.38774017e-02  1.65626760e-01\n",
      "  2.99425028e-01  1.50067784e-01  3.72281495e-01  6.54007756e-02\n",
      "  7.12957618e-01  3.44852478e-01  7.39018159e-01  7.11767639e-01\n",
      "  7.64468836e-01  6.45575055e-01 -5.22286522e-02  9.60116264e-01\n",
      "  1.00725431e+00  1.23089599e+00  1.49825453e+00  1.34928403e+00\n",
      "  8.41281983e-01  1.19635685e+00  1.24075795e+00  1.38490903e+00\n",
      "  1.65626888e+00  1.80541787e+00  1.49548783e+00  9.79379050e-01\n",
      "  1.38065486e+00  1.44241477e+00  1.55504628e+00  5.33538529e-01\n",
      "  1.85448963e+00  1.14988817e+00  8.93432814e-01  1.13767601e+00\n",
      "  1.68877018e+00  1.84208410e+00  2.14497839e+00  2.29667097e+00\n",
      "  2.08858826e+00  1.46196017e+00  1.65467728e+00  2.23446482e+00\n",
      "  2.10074092e+00  2.28994759e+00  2.38614252e+00  2.07860731e+00\n",
      "  1.58525688e+00  1.80938943e+00  2.09958069e+00  2.38184372e+00\n",
      "  2.33842436e+00  2.50173411e+00  1.79744501e+00  1.56200766e+00\n",
      "  1.65060160e+00  1.79841187e+00  2.15860365e+00  1.85892231e+00\n",
      "  4.11729300e-01  2.05550684e+00  1.10327074e+00  1.30385658e+00\n",
      "  1.79832262e+00  2.10407286e+00  2.65531578e+00  1.25509719e+00\n",
      "  3.21529016e+00  1.82595989e+00  1.52238136e+00  2.24486226e+00\n",
      "  2.61798018e+00  3.09953495e+00  3.31264532e+00  2.65954020e+00\n",
      "  1.96932261e+00  1.95904417e+00  2.05461436e+00  2.21911409e+00\n",
      "  2.35499482e+00  2.46752221e+00  1.90079469e+00  1.42997949e+00\n",
      "  8.99114964e-01  1.26600038e+00  1.56171017e+00  1.66120729e+00\n",
      "  1.62208673e+00  1.39732944e+00  8.52110792e-01  9.31155149e-01\n",
      "  9.52678895e-01  1.11548290e+00  1.28325507e+00  1.28591765e+00\n",
      "  9.57870179e-01  5.18396046e-01  7.33722752e-01  5.04532790e-01\n",
      "  6.36025473e-01  6.49189616e-01  7.58459442e-01  4.52486082e-01\n",
      "  1.66638242e-01  8.34438327e-02  2.06621538e-01  2.31194605e-01\n",
      "  3.84211034e-01  2.90396062e-01  1.23248632e-01 -2.08353902e-01\n",
      " -3.84173305e-01 -3.14500032e-01 -1.52871129e-01 -1.33816590e-01\n",
      " -3.22816286e-02 -1.06744567e-01 -3.35518037e-01 -3.74311353e-01\n",
      " -1.24624002e-01 -7.87949342e-02 -3.44384656e-02 -3.90347597e-02\n",
      " -2.16713505e-01 -4.21137028e-01 -3.70116677e-01 -3.47908693e-01\n",
      " -1.94951763e-01 -1.79437411e-01 -1.99027441e-01 -3.19393821e-01\n",
      " -5.69408417e-01 -5.29975486e-01 -3.62277690e-01 -3.29151649e-01\n",
      " -2.60668355e-01 -2.78131298e-01 -3.97858064e-01 -6.18837171e-01\n",
      " -3.72883379e-01 -3.86553263e-01 -3.11584583e-01 -2.97051964e-01\n",
      " -2.72761517e-01 -3.52222368e-01 -6.79823596e-01 -4.49146160e-01\n",
      " -4.00580141e-01  9.78277043e-02 -1.85179060e-01 -4.22625778e-02\n",
      " -2.45183753e-01 -5.45430339e-01 -1.78143309e-01 -2.83977070e-01\n",
      " -2.00395917e-01 -1.74068907e-02 -1.39811109e-01 -2.46195235e-01\n",
      " -6.56604130e-01 -8.08922723e-02 -2.88707236e-01 -7.90180553e-02\n",
      " -2.75527377e-03  5.77551603e-02 -1.73428017e-01 -5.09284726e-01\n",
      " -1.79496910e-01 -3.33674845e-02 -6.97064693e-02 -9.43241607e-02\n",
      " -1.02980417e-03 -4.01026383e-01 -5.61257060e-01 -1.95710375e-01\n",
      " -2.90849199e-01 -2.45674619e-01 -2.05602075e-01 -2.56384431e-01\n",
      " -3.96653210e-01 -7.03950421e-01 -5.03096835e-01 -4.44088749e-01\n",
      " -3.72675132e-01 -3.24361983e-01 -3.30311878e-01 -5.07068390e-01\n",
      " -7.51861952e-01 -4.57684260e-01 -5.98265408e-01 -5.22181123e-01\n",
      " -4.83447306e-01 -4.87136241e-01 -6.84330642e-01 -8.69387257e-01\n",
      " -6.61676416e-01 -6.94817332e-01 -6.60322815e-01 -6.15311858e-01\n",
      " -5.75551683e-01 -7.58049843e-01 -9.38346542e-01 -7.72493214e-01\n",
      " -7.86564716e-01 -7.59329071e-01 -7.45391441e-01 -7.75483036e-01\n",
      " -8.90598633e-01 -9.97116632e-01 -8.22026091e-01 -8.58082456e-01\n",
      " -8.31828544e-01 -7.88438933e-01 -8.70562361e-01 -1.00904617e+00\n",
      " -1.09149684e+00 -1.10665420e+00 -8.65504950e-01 -9.43165957e-01\n",
      " -9.09370553e-01 -9.42972586e-01 -9.81751028e-01 -1.11012002e+00\n",
      " -9.69062876e-01 -1.00318553e+00 -9.13327233e-01 -9.79966059e-01\n",
      " -8.26667010e-01 -1.06528756e+00 -1.11781026e+00 -1.01083114e+00\n",
      " -1.03338124e+00 -1.00785619e+00 -1.03634132e+00 -8.79264083e-01\n",
      " -1.06830713e+00 -1.12823745e+00 -1.02067822e+00 -1.03552321e+00\n",
      " -1.00126668e+00 -9.89828010e-01] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "india_cases_train, india_cases_test = india_cases_train.to_numpy().flatten(), india_cases_test.to_numpy()\n",
    "usa_cases_train, usa_cases_test = usa_cases_train.to_numpy().flatten(), usa_cases_test.to_numpy()\n",
    "\n",
    "# Visualize outputs\n",
    "print('India Cases:\\n',india_cases_train,'\\n')\n",
    "print('USA Cases:\\n',usa_cases_train,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80961213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate data preparation\n",
    "from numpy import array\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a9fb009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68799512 -0.68799512 -0.68798255] -0.687982551549953\n",
      "[-0.68799512 -0.68798255 -0.68798255] -0.6879951169346211\n",
      "[-0.68798255 -0.68798255 -0.68799512] -0.6879951169346211\n",
      "[-0.68798255 -0.68799512 -0.68799512] -0.6879951169346211\n",
      "[-0.68799512 -0.68799512 -0.68799512] -0.6879951169346211\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "india_cases_train_X, india_cases_train_y = split_sequence(india_cases_train, n_steps)\n",
    "india_cases_test_X, india_cases_test_y = split_sequence(india_cases_test, n_steps)\n",
    "\n",
    "\n",
    "# summarize the data\n",
    "for i in range(0,5):\n",
    "    print(india_cases_train_X[i], india_cases_train_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f0269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      " [[[-0.68799512]\n",
      "  [-0.68799512]\n",
      "  [-0.68798255]]\n",
      "\n",
      " [[-0.68799512]\n",
      "  [-0.68798255]\n",
      "  [-0.68798255]]\n",
      "\n",
      " [[-0.68798255]\n",
      "  [-0.68798255]\n",
      "  [-0.68799512]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.82649813]\n",
      "  [ 0.75023881]\n",
      "  [ 0.57653493]]\n",
      "\n",
      " [[ 0.75023881]\n",
      "  [ 0.57653493]\n",
      "  [ 0.39888553]]\n",
      "\n",
      " [[ 0.57653493]\n",
      "  [ 0.39888553]\n",
      "  [ 0.47550924]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data into [samples, timesteps, features]\n",
    "# univariate\n",
    "n_features = 1\n",
    "\n",
    "india_cases_train_X = india_cases_train_X.reshape((india_cases_train_X.shape[0], \n",
    "                                                   india_cases_train_X.shape[1], n_features))\n",
    "india_cases_test_X = india_cases_test_X.reshape((india_cases_test_X.shape[0], \n",
    "                                                 india_cases_test_X.shape[1], n_features))\n",
    "\n",
    "# Visualize outputs\n",
    "print('India Cases:\\n',india_cases_train_X,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a237a15",
   "metadata": {},
   "source": [
    "<a name=model></a>\n",
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0500ceb",
   "metadata": {},
   "source": [
    "### Univariate non-stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6209e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.losses import MeanAbsolutePercentageError, MeanAbsoluteError\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a3bf1a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_univariate_non_stacked(optimizer=\"adam\", lstm_nparams=100, n_steps=3, n_features=1):\n",
    "    model_uni = Sequential()\n",
    "    model_uni.add(LSTM(lstm_nparams, activation='relu', input_shape=(n_steps, n_features)))\n",
    "    model_uni.add(Dense(1))\n",
    "    model_uni.compile(optimizer=optimizer,loss='mae', metrics=[\"mae\"])\n",
    "    model_uni.summary()\n",
    "    return model_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3174c71e",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6dd043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KerasClassifier wrapper \n",
    "keras_estimator = KerasRegressor(build_fn=build_univariate_non_stacked, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for the gridserach\n",
    "param_grid = {\n",
    "#     'epochs': [10,100,300,],\n",
    "    'lstm_nparams':[15,50],\n",
    "#     'n_steps': [3, 6, 15],\n",
    "#     'optimizer': ['RMSprop','Adam','Adamax','sgd']\n",
    "}\n",
    "\n",
    "kfold_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GridSearch\n",
    "grid = GridSearchCV(estimator=keras_estimator,\n",
    "                    verbose=-1,\n",
    "                    return_train_score=True,\n",
    "                    cv=kfold_splits,\n",
    "                    param_grid=param_grid,\n",
    "#                     scoring=\"neg_mean_absolute_error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc73262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting GridSearch\n",
    "grid_result = grid.fit(india_cases_train_X, india_cases_train_y, )\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the gridsearch results to file\n",
    "file1 = open(\"univariate_non_stacked_india.txt\", \"w\")\n",
    "file1.write(\"mean,stdev,pram\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    file1.write(\"%f,%f,%r\" % (mean, stdev, param))\n",
    "    file1.write(\"\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc006cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(grid_result.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab879991",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.cv_results_['split2_train_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70513f80",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fca1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_univariate_stacked(optimizer=\"adam\",lstm_nparams_l1=100, lstm_nparams_l2=150, n_steps=3, n_features=1):\n",
    "    model_uni_stacked = Sequential()\n",
    "    model_uni_stacked.add(LSTM(lstm_nparams_l1, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    model_uni_stacked.add(LSTM(lstm_nparams_l2, activation='relu'))\n",
    "    model_uni_stacked.add(Dense(1))\n",
    "    model_uni_stacked.compile(optimizer=optimizer,loss='mae')\n",
    "    model_uni_stacked.summary()\n",
    "    return model_uni_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31103e54",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d090ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KerasClassifier wrapper \n",
    "keras_estimator = KerasRegressor(build_fn=build_univariate_stacked, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5796d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for the gridserach\n",
    "param_grid = {\n",
    "    'epochs': [10,100,300,],\n",
    "    'lstm_nparams_l1':[15,50,100,150],\n",
    "    'lstm_nparams_l2':[15,50,100,150],\n",
    "    'n_steps': [3, 6, 15],\n",
    "#     'optimizer': ['RMSprop','Adam','Adamax','sgd']\n",
    "}\n",
    "\n",
    "kfold_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac03a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GridSearch\n",
    "grid = GridSearchCV(estimator=keras_estimator,\n",
    "                    verbose=-1,\n",
    "                    return_train_score=True,\n",
    "                    cv=kfold_splits,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring=\"neg_mean_absolute_error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1044188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting GridSearch\n",
    "grid_result = grid.fit(india_cases_train_X, india_cases_train_y, )\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the gridsearch results to file\n",
    "file1 = open(\"univariate_stacked_india.txt\", \"w\")\n",
    "file1.write(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "file1.write(\"\\n\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    file1.write(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    file1.write(\"\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f9fbe",
   "metadata": {},
   "source": [
    "## Multivariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "826f821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 150)               91200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 91,351\n",
      "Trainable params: 91,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model_uni = Sequential()\n",
    "model_uni.add(LSTM(150, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model_uni.add(Dense(1))\n",
    "model_uni.compile(optimizer='adam',loss='mae')\n",
    "model_uni.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8629c",
   "metadata": {},
   "source": [
    "<a name=train></a>\n",
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c1eb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard callback\n",
    "logdir = os.path.join(parentDir+\"/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a390c1c",
   "metadata": {},
   "source": [
    "### Univariate non-stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e165ffb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 2s 29ms/step - loss: 0.6528 - mae: 0.6528 - val_loss: 0.1765 - val_mae: 0.1765\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5165 - mae: 0.5165 - val_loss: 0.1186 - val_mae: 0.1186\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3137 - mae: 0.3137 - val_loss: 0.0797 - val_mae: 0.0797\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1403 - mae: 0.1403 - val_loss: 0.0801 - val_mae: 0.0801\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1036 - mae: 0.1036 - val_loss: 0.0793 - val_mae: 0.0793\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0972 - mae: 0.0972 - val_loss: 0.0767 - val_mae: 0.0767\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.0745 - val_mae: 0.0745\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0910 - mae: 0.0910 - val_loss: 0.0739 - val_mae: 0.0739\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0906 - mae: 0.0906 - val_loss: 0.0734 - val_mae: 0.0734\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0873 - mae: 0.0873 - val_loss: 0.0716 - val_mae: 0.0716\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0892 - mae: 0.0892 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0891 - mae: 0.0891 - val_loss: 0.0725 - val_mae: 0.0725\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0861 - mae: 0.0861 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0858 - mae: 0.0858 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0859 - mae: 0.0859 - val_loss: 0.0745 - val_mae: 0.0745\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0821 - mae: 0.0821 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0829 - mae: 0.0829 - val_loss: 0.0729 - val_mae: 0.0729\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0796 - mae: 0.0796 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0779 - mae: 0.0779 - val_loss: 0.0737 - val_mae: 0.0737\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0802 - mae: 0.0802 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0799 - mae: 0.0799 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0774 - mae: 0.0774 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0806 - mae: 0.0806 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0798 - mae: 0.0798 - val_loss: 0.0729 - val_mae: 0.0729\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0769 - mae: 0.0769 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0771 - mae: 0.0771 - val_loss: 0.0714 - val_mae: 0.0714\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0771 - mae: 0.0771 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0744 - mae: 0.0744 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0777 - mae: 0.0777 - val_loss: 0.0715 - val_mae: 0.0715\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0743 - mae: 0.0743 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0722 - mae: 0.0722 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0725 - mae: 0.0725 - val_loss: 0.0704 - val_mae: 0.0704\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0714 - mae: 0.0714 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0725 - mae: 0.0725 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0742 - mae: 0.0742 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0711 - mae: 0.0711 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0710 - mae: 0.0710 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.0641 - val_mae: 0.0641\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0713 - mae: 0.0713 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0689 - mae: 0.0689 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0703 - val_mae: 0.0703\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0705 - mae: 0.0705 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0703 - val_mae: 0.0703\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0756 - mae: 0.0756 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0706 - mae: 0.0706 - val_loss: 0.0697 - val_mae: 0.0697\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0751 - mae: 0.0751 - val_loss: 0.0716 - val_mae: 0.0716\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0771 - mae: 0.0771 - val_loss: 0.0703 - val_mae: 0.0703\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0688 - mae: 0.0688 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0684 - mae: 0.0684 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0684 - mae: 0.0684 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0684 - mae: 0.0684 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0722 - mae: 0.0722 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0687 - mae: 0.0687 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0712 - mae: 0.0712 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0676 - mae: 0.0676 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0712 - mae: 0.0712 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0704 - mae: 0.0704 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.0713 - val_mae: 0.0713\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0685 - mae: 0.0685 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0706 - mae: 0.0706 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0698 - mae: 0.0698 - val_loss: 0.0696 - val_mae: 0.0696\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0720 - mae: 0.0720 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0706 - mae: 0.0706 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0742 - mae: 0.0742 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0714 - mae: 0.0714 - val_loss: 0.0711 - val_mae: 0.0711\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0746 - mae: 0.0746 - val_loss: 0.0709 - val_mae: 0.0709\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0685 - mae: 0.0685 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0670 - mae: 0.0670 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0687 - mae: 0.0687 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0661 - mae: 0.0661 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0680 - mae: 0.0680 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0702 - mae: 0.0702 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0703 - mae: 0.0703 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0677 - mae: 0.0677 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0719 - mae: 0.0719 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0714 - mae: 0.0714 - val_loss: 0.0676 - val_mae: 0.0676\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0661 - mae: 0.0661 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.0706 - val_mae: 0.0706\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0628 - val_mae: 0.0628\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0663 - mae: 0.0663 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0707 - mae: 0.0707 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0701 - mae: 0.0701 - val_loss: 0.0720 - val_mae: 0.0720\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0687 - mae: 0.0687 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0713 - val_mae: 0.0713\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0657 - mae: 0.0657 - val_loss: 0.0628 - val_mae: 0.0628\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0660 - mae: 0.0660 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0654 - mae: 0.0654 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0672 - mae: 0.0672 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0658 - mae: 0.0658 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0676 - mae: 0.0676 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0698 - val_mae: 0.0698\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0691 - mae: 0.0691 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0648 - mae: 0.0648 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0657 - mae: 0.0657 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0680 - mae: 0.0680 - val_loss: 0.0676 - val_mae: 0.0676\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0650 - mae: 0.0650 - val_loss: 0.0643 - val_mae: 0.0643\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0661 - mae: 0.0661 - val_loss: 0.0634 - val_mae: 0.0634\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0658 - mae: 0.0658 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0733 - mae: 0.0733 - val_loss: 0.0714 - val_mae: 0.0714\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0744 - mae: 0.0744 - val_loss: 0.0630 - val_mae: 0.0630\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0698 - val_mae: 0.0698\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0688 - mae: 0.0688 - val_loss: 0.0626 - val_mae: 0.0626\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.0700 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0644 - mae: 0.0644 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0637 - mae: 0.0637 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0650 - mae: 0.0650 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0660 - mae: 0.0660 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0638 - mae: 0.0638 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0631 - mae: 0.0631 - val_loss: 0.0686 - val_mae: 0.0686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0632 - val_mae: 0.0632\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0614 - val_mae: 0.0614\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0632 - mae: 0.0632 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0646 - mae: 0.0646 - val_loss: 0.0630 - val_mae: 0.0630\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0632 - mae: 0.0632 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0622 - mae: 0.0622 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0636 - mae: 0.0636 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0630 - mae: 0.0630 - val_loss: 0.0631 - val_mae: 0.0631\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0643 - mae: 0.0643 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0625 - mae: 0.0625 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0627 - mae: 0.0627 - val_loss: 0.0620 - val_mae: 0.0620\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0621 - mae: 0.0621 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0642 - mae: 0.0642 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0653 - mae: 0.0653 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0607 - val_mae: 0.0607\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0646 - mae: 0.0646 - val_loss: 0.0701 - val_mae: 0.0701\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0612 - val_mae: 0.0612\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0614 - val_mae: 0.0614\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0636 - mae: 0.0636 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0632 - val_mae: 0.0632\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0635 - mae: 0.0635 - val_loss: 0.0621 - val_mae: 0.0621\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0620 - mae: 0.0620 - val_loss: 0.0629 - val_mae: 0.0629\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0621 - val_mae: 0.0621\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0637 - mae: 0.0637 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0629 - val_mae: 0.0629\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0631 - mae: 0.0631 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0602 - mae: 0.0602 - val_loss: 0.0627 - val_mae: 0.0627\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0626 - mae: 0.0626 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0611 - mae: 0.0611 - val_loss: 0.0623 - val_mae: 0.0623\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0614 - mae: 0.0614 - val_loss: 0.0615 - val_mae: 0.0615\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0635 - mae: 0.0635 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0607 - mae: 0.0607 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0611 - mae: 0.0611 - val_loss: 0.0621 - val_mae: 0.0621\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0597 - mae: 0.0597 - val_loss: 0.0634 - val_mae: 0.0634\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0603 - mae: 0.0603 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0642 - mae: 0.0642 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0608 - mae: 0.0608 - val_loss: 0.0591 - val_mae: 0.0591\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0605 - val_mae: 0.0605\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0626 - mae: 0.0626 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0587 - val_mae: 0.0587\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0603 - mae: 0.0603 - val_loss: 0.0610 - val_mae: 0.0610\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0604 - mae: 0.0604 - val_loss: 0.0620 - val_mae: 0.0620\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0600 - mae: 0.0600 - val_loss: 0.0604 - val_mae: 0.0604\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0599 - mae: 0.0599 - val_loss: 0.0606 - val_mae: 0.0606\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0598 - mae: 0.0598 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 242/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0615 - mae: 0.0615 - val_loss: 0.0619 - val_mae: 0.0619\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0616 - mae: 0.0616 - val_loss: 0.0590 - val_mae: 0.0590\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0592 - mae: 0.0592 - val_loss: 0.0631 - val_mae: 0.0631\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0601 - mae: 0.0601 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0607 - mae: 0.0607 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0608 - mae: 0.0608 - val_loss: 0.0587 - val_mae: 0.0587\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0598 - mae: 0.0598 - val_loss: 0.0578 - val_mae: 0.0578\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0601 - mae: 0.0601 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0597 - mae: 0.0597 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0740 - mae: 0.0740 - val_loss: 0.0561 - val_mae: 0.0561\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0611 - mae: 0.0611 - val_loss: 0.0615 - val_mae: 0.0615\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0615 - mae: 0.0615 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0600 - mae: 0.0600 - val_loss: 0.0590 - val_mae: 0.0590\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0590 - mae: 0.0590 - val_loss: 0.0612 - val_mae: 0.0612\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0586 - mae: 0.0586 - val_loss: 0.0596 - val_mae: 0.0596\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0576 - val_mae: 0.0576\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0623 - mae: 0.0623 - val_loss: 0.0595 - val_mae: 0.0595\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0624 - mae: 0.0624 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0622 - mae: 0.0622 - val_loss: 0.0585 - val_mae: 0.0585\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0589 - mae: 0.0589 - val_loss: 0.0593 - val_mae: 0.0593\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0596 - mae: 0.0596 - val_loss: 0.0614 - val_mae: 0.0614\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0586 - mae: 0.0586 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0587 - mae: 0.0587 - val_loss: 0.0609 - val_mae: 0.0609\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0613 - mae: 0.0613 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0648 - mae: 0.0648 - val_loss: 0.0585 - val_mae: 0.0585\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0609 - val_mae: 0.0609\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0592 - mae: 0.0592 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0567 - val_mae: 0.0567\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0576 - mae: 0.0576 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0609 - mae: 0.0609 - val_loss: 0.0592 - val_mae: 0.0592\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0593 - val_mae: 0.0593\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0587 - mae: 0.0587 - val_loss: 0.0613 - val_mae: 0.0613\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0587 - mae: 0.0587 - val_loss: 0.0570 - val_mae: 0.0570\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0589 - mae: 0.0589 - val_loss: 0.0553 - val_mae: 0.0553\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0610 - mae: 0.0610 - val_loss: 0.0624 - val_mae: 0.0624\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0599 - mae: 0.0599 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0572 - mae: 0.0572 - val_loss: 0.0598 - val_mae: 0.0598\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0586 - mae: 0.0586 - val_loss: 0.0602 - val_mae: 0.0602\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0566 - mae: 0.0566 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0571 - mae: 0.0571 - val_loss: 0.0544 - val_mae: 0.0544\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0617 - mae: 0.0617 - val_loss: 0.0555 - val_mae: 0.0555\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0567 - mae: 0.0567 - val_loss: 0.0581 - val_mae: 0.0581\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0591 - mae: 0.0591 - val_loss: 0.0618 - val_mae: 0.0618\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0582 - mae: 0.0582 - val_loss: 0.0540 - val_mae: 0.0540\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0590 - mae: 0.0590 - val_loss: 0.0547 - val_mae: 0.0547\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0569 - mae: 0.0569 - val_loss: 0.0611 - val_mae: 0.0611\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0563 - mae: 0.0563 - val_loss: 0.0564 - val_mae: 0.0564\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0571 - mae: 0.0571 - val_loss: 0.0574 - val_mae: 0.0574\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0579 - val_mae: 0.0579\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0604 - mae: 0.0604 - val_loss: 0.0570 - val_mae: 0.0570\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0607 - mae: 0.0607 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0574 - mae: 0.0574 - val_loss: 0.0545 - val_mae: 0.0545\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0578 - mae: 0.0578 - val_loss: 0.0561 - val_mae: 0.0561\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0560 - val_mae: 0.0560\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0572 - mae: 0.0572 - val_loss: 0.0603 - val_mae: 0.0603\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0580 - val_mae: 0.0580\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0582 - mae: 0.0582 - val_loss: 0.0558 - val_mae: 0.0558\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni = build_univariate_non_stacked()\n",
    "model_uni.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni.save('univar_1_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee706d9a",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a63fe62b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_uni_stacked' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bf62f649533f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_uni_stacked.fit(india_cases_train_X,\n\u001b[0m\u001b[1;32m      3\u001b[0m           \u001b[0mindia_cases_train_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindia_cases_test_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindia_cases_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_uni_stacked' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni_stacked.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni_stacked.save('univar_2_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cdc896",
   "metadata": {},
   "source": [
    "<a name=predict></a>\n",
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1df6917e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.4716768 ],\n",
       "        [ 0.3716689 ],\n",
       "        [ 0.32771519]],\n",
       "\n",
       "       [[ 0.3716689 ],\n",
       "        [ 0.32771519],\n",
       "        [ 0.19687184]],\n",
       "\n",
       "       [[ 0.32771519],\n",
       "        [ 0.19687184],\n",
       "        [ 0.07184626]],\n",
       "\n",
       "       [[ 0.19687184],\n",
       "        [ 0.07184626],\n",
       "        [ 0.09387338]],\n",
       "\n",
       "       [[ 0.07184626],\n",
       "        [ 0.09387338],\n",
       "        [ 0.15649926]],\n",
       "\n",
       "       [[ 0.09387338],\n",
       "        [ 0.15649926],\n",
       "        [ 0.09709012]],\n",
       "\n",
       "       [[ 0.15649926],\n",
       "        [ 0.09709012],\n",
       "        [ 0.0753897 ]],\n",
       "\n",
       "       [[ 0.09709012],\n",
       "        [ 0.0753897 ],\n",
       "        [ 0.04363697]],\n",
       "\n",
       "       [[ 0.0753897 ],\n",
       "        [ 0.04363697],\n",
       "        [-0.01638787]],\n",
       "\n",
       "       [[ 0.04363697],\n",
       "        [-0.01638787],\n",
       "        [-0.15220711]],\n",
       "\n",
       "       [[-0.01638787],\n",
       "        [-0.15220711],\n",
       "        [-0.04907044]],\n",
       "\n",
       "       [[-0.15220711],\n",
       "        [-0.04907044],\n",
       "        [-0.00859733]],\n",
       "\n",
       "       [[-0.04907044],\n",
       "        [-0.00859733],\n",
       "        [-0.03877939]],\n",
       "\n",
       "       [[-0.00859733],\n",
       "        [-0.03877939],\n",
       "        [-0.07608601]],\n",
       "\n",
       "       [[-0.03877939],\n",
       "        [-0.07608601],\n",
       "        [-0.05922327]],\n",
       "\n",
       "       [[-0.07608601],\n",
       "        [-0.05922327],\n",
       "        [-0.10812775]],\n",
       "\n",
       "       [[-0.05922327],\n",
       "        [-0.10812775],\n",
       "        [-0.21596388]],\n",
       "\n",
       "       [[-0.10812775],\n",
       "        [-0.21596388],\n",
       "        [-0.11060313]],\n",
       "\n",
       "       [[-0.21596388],\n",
       "        [-0.11060313],\n",
       "        [-0.07498026]],\n",
       "\n",
       "       [[-0.11060313],\n",
       "        [-0.07498026],\n",
       "        [-0.10223458]],\n",
       "\n",
       "       [[-0.07498026],\n",
       "        [-0.10223458],\n",
       "        [-0.13372343]],\n",
       "\n",
       "       [[-0.10223458],\n",
       "        [-0.13372343],\n",
       "        [-0.14679143]],\n",
       "\n",
       "       [[-0.13372343],\n",
       "        [-0.14679143],\n",
       "        [-0.18794307]],\n",
       "\n",
       "       [[-0.14679143],\n",
       "        [-0.18794307],\n",
       "        [-0.25193857]],\n",
       "\n",
       "       [[-0.18794307],\n",
       "        [-0.25193857],\n",
       "        [-0.13847315]],\n",
       "\n",
       "       [[-0.25193857],\n",
       "        [-0.13847315],\n",
       "        [-0.11134448]],\n",
       "\n",
       "       [[-0.13847315],\n",
       "        [-0.11134448],\n",
       "        [-0.14274538]],\n",
       "\n",
       "       [[-0.11134448],\n",
       "        [-0.14274538],\n",
       "        [-0.15062388]],\n",
       "\n",
       "       [[-0.14274538],\n",
       "        [-0.15062388],\n",
       "        [-0.16645626]],\n",
       "\n",
       "       [[-0.15062388],\n",
       "        [-0.16645626],\n",
       "        [-0.22114081]],\n",
       "\n",
       "       [[-0.16645626],\n",
       "        [-0.22114081],\n",
       "        [-0.27451857]],\n",
       "\n",
       "       [[-0.22114081],\n",
       "        [-0.27451857],\n",
       "        [-0.19964144]],\n",
       "\n",
       "       [[-0.27451857],\n",
       "        [-0.19964144],\n",
       "        [-0.16360392]],\n",
       "\n",
       "       [[-0.19964144],\n",
       "        [-0.16360392],\n",
       "        [-0.19858595]],\n",
       "\n",
       "       [[-0.16360392],\n",
       "        [-0.19858595],\n",
       "        [-0.20951783]],\n",
       "\n",
       "       [[-0.19858595],\n",
       "        [-0.20951783],\n",
       "        [-0.17084158]],\n",
       "\n",
       "       [[-0.20951783],\n",
       "        [-0.17084158],\n",
       "        [-0.20844978]],\n",
       "\n",
       "       [[-0.17084158],\n",
       "        [-0.20844978],\n",
       "        [-0.309865  ]],\n",
       "\n",
       "       [[-0.20844978],\n",
       "        [-0.309865  ],\n",
       "        [-0.16006048]],\n",
       "\n",
       "       [[-0.309865  ],\n",
       "        [-0.16006048],\n",
       "        [-0.1680018 ]],\n",
       "\n",
       "       [[-0.16006048],\n",
       "        [-0.1680018 ],\n",
       "        [-0.24390929]],\n",
       "\n",
       "       [[-0.1680018 ],\n",
       "        [-0.24390929],\n",
       "        [-0.68799512]],\n",
       "\n",
       "       [[-0.24390929],\n",
       "        [-0.68799512],\n",
       "        [ 0.30264724]],\n",
       "\n",
       "       [[-0.68799512],\n",
       "        [ 0.30264724],\n",
       "        [-0.19340901]],\n",
       "\n",
       "       [[ 0.30264724],\n",
       "        [-0.19340901],\n",
       "        [-0.31494141]],\n",
       "\n",
       "       [[-0.19340901],\n",
       "        [-0.31494141],\n",
       "        [-0.13946581]],\n",
       "\n",
       "       [[-0.31494141],\n",
       "        [-0.13946581],\n",
       "        [-0.1412878 ]],\n",
       "\n",
       "       [[-0.13946581],\n",
       "        [-0.1412878 ],\n",
       "        [-0.13222815]],\n",
       "\n",
       "       [[-0.1412878 ],\n",
       "        [-0.13222815],\n",
       "        [-0.16465941]],\n",
       "\n",
       "       [[-0.13222815],\n",
       "        [-0.16465941],\n",
       "        [-0.16237251]],\n",
       "\n",
       "       [[-0.16465941],\n",
       "        [-0.16237251],\n",
       "        [-0.18369597]],\n",
       "\n",
       "       [[-0.16237251],\n",
       "        [-0.18369597],\n",
       "        [-0.30413518]],\n",
       "\n",
       "       [[-0.18369597],\n",
       "        [-0.30413518],\n",
       "        [-0.1523956 ]],\n",
       "\n",
       "       [[-0.30413518],\n",
       "        [-0.1523956 ],\n",
       "        [-0.14790975]],\n",
       "\n",
       "       [[-0.1523956 ],\n",
       "        [-0.14790975],\n",
       "        [-0.12703865]],\n",
       "\n",
       "       [[-0.14790975],\n",
       "        [-0.12703865],\n",
       "        [-0.20261944]],\n",
       "\n",
       "       [[-0.12703865],\n",
       "        [-0.20261944],\n",
       "        [-0.19706554]],\n",
       "\n",
       "       [[-0.20261944],\n",
       "        [-0.19706554],\n",
       "        [-0.24193653]],\n",
       "\n",
       "       [[-0.19706554],\n",
       "        [-0.24193653],\n",
       "        [-0.33360101]],\n",
       "\n",
       "       [[-0.24193653],\n",
       "        [-0.33360101],\n",
       "        [-0.20607492]],\n",
       "\n",
       "       [[-0.33360101],\n",
       "        [-0.20607492],\n",
       "        [-0.1703641 ]],\n",
       "\n",
       "       [[-0.20607492],\n",
       "        [-0.1703641 ],\n",
       "        [-0.18387188]],\n",
       "\n",
       "       [[-0.1703641 ],\n",
       "        [-0.18387188],\n",
       "        [-0.20212939]],\n",
       "\n",
       "       [[-0.18387188],\n",
       "        [-0.20212939],\n",
       "        [-0.23459834]],\n",
       "\n",
       "       [[-0.20212939],\n",
       "        [-0.23459834],\n",
       "        [-0.27412904]],\n",
       "\n",
       "       [[-0.23459834],\n",
       "        [-0.27412904],\n",
       "        [-0.37177465]],\n",
       "\n",
       "       [[-0.27412904],\n",
       "        [-0.37177465],\n",
       "        [-0.24597002]],\n",
       "\n",
       "       [[-0.37177465],\n",
       "        [-0.24597002],\n",
       "        [-0.23060255]],\n",
       "\n",
       "       [[-0.24597002],\n",
       "        [-0.23060255],\n",
       "        [-0.22846643]],\n",
       "\n",
       "       [[-0.23060255],\n",
       "        [-0.22846643],\n",
       "        [-0.25502966]],\n",
       "\n",
       "       [[-0.22846643],\n",
       "        [-0.25502966],\n",
       "        [-0.29912159]],\n",
       "\n",
       "       [[-0.25502966],\n",
       "        [-0.29912159],\n",
       "        [-0.37295579]],\n",
       "\n",
       "       [[-0.29912159],\n",
       "        [-0.37295579],\n",
       "        [-0.36799247]],\n",
       "\n",
       "       [[-0.37295579],\n",
       "        [-0.36799247],\n",
       "        [-0.21562461]],\n",
       "\n",
       "       [[-0.36799247],\n",
       "        [-0.21562461],\n",
       "        [-0.1079267 ]],\n",
       "\n",
       "       [[-0.21562461],\n",
       "        [-0.1079267 ],\n",
       "        [-0.12685017]],\n",
       "\n",
       "       [[-0.1079267 ],\n",
       "        [-0.12685017],\n",
       "        [-0.1004503 ]],\n",
       "\n",
       "       [[-0.12685017],\n",
       "        [-0.1004503 ],\n",
       "        [-0.12150988]],\n",
       "\n",
       "       [[-0.1004503 ],\n",
       "        [-0.12150988],\n",
       "        [-0.14882703]],\n",
       "\n",
       "       [[-0.12150988],\n",
       "        [-0.14882703],\n",
       "        [-0.29920955]],\n",
       "\n",
       "       [[-0.14882703],\n",
       "        [-0.29920955],\n",
       "        [-0.16068875]],\n",
       "\n",
       "       [[-0.29920955],\n",
       "        [-0.16068875],\n",
       "        [-0.09626602]],\n",
       "\n",
       "       [[-0.16068875],\n",
       "        [-0.09626602],\n",
       "        [-0.11812979]],\n",
       "\n",
       "       [[-0.09626602],\n",
       "        [-0.11812979],\n",
       "        [-0.15248355]],\n",
       "\n",
       "       [[-0.11812979],\n",
       "        [-0.15248355],\n",
       "        [-0.15062388]],\n",
       "\n",
       "       [[-0.15248355],\n",
       "        [-0.15062388],\n",
       "        [-0.19859851]],\n",
       "\n",
       "       [[-0.15062388],\n",
       "        [-0.19859851],\n",
       "        [-0.29567868]],\n",
       "\n",
       "       [[-0.19859851],\n",
       "        [-0.29567868],\n",
       "        [-0.21208117]],\n",
       "\n",
       "       [[-0.29567868],\n",
       "        [-0.21208117],\n",
       "        [-0.14437888]],\n",
       "\n",
       "       [[-0.21208117],\n",
       "        [-0.14437888],\n",
       "        [-0.24854592]],\n",
       "\n",
       "       [[-0.14437888],\n",
       "        [-0.24854592],\n",
       "        [-0.26861284]],\n",
       "\n",
       "       [[-0.24854592],\n",
       "        [-0.26861284],\n",
       "        [-0.3287382 ]],\n",
       "\n",
       "       [[-0.26861284],\n",
       "        [-0.3287382 ],\n",
       "        [-0.34553812]],\n",
       "\n",
       "       [[-0.3287382 ],\n",
       "        [-0.34553812],\n",
       "        [-0.36878408]],\n",
       "\n",
       "       [[-0.34553812],\n",
       "        [-0.36878408],\n",
       "        [-0.34651822]],\n",
       "\n",
       "       [[-0.36878408],\n",
       "        [-0.34651822],\n",
       "        [-0.30387131]],\n",
       "\n",
       "       [[-0.34651822],\n",
       "        [-0.30387131],\n",
       "        [-0.25570819]],\n",
       "\n",
       "       [[-0.30387131],\n",
       "        [-0.25570819],\n",
       "        [-0.23988837]],\n",
       "\n",
       "       [[-0.25570819],\n",
       "        [-0.23988837],\n",
       "        [-0.30132053]],\n",
       "\n",
       "       [[-0.23988837],\n",
       "        [-0.30132053],\n",
       "        [-0.30781684]],\n",
       "\n",
       "       [[-0.30132053],\n",
       "        [-0.30781684],\n",
       "        [-0.3598501 ]],\n",
       "\n",
       "       [[-0.30781684],\n",
       "        [-0.3598501 ],\n",
       "        [-0.34918208]],\n",
       "\n",
       "       [[-0.3598501 ],\n",
       "        [-0.34918208],\n",
       "        [-0.28687034]],\n",
       "\n",
       "       [[-0.34918208],\n",
       "        [-0.28687034],\n",
       "        [-0.29366822]],\n",
       "\n",
       "       [[-0.28687034],\n",
       "        [-0.29366822],\n",
       "        [-0.31585868]],\n",
       "\n",
       "       [[-0.29366822],\n",
       "        [-0.31585868],\n",
       "        [-0.33206803]],\n",
       "\n",
       "       [[-0.31585868],\n",
       "        [-0.33206803],\n",
       "        [-0.36077993]],\n",
       "\n",
       "       [[-0.33206803],\n",
       "        [-0.36077993],\n",
       "        [-0.45182871]],\n",
       "\n",
       "       [[-0.36077993],\n",
       "        [-0.45182871],\n",
       "        [-0.45088631]],\n",
       "\n",
       "       [[-0.45182871],\n",
       "        [-0.45088631],\n",
       "        [-0.39234418]],\n",
       "\n",
       "       [[-0.45088631],\n",
       "        [-0.39234418],\n",
       "        [-0.35216008]],\n",
       "\n",
       "       [[-0.39234418],\n",
       "        [-0.35216008],\n",
       "        [-0.38197774]],\n",
       "\n",
       "       [[-0.35216008],\n",
       "        [-0.38197774],\n",
       "        [-0.4009766 ]],\n",
       "\n",
       "       [[-0.38197774],\n",
       "        [-0.4009766 ],\n",
       "        [-0.42664768]],\n",
       "\n",
       "       [[-0.4009766 ],\n",
       "        [-0.42664768],\n",
       "        [-0.45747057]],\n",
       "\n",
       "       [[-0.42664768],\n",
       "        [-0.45747057],\n",
       "        [-0.45135123]],\n",
       "\n",
       "       [[-0.45747057],\n",
       "        [-0.45135123],\n",
       "        [-0.40614097]],\n",
       "\n",
       "       [[-0.45135123],\n",
       "        [-0.40614097],\n",
       "        [-0.42089274]],\n",
       "\n",
       "       [[-0.40614097],\n",
       "        [-0.42089274],\n",
       "        [-0.43995442]],\n",
       "\n",
       "       [[-0.42089274],\n",
       "        [-0.43995442],\n",
       "        [-0.45973234]],\n",
       "\n",
       "       [[-0.43995442],\n",
       "        [-0.45973234],\n",
       "        [-0.46015956]],\n",
       "\n",
       "       [[-0.45973234],\n",
       "        [-0.46015956],\n",
       "        [-0.50814677]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_cases_test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4df1259b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.4716768 ]\n",
      "  [ 0.3716689 ]\n",
      "  [ 0.32771519]]\n",
      "\n",
      " [[ 0.3716689 ]\n",
      "  [ 0.32771519]\n",
      "  [ 0.19687184]]\n",
      "\n",
      " [[ 0.32771519]\n",
      "  [ 0.19687184]\n",
      "  [ 0.07184626]]\n",
      "\n",
      " [[ 0.19687184]\n",
      "  [ 0.07184626]\n",
      "  [ 0.09387338]]\n",
      "\n",
      " [[ 0.07184626]\n",
      "  [ 0.09387338]\n",
      "  [ 0.15649926]]\n",
      "\n",
      " [[ 0.09387338]\n",
      "  [ 0.15649926]\n",
      "  [ 0.09709012]]\n",
      "\n",
      " [[ 0.15649926]\n",
      "  [ 0.09709012]\n",
      "  [ 0.0753897 ]]\n",
      "\n",
      " [[ 0.09709012]\n",
      "  [ 0.0753897 ]\n",
      "  [ 0.04363697]]\n",
      "\n",
      " [[ 0.0753897 ]\n",
      "  [ 0.04363697]\n",
      "  [-0.01638787]]\n",
      "\n",
      " [[ 0.04363697]\n",
      "  [-0.01638787]\n",
      "  [-0.15220711]]\n",
      "\n",
      " [[-0.01638787]\n",
      "  [-0.15220711]\n",
      "  [-0.04907044]]\n",
      "\n",
      " [[-0.15220711]\n",
      "  [-0.04907044]\n",
      "  [-0.00859733]]\n",
      "\n",
      " [[-0.04907044]\n",
      "  [-0.00859733]\n",
      "  [-0.03877939]]\n",
      "\n",
      " [[-0.00859733]\n",
      "  [-0.03877939]\n",
      "  [-0.07608601]]\n",
      "\n",
      " [[-0.03877939]\n",
      "  [-0.07608601]\n",
      "  [-0.05922327]]\n",
      "\n",
      " [[-0.07608601]\n",
      "  [-0.05922327]\n",
      "  [-0.10812775]]\n",
      "\n",
      " [[-0.05922327]\n",
      "  [-0.10812775]\n",
      "  [-0.21596388]]\n",
      "\n",
      " [[-0.10812775]\n",
      "  [-0.21596388]\n",
      "  [-0.11060313]]\n",
      "\n",
      " [[-0.21596388]\n",
      "  [-0.11060313]\n",
      "  [-0.07498026]]\n",
      "\n",
      " [[-0.11060313]\n",
      "  [-0.07498026]\n",
      "  [-0.10223458]]\n",
      "\n",
      " [[-0.07498026]\n",
      "  [-0.10223458]\n",
      "  [-0.13372343]]\n",
      "\n",
      " [[-0.10223458]\n",
      "  [-0.13372343]\n",
      "  [-0.14679143]]\n",
      "\n",
      " [[-0.13372343]\n",
      "  [-0.14679143]\n",
      "  [-0.18794307]]\n",
      "\n",
      " [[-0.14679143]\n",
      "  [-0.18794307]\n",
      "  [-0.25193857]]\n",
      "\n",
      " [[-0.18794307]\n",
      "  [-0.25193857]\n",
      "  [-0.13847315]]\n",
      "\n",
      " [[-0.25193857]\n",
      "  [-0.13847315]\n",
      "  [-0.11134448]]\n",
      "\n",
      " [[-0.13847315]\n",
      "  [-0.11134448]\n",
      "  [-0.14274538]]\n",
      "\n",
      " [[-0.11134448]\n",
      "  [-0.14274538]\n",
      "  [-0.15062388]]\n",
      "\n",
      " [[-0.14274538]\n",
      "  [-0.15062388]\n",
      "  [-0.16645626]]\n",
      "\n",
      " [[-0.15062388]\n",
      "  [-0.16645626]\n",
      "  [-0.22114081]]\n",
      "\n",
      " [[-0.16645626]\n",
      "  [-0.22114081]\n",
      "  [-0.27451857]]\n",
      "\n",
      " [[-0.22114081]\n",
      "  [-0.27451857]\n",
      "  [-0.19964144]]\n",
      "\n",
      " [[-0.27451857]\n",
      "  [-0.19964144]\n",
      "  [-0.16360392]]\n",
      "\n",
      " [[-0.19964144]\n",
      "  [-0.16360392]\n",
      "  [-0.19858595]]\n",
      "\n",
      " [[-0.16360392]\n",
      "  [-0.19858595]\n",
      "  [-0.20951783]]\n",
      "\n",
      " [[-0.19858595]\n",
      "  [-0.20951783]\n",
      "  [-0.17084158]]\n",
      "\n",
      " [[-0.20951783]\n",
      "  [-0.17084158]\n",
      "  [-0.20844978]]\n",
      "\n",
      " [[-0.17084158]\n",
      "  [-0.20844978]\n",
      "  [-0.309865  ]]\n",
      "\n",
      " [[-0.20844978]\n",
      "  [-0.309865  ]\n",
      "  [-0.16006048]]\n",
      "\n",
      " [[-0.309865  ]\n",
      "  [-0.16006048]\n",
      "  [-0.1680018 ]]\n",
      "\n",
      " [[-0.16006048]\n",
      "  [-0.1680018 ]\n",
      "  [-0.24390929]]\n",
      "\n",
      " [[-0.1680018 ]\n",
      "  [-0.24390929]\n",
      "  [-0.68799512]]\n",
      "\n",
      " [[-0.24390929]\n",
      "  [-0.68799512]\n",
      "  [ 0.30264724]]\n",
      "\n",
      " [[-0.68799512]\n",
      "  [ 0.30264724]\n",
      "  [-0.19340901]]\n",
      "\n",
      " [[ 0.30264724]\n",
      "  [-0.19340901]\n",
      "  [-0.31494141]]\n",
      "\n",
      " [[-0.19340901]\n",
      "  [-0.31494141]\n",
      "  [-0.13946581]]\n",
      "\n",
      " [[-0.31494141]\n",
      "  [-0.13946581]\n",
      "  [-0.1412878 ]]\n",
      "\n",
      " [[-0.13946581]\n",
      "  [-0.1412878 ]\n",
      "  [-0.13222815]]\n",
      "\n",
      " [[-0.1412878 ]\n",
      "  [-0.13222815]\n",
      "  [-0.16465941]]\n",
      "\n",
      " [[-0.13222815]\n",
      "  [-0.16465941]\n",
      "  [-0.16237251]]\n",
      "\n",
      " [[-0.16465941]\n",
      "  [-0.16237251]\n",
      "  [-0.18369597]]\n",
      "\n",
      " [[-0.16237251]\n",
      "  [-0.18369597]\n",
      "  [-0.30413518]]\n",
      "\n",
      " [[-0.18369597]\n",
      "  [-0.30413518]\n",
      "  [-0.1523956 ]]\n",
      "\n",
      " [[-0.30413518]\n",
      "  [-0.1523956 ]\n",
      "  [-0.14790975]]\n",
      "\n",
      " [[-0.1523956 ]\n",
      "  [-0.14790975]\n",
      "  [-0.12703865]]\n",
      "\n",
      " [[-0.14790975]\n",
      "  [-0.12703865]\n",
      "  [-0.20261944]]\n",
      "\n",
      " [[-0.12703865]\n",
      "  [-0.20261944]\n",
      "  [-0.19706554]]\n",
      "\n",
      " [[-0.20261944]\n",
      "  [-0.19706554]\n",
      "  [-0.24193653]]\n",
      "\n",
      " [[-0.19706554]\n",
      "  [-0.24193653]\n",
      "  [-0.33360101]]\n",
      "\n",
      " [[-0.24193653]\n",
      "  [-0.33360101]\n",
      "  [-0.20607492]]\n",
      "\n",
      " [[-0.33360101]\n",
      "  [-0.20607492]\n",
      "  [-0.1703641 ]]\n",
      "\n",
      " [[-0.20607492]\n",
      "  [-0.1703641 ]\n",
      "  [-0.18387188]]\n",
      "\n",
      " [[-0.1703641 ]\n",
      "  [-0.18387188]\n",
      "  [-0.20212939]]\n",
      "\n",
      " [[-0.18387188]\n",
      "  [-0.20212939]\n",
      "  [-0.23459834]]\n",
      "\n",
      " [[-0.20212939]\n",
      "  [-0.23459834]\n",
      "  [-0.27412904]]\n",
      "\n",
      " [[-0.23459834]\n",
      "  [-0.27412904]\n",
      "  [-0.37177465]]\n",
      "\n",
      " [[-0.27412904]\n",
      "  [-0.37177465]\n",
      "  [-0.24597002]]\n",
      "\n",
      " [[-0.37177465]\n",
      "  [-0.24597002]\n",
      "  [-0.23060255]]\n",
      "\n",
      " [[-0.24597002]\n",
      "  [-0.23060255]\n",
      "  [-0.22846643]]\n",
      "\n",
      " [[-0.23060255]\n",
      "  [-0.22846643]\n",
      "  [-0.25502966]]\n",
      "\n",
      " [[-0.22846643]\n",
      "  [-0.25502966]\n",
      "  [-0.29912159]]\n",
      "\n",
      " [[-0.25502966]\n",
      "  [-0.29912159]\n",
      "  [-0.37295579]]\n",
      "\n",
      " [[-0.29912159]\n",
      "  [-0.37295579]\n",
      "  [-0.36799247]]\n",
      "\n",
      " [[-0.37295579]\n",
      "  [-0.36799247]\n",
      "  [-0.21562461]]\n",
      "\n",
      " [[-0.36799247]\n",
      "  [-0.21562461]\n",
      "  [-0.1079267 ]]\n",
      "\n",
      " [[-0.21562461]\n",
      "  [-0.1079267 ]\n",
      "  [-0.12685017]]\n",
      "\n",
      " [[-0.1079267 ]\n",
      "  [-0.12685017]\n",
      "  [-0.1004503 ]]\n",
      "\n",
      " [[-0.12685017]\n",
      "  [-0.1004503 ]\n",
      "  [-0.12150988]]\n",
      "\n",
      " [[-0.1004503 ]\n",
      "  [-0.12150988]\n",
      "  [-0.14882703]]\n",
      "\n",
      " [[-0.12150988]\n",
      "  [-0.14882703]\n",
      "  [-0.29920955]]\n",
      "\n",
      " [[-0.14882703]\n",
      "  [-0.29920955]\n",
      "  [-0.16068875]]\n",
      "\n",
      " [[-0.29920955]\n",
      "  [-0.16068875]\n",
      "  [-0.09626602]]\n",
      "\n",
      " [[-0.16068875]\n",
      "  [-0.09626602]\n",
      "  [-0.11812979]]\n",
      "\n",
      " [[-0.09626602]\n",
      "  [-0.11812979]\n",
      "  [-0.15248355]]\n",
      "\n",
      " [[-0.11812979]\n",
      "  [-0.15248355]\n",
      "  [-0.15062388]]\n",
      "\n",
      " [[-0.15248355]\n",
      "  [-0.15062388]\n",
      "  [-0.19859851]]\n",
      "\n",
      " [[-0.15062388]\n",
      "  [-0.19859851]\n",
      "  [-0.29567868]]\n",
      "\n",
      " [[-0.19859851]\n",
      "  [-0.29567868]\n",
      "  [-0.21208117]]\n",
      "\n",
      " [[-0.29567868]\n",
      "  [-0.21208117]\n",
      "  [-0.14437888]]\n",
      "\n",
      " [[-0.21208117]\n",
      "  [-0.14437888]\n",
      "  [-0.24854592]]\n",
      "\n",
      " [[-0.14437888]\n",
      "  [-0.24854592]\n",
      "  [-0.26861284]]\n",
      "\n",
      " [[-0.24854592]\n",
      "  [-0.26861284]\n",
      "  [-0.3287382 ]]\n",
      "\n",
      " [[-0.26861284]\n",
      "  [-0.3287382 ]\n",
      "  [-0.34553812]]\n",
      "\n",
      " [[-0.3287382 ]\n",
      "  [-0.34553812]\n",
      "  [-0.36878408]]\n",
      "\n",
      " [[-0.34553812]\n",
      "  [-0.36878408]\n",
      "  [-0.34651822]]\n",
      "\n",
      " [[-0.36878408]\n",
      "  [-0.34651822]\n",
      "  [-0.30387131]]\n",
      "\n",
      " [[-0.34651822]\n",
      "  [-0.30387131]\n",
      "  [-0.25570819]]\n",
      "\n",
      " [[-0.30387131]\n",
      "  [-0.25570819]\n",
      "  [-0.23988837]]\n",
      "\n",
      " [[-0.25570819]\n",
      "  [-0.23988837]\n",
      "  [-0.30132053]]\n",
      "\n",
      " [[-0.23988837]\n",
      "  [-0.30132053]\n",
      "  [-0.30781684]]\n",
      "\n",
      " [[-0.30132053]\n",
      "  [-0.30781684]\n",
      "  [-0.3598501 ]]\n",
      "\n",
      " [[-0.30781684]\n",
      "  [-0.3598501 ]\n",
      "  [-0.34918208]]\n",
      "\n",
      " [[-0.3598501 ]\n",
      "  [-0.34918208]\n",
      "  [-0.28687034]]\n",
      "\n",
      " [[-0.34918208]\n",
      "  [-0.28687034]\n",
      "  [-0.29366822]]\n",
      "\n",
      " [[-0.28687034]\n",
      "  [-0.29366822]\n",
      "  [-0.31585868]]\n",
      "\n",
      " [[-0.29366822]\n",
      "  [-0.31585868]\n",
      "  [-0.33206803]]\n",
      "\n",
      " [[-0.31585868]\n",
      "  [-0.33206803]\n",
      "  [-0.36077993]]\n",
      "\n",
      " [[-0.33206803]\n",
      "  [-0.36077993]\n",
      "  [-0.45182871]]\n",
      "\n",
      " [[-0.36077993]\n",
      "  [-0.45182871]\n",
      "  [-0.45088631]]\n",
      "\n",
      " [[-0.45182871]\n",
      "  [-0.45088631]\n",
      "  [-0.39234418]]\n",
      "\n",
      " [[-0.45088631]\n",
      "  [-0.39234418]\n",
      "  [-0.35216008]]\n",
      "\n",
      " [[-0.39234418]\n",
      "  [-0.35216008]\n",
      "  [-0.38197774]]\n",
      "\n",
      " [[-0.35216008]\n",
      "  [-0.38197774]\n",
      "  [-0.4009766 ]]\n",
      "\n",
      " [[-0.38197774]\n",
      "  [-0.4009766 ]\n",
      "  [-0.42664768]]\n",
      "\n",
      " [[-0.4009766 ]\n",
      "  [-0.42664768]\n",
      "  [-0.45747057]]\n",
      "\n",
      " [[-0.42664768]\n",
      "  [-0.45747057]\n",
      "  [-0.45135123]]\n",
      "\n",
      " [[-0.45747057]\n",
      "  [-0.45135123]\n",
      "  [-0.40614097]]\n",
      "\n",
      " [[-0.45135123]\n",
      "  [-0.40614097]\n",
      "  [-0.42089274]]\n",
      "\n",
      " [[-0.40614097]\n",
      "  [-0.42089274]\n",
      "  [-0.43995442]]\n",
      "\n",
      " [[-0.42089274]\n",
      "  [-0.43995442]\n",
      "  [-0.45973234]]\n",
      "\n",
      " [[-0.43995442]\n",
      "  [-0.45973234]\n",
      "  [-0.46015956]]\n",
      "\n",
      " [[-0.45973234]\n",
      "  [-0.46015956]\n",
      "  [-0.50814677]]]\n",
      "[[ 0.32119176]\n",
      " [ 0.2766939 ]\n",
      " [ 0.2044297 ]\n",
      " [ 0.08007066]\n",
      " [ 0.12769143]\n",
      " [ 0.08592498]\n",
      " [ 0.0648355 ]\n",
      " [ 0.03252039]\n",
      " [-0.01915614]\n",
      " [-0.05453897]\n",
      " [-0.07077751]\n",
      " [-0.02763348]\n",
      " [-0.04520274]\n",
      " [-0.08007582]\n",
      " [-0.07161295]\n",
      " [-0.10793351]\n",
      " [-0.1385    ]\n",
      " [-0.12653232]\n",
      " [-0.09091406]\n",
      " [-0.10503405]\n",
      " [-0.1336214 ]\n",
      " [-0.14747998]\n",
      " [-0.17810082]\n",
      " [-0.20834512]\n",
      " [-0.15625273]\n",
      " [-0.12353909]\n",
      " [-0.14151229]\n",
      " [-0.15128715]\n",
      " [-0.16444133]\n",
      " [-0.19770086]\n",
      " [-0.23306164]\n",
      " [-0.20677346]\n",
      " [-0.17269123]\n",
      " [-0.19212243]\n",
      " [-0.20320427]\n",
      " [-0.17720425]\n",
      " [-0.20078324]\n",
      " [-0.22248825]\n",
      " [-0.17948222]\n",
      " [-0.17252402]\n",
      " [-0.20191321]\n",
      " [-0.15297142]\n",
      " [-0.12061955]\n",
      " [-0.11710061]\n",
      " [-0.18132657]\n",
      " [-0.163829  ]\n",
      " [-0.15154324]\n",
      " [-0.13716538]\n",
      " [-0.16107169]\n",
      " [-0.16240166]\n",
      " [-0.17965329]\n",
      " [-0.2043683 ]\n",
      " [-0.17103055]\n",
      " [-0.15607958]\n",
      " [-0.13445726]\n",
      " [-0.1772602 ]\n",
      " [-0.19207148]\n",
      " [-0.22525407]\n",
      " [-0.25066623]\n",
      " [-0.21889964]\n",
      " [-0.18262835]\n",
      " [-0.18211052]\n",
      " [-0.19609326]\n",
      " [-0.22042796]\n",
      " [-0.24857588]\n",
      " [-0.28185296]\n",
      " [-0.2550921 ]\n",
      " [-0.23750004]\n",
      " [-0.22486156]\n",
      " [-0.24384567]\n",
      " [-0.2693362 ]\n",
      " [-0.30575913]\n",
      " [-0.3459206 ]\n",
      " [-0.25231433]\n",
      " [-0.14626154]\n",
      " [-0.13009189]\n",
      " [-0.11102487]\n",
      " [-0.12373836]\n",
      " [-0.14780052]\n",
      " [-0.16742311]\n",
      " [-0.17356902]\n",
      " [-0.11764283]\n",
      " [-0.12095699]\n",
      " [-0.1495954 ]\n",
      " [-0.15224962]\n",
      " [-0.18640006]\n",
      " [-0.21204442]\n",
      " [-0.21551573]\n",
      " [-0.1613676 ]\n",
      " [-0.20660475]\n",
      " [-0.24378824]\n",
      " [-0.28467953]\n",
      " [-0.32054958]\n",
      " [-0.34769186]\n",
      " [-0.33675396]\n",
      " [-0.30656615]\n",
      " [-0.26221415]\n",
      " [-0.23915459]\n",
      " [-0.2706369 ]\n",
      " [-0.29026583]\n",
      " [-0.32480523]\n",
      " [-0.33232167]\n",
      " [-0.2936147 ]\n",
      " [-0.28747076]\n",
      " [-0.29958388]\n",
      " [-0.3143148 ]\n",
      " [-0.33776495]\n",
      " [-0.36984625]\n",
      " [-0.4216663 ]\n",
      " [-0.39599955]\n",
      " [-0.35830906]\n",
      " [-0.36627522]\n",
      " [-0.3778096 ]\n",
      " [-0.4023021 ]\n",
      " [-0.42728004]\n",
      " [-0.4344099 ]\n",
      " [-0.40677044]\n",
      " [-0.41011822]\n",
      " [-0.4185591 ]\n",
      " [-0.43678847]\n",
      " [-0.44309554]\n",
      " [-0.47256076]]\n"
     ]
    }
   ],
   "source": [
    "x_input = np.array(india_cases_test_X)\n",
    "print(x_input)\n",
    "yhat = model_uni.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73816cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std <class 'pandas.core.series.Series'>\n",
      "mean <class 'pandas.core.series.Series'>\n",
      "std <class 'numpy.ndarray'>\n",
      "std [79583.71561331]\n",
      "x <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Reversing Z-score normalization\n",
    "\n",
    "# india_cases_df = (india_cases_df-india_cases_mean)/india_cases_std\n",
    "# usa_cases_df = (usa_cases_df-usa_cases_mean)/usa_cases_std\n",
    "\n",
    "print('std',type(india_cases_std))\n",
    "print('mean',type(india_cases_mean))\n",
    "casted_mean = india_cases_mean.to_numpy()\n",
    "casted_std = india_cases_std.to_numpy()\n",
    "print('std',type(casted_std))\n",
    "print('std',casted_std)\n",
    "\n",
    "\n",
    "print('x',type(x_input))\n",
    "\n",
    "x_input_scaled = (x_input*india_cases_std[0])+india_cases_mean[0]\n",
    "yhat_scaled = (india_cases_std[0]*yhat)+india_cases_mean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc16329",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4246121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fore_test(test, fore, title):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(12, 8)\n",
    "\n",
    "    ax.plot(test, color='blue', label='Test')\n",
    "    ax.plot(fore, color='red', label='Forecast')\n",
    "    ax.legend(loc='best')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4dae349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fore_test(x_input_scaled.flatten(), yhat_scaled, title='Daily cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18962bf2",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4586548b",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abe239cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.4716768 ]\n",
      "  [ 0.3716689 ]\n",
      "  [ 0.32771519]]\n",
      "\n",
      " [[ 0.3716689 ]\n",
      "  [ 0.32771519]\n",
      "  [ 0.19687184]]\n",
      "\n",
      " [[ 0.32771519]\n",
      "  [ 0.19687184]\n",
      "  [ 0.07184626]]\n",
      "\n",
      " [[ 0.19687184]\n",
      "  [ 0.07184626]\n",
      "  [ 0.09387338]]\n",
      "\n",
      " [[ 0.07184626]\n",
      "  [ 0.09387338]\n",
      "  [ 0.15649926]]\n",
      "\n",
      " [[ 0.09387338]\n",
      "  [ 0.15649926]\n",
      "  [ 0.09709012]]\n",
      "\n",
      " [[ 0.15649926]\n",
      "  [ 0.09709012]\n",
      "  [ 0.0753897 ]]\n",
      "\n",
      " [[ 0.09709012]\n",
      "  [ 0.0753897 ]\n",
      "  [ 0.04363697]]\n",
      "\n",
      " [[ 0.0753897 ]\n",
      "  [ 0.04363697]\n",
      "  [-0.01638787]]\n",
      "\n",
      " [[ 0.04363697]\n",
      "  [-0.01638787]\n",
      "  [-0.15220711]]\n",
      "\n",
      " [[-0.01638787]\n",
      "  [-0.15220711]\n",
      "  [-0.04907044]]\n",
      "\n",
      " [[-0.15220711]\n",
      "  [-0.04907044]\n",
      "  [-0.00859733]]\n",
      "\n",
      " [[-0.04907044]\n",
      "  [-0.00859733]\n",
      "  [-0.03877939]]\n",
      "\n",
      " [[-0.00859733]\n",
      "  [-0.03877939]\n",
      "  [-0.07608601]]\n",
      "\n",
      " [[-0.03877939]\n",
      "  [-0.07608601]\n",
      "  [-0.05922327]]\n",
      "\n",
      " [[-0.07608601]\n",
      "  [-0.05922327]\n",
      "  [-0.10812775]]\n",
      "\n",
      " [[-0.05922327]\n",
      "  [-0.10812775]\n",
      "  [-0.21596388]]\n",
      "\n",
      " [[-0.10812775]\n",
      "  [-0.21596388]\n",
      "  [-0.11060313]]\n",
      "\n",
      " [[-0.21596388]\n",
      "  [-0.11060313]\n",
      "  [-0.07498026]]\n",
      "\n",
      " [[-0.11060313]\n",
      "  [-0.07498026]\n",
      "  [-0.10223458]]\n",
      "\n",
      " [[-0.07498026]\n",
      "  [-0.10223458]\n",
      "  [-0.13372343]]\n",
      "\n",
      " [[-0.10223458]\n",
      "  [-0.13372343]\n",
      "  [-0.14679143]]\n",
      "\n",
      " [[-0.13372343]\n",
      "  [-0.14679143]\n",
      "  [-0.18794307]]\n",
      "\n",
      " [[-0.14679143]\n",
      "  [-0.18794307]\n",
      "  [-0.25193857]]\n",
      "\n",
      " [[-0.18794307]\n",
      "  [-0.25193857]\n",
      "  [-0.13847315]]\n",
      "\n",
      " [[-0.25193857]\n",
      "  [-0.13847315]\n",
      "  [-0.11134448]]\n",
      "\n",
      " [[-0.13847315]\n",
      "  [-0.11134448]\n",
      "  [-0.14274538]]\n",
      "\n",
      " [[-0.11134448]\n",
      "  [-0.14274538]\n",
      "  [-0.15062388]]\n",
      "\n",
      " [[-0.14274538]\n",
      "  [-0.15062388]\n",
      "  [-0.16645626]]\n",
      "\n",
      " [[-0.15062388]\n",
      "  [-0.16645626]\n",
      "  [-0.22114081]]\n",
      "\n",
      " [[-0.16645626]\n",
      "  [-0.22114081]\n",
      "  [-0.27451857]]\n",
      "\n",
      " [[-0.22114081]\n",
      "  [-0.27451857]\n",
      "  [-0.19964144]]\n",
      "\n",
      " [[-0.27451857]\n",
      "  [-0.19964144]\n",
      "  [-0.16360392]]\n",
      "\n",
      " [[-0.19964144]\n",
      "  [-0.16360392]\n",
      "  [-0.19858595]]\n",
      "\n",
      " [[-0.16360392]\n",
      "  [-0.19858595]\n",
      "  [-0.20951783]]\n",
      "\n",
      " [[-0.19858595]\n",
      "  [-0.20951783]\n",
      "  [-0.17084158]]\n",
      "\n",
      " [[-0.20951783]\n",
      "  [-0.17084158]\n",
      "  [-0.20844978]]\n",
      "\n",
      " [[-0.17084158]\n",
      "  [-0.20844978]\n",
      "  [-0.309865  ]]\n",
      "\n",
      " [[-0.20844978]\n",
      "  [-0.309865  ]\n",
      "  [-0.16006048]]\n",
      "\n",
      " [[-0.309865  ]\n",
      "  [-0.16006048]\n",
      "  [-0.1680018 ]]\n",
      "\n",
      " [[-0.16006048]\n",
      "  [-0.1680018 ]\n",
      "  [-0.24390929]]\n",
      "\n",
      " [[-0.1680018 ]\n",
      "  [-0.24390929]\n",
      "  [-0.68799512]]\n",
      "\n",
      " [[-0.24390929]\n",
      "  [-0.68799512]\n",
      "  [ 0.30264724]]\n",
      "\n",
      " [[-0.68799512]\n",
      "  [ 0.30264724]\n",
      "  [-0.19340901]]\n",
      "\n",
      " [[ 0.30264724]\n",
      "  [-0.19340901]\n",
      "  [-0.31494141]]\n",
      "\n",
      " [[-0.19340901]\n",
      "  [-0.31494141]\n",
      "  [-0.13946581]]\n",
      "\n",
      " [[-0.31494141]\n",
      "  [-0.13946581]\n",
      "  [-0.1412878 ]]\n",
      "\n",
      " [[-0.13946581]\n",
      "  [-0.1412878 ]\n",
      "  [-0.13222815]]\n",
      "\n",
      " [[-0.1412878 ]\n",
      "  [-0.13222815]\n",
      "  [-0.16465941]]\n",
      "\n",
      " [[-0.13222815]\n",
      "  [-0.16465941]\n",
      "  [-0.16237251]]\n",
      "\n",
      " [[-0.16465941]\n",
      "  [-0.16237251]\n",
      "  [-0.18369597]]\n",
      "\n",
      " [[-0.16237251]\n",
      "  [-0.18369597]\n",
      "  [-0.30413518]]\n",
      "\n",
      " [[-0.18369597]\n",
      "  [-0.30413518]\n",
      "  [-0.1523956 ]]\n",
      "\n",
      " [[-0.30413518]\n",
      "  [-0.1523956 ]\n",
      "  [-0.14790975]]\n",
      "\n",
      " [[-0.1523956 ]\n",
      "  [-0.14790975]\n",
      "  [-0.12703865]]\n",
      "\n",
      " [[-0.14790975]\n",
      "  [-0.12703865]\n",
      "  [-0.20261944]]\n",
      "\n",
      " [[-0.12703865]\n",
      "  [-0.20261944]\n",
      "  [-0.19706554]]\n",
      "\n",
      " [[-0.20261944]\n",
      "  [-0.19706554]\n",
      "  [-0.24193653]]\n",
      "\n",
      " [[-0.19706554]\n",
      "  [-0.24193653]\n",
      "  [-0.33360101]]\n",
      "\n",
      " [[-0.24193653]\n",
      "  [-0.33360101]\n",
      "  [-0.20607492]]\n",
      "\n",
      " [[-0.33360101]\n",
      "  [-0.20607492]\n",
      "  [-0.1703641 ]]\n",
      "\n",
      " [[-0.20607492]\n",
      "  [-0.1703641 ]\n",
      "  [-0.18387188]]\n",
      "\n",
      " [[-0.1703641 ]\n",
      "  [-0.18387188]\n",
      "  [-0.20212939]]\n",
      "\n",
      " [[-0.18387188]\n",
      "  [-0.20212939]\n",
      "  [-0.23459834]]\n",
      "\n",
      " [[-0.20212939]\n",
      "  [-0.23459834]\n",
      "  [-0.27412904]]\n",
      "\n",
      " [[-0.23459834]\n",
      "  [-0.27412904]\n",
      "  [-0.37177465]]\n",
      "\n",
      " [[-0.27412904]\n",
      "  [-0.37177465]\n",
      "  [-0.24597002]]\n",
      "\n",
      " [[-0.37177465]\n",
      "  [-0.24597002]\n",
      "  [-0.23060255]]\n",
      "\n",
      " [[-0.24597002]\n",
      "  [-0.23060255]\n",
      "  [-0.22846643]]\n",
      "\n",
      " [[-0.23060255]\n",
      "  [-0.22846643]\n",
      "  [-0.25502966]]\n",
      "\n",
      " [[-0.22846643]\n",
      "  [-0.25502966]\n",
      "  [-0.29912159]]\n",
      "\n",
      " [[-0.25502966]\n",
      "  [-0.29912159]\n",
      "  [-0.37295579]]\n",
      "\n",
      " [[-0.29912159]\n",
      "  [-0.37295579]\n",
      "  [-0.36799247]]\n",
      "\n",
      " [[-0.37295579]\n",
      "  [-0.36799247]\n",
      "  [-0.21562461]]\n",
      "\n",
      " [[-0.36799247]\n",
      "  [-0.21562461]\n",
      "  [-0.1079267 ]]\n",
      "\n",
      " [[-0.21562461]\n",
      "  [-0.1079267 ]\n",
      "  [-0.12685017]]\n",
      "\n",
      " [[-0.1079267 ]\n",
      "  [-0.12685017]\n",
      "  [-0.1004503 ]]\n",
      "\n",
      " [[-0.12685017]\n",
      "  [-0.1004503 ]\n",
      "  [-0.12150988]]\n",
      "\n",
      " [[-0.1004503 ]\n",
      "  [-0.12150988]\n",
      "  [-0.14882703]]\n",
      "\n",
      " [[-0.12150988]\n",
      "  [-0.14882703]\n",
      "  [-0.29920955]]\n",
      "\n",
      " [[-0.14882703]\n",
      "  [-0.29920955]\n",
      "  [-0.16068875]]\n",
      "\n",
      " [[-0.29920955]\n",
      "  [-0.16068875]\n",
      "  [-0.09626602]]\n",
      "\n",
      " [[-0.16068875]\n",
      "  [-0.09626602]\n",
      "  [-0.11812979]]\n",
      "\n",
      " [[-0.09626602]\n",
      "  [-0.11812979]\n",
      "  [-0.15248355]]\n",
      "\n",
      " [[-0.11812979]\n",
      "  [-0.15248355]\n",
      "  [-0.15062388]]\n",
      "\n",
      " [[-0.15248355]\n",
      "  [-0.15062388]\n",
      "  [-0.19859851]]\n",
      "\n",
      " [[-0.15062388]\n",
      "  [-0.19859851]\n",
      "  [-0.29567868]]\n",
      "\n",
      " [[-0.19859851]\n",
      "  [-0.29567868]\n",
      "  [-0.21208117]]\n",
      "\n",
      " [[-0.29567868]\n",
      "  [-0.21208117]\n",
      "  [-0.14437888]]\n",
      "\n",
      " [[-0.21208117]\n",
      "  [-0.14437888]\n",
      "  [-0.24854592]]\n",
      "\n",
      " [[-0.14437888]\n",
      "  [-0.24854592]\n",
      "  [-0.26861284]]\n",
      "\n",
      " [[-0.24854592]\n",
      "  [-0.26861284]\n",
      "  [-0.3287382 ]]\n",
      "\n",
      " [[-0.26861284]\n",
      "  [-0.3287382 ]\n",
      "  [-0.34553812]]\n",
      "\n",
      " [[-0.3287382 ]\n",
      "  [-0.34553812]\n",
      "  [-0.36878408]]\n",
      "\n",
      " [[-0.34553812]\n",
      "  [-0.36878408]\n",
      "  [-0.34651822]]\n",
      "\n",
      " [[-0.36878408]\n",
      "  [-0.34651822]\n",
      "  [-0.30387131]]\n",
      "\n",
      " [[-0.34651822]\n",
      "  [-0.30387131]\n",
      "  [-0.25570819]]\n",
      "\n",
      " [[-0.30387131]\n",
      "  [-0.25570819]\n",
      "  [-0.23988837]]\n",
      "\n",
      " [[-0.25570819]\n",
      "  [-0.23988837]\n",
      "  [-0.30132053]]\n",
      "\n",
      " [[-0.23988837]\n",
      "  [-0.30132053]\n",
      "  [-0.30781684]]\n",
      "\n",
      " [[-0.30132053]\n",
      "  [-0.30781684]\n",
      "  [-0.3598501 ]]\n",
      "\n",
      " [[-0.30781684]\n",
      "  [-0.3598501 ]\n",
      "  [-0.34918208]]\n",
      "\n",
      " [[-0.3598501 ]\n",
      "  [-0.34918208]\n",
      "  [-0.28687034]]\n",
      "\n",
      " [[-0.34918208]\n",
      "  [-0.28687034]\n",
      "  [-0.29366822]]\n",
      "\n",
      " [[-0.28687034]\n",
      "  [-0.29366822]\n",
      "  [-0.31585868]]\n",
      "\n",
      " [[-0.29366822]\n",
      "  [-0.31585868]\n",
      "  [-0.33206803]]\n",
      "\n",
      " [[-0.31585868]\n",
      "  [-0.33206803]\n",
      "  [-0.36077993]]\n",
      "\n",
      " [[-0.33206803]\n",
      "  [-0.36077993]\n",
      "  [-0.45182871]]\n",
      "\n",
      " [[-0.36077993]\n",
      "  [-0.45182871]\n",
      "  [-0.45088631]]\n",
      "\n",
      " [[-0.45182871]\n",
      "  [-0.45088631]\n",
      "  [-0.39234418]]\n",
      "\n",
      " [[-0.45088631]\n",
      "  [-0.39234418]\n",
      "  [-0.35216008]]\n",
      "\n",
      " [[-0.39234418]\n",
      "  [-0.35216008]\n",
      "  [-0.38197774]]\n",
      "\n",
      " [[-0.35216008]\n",
      "  [-0.38197774]\n",
      "  [-0.4009766 ]]\n",
      "\n",
      " [[-0.38197774]\n",
      "  [-0.4009766 ]\n",
      "  [-0.42664768]]\n",
      "\n",
      " [[-0.4009766 ]\n",
      "  [-0.42664768]\n",
      "  [-0.45747057]]\n",
      "\n",
      " [[-0.42664768]\n",
      "  [-0.45747057]\n",
      "  [-0.45135123]]\n",
      "\n",
      " [[-0.45747057]\n",
      "  [-0.45135123]\n",
      "  [-0.40614097]]\n",
      "\n",
      " [[-0.45135123]\n",
      "  [-0.40614097]\n",
      "  [-0.42089274]]\n",
      "\n",
      " [[-0.40614097]\n",
      "  [-0.42089274]\n",
      "  [-0.43995442]]\n",
      "\n",
      " [[-0.42089274]\n",
      "  [-0.43995442]\n",
      "  [-0.45973234]]\n",
      "\n",
      " [[-0.43995442]\n",
      "  [-0.45973234]\n",
      "  [-0.46015956]]\n",
      "\n",
      " [[-0.45973234]\n",
      "  [-0.46015956]\n",
      "  [-0.50814677]]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_uni_stacked' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-48d5b64d446d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindia_cases_test_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0myhat_stacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_uni_stacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_uni_stacked' is not defined"
     ]
    }
   ],
   "source": [
    "x_input = np.array(india_cases_test_X)\n",
    "print(x_input)\n",
    "yhat_stacked = model_uni_stacked.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82a69f",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c938009",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca77a056",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.146946"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape = MeanAbsolutePercentageError()\n",
    "mape(india_cases_test_y, yhat).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f109939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05580243"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = MeanAbsoluteError()\n",
    "mae(india_cases_test_y, yhat).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd2334e",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf4366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mape(india_cases_test_y, yhat_stacked).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
