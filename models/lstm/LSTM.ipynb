{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da7f88f7",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b493ee8",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. [Imports](#imports)\n",
    "2. [Data](#data)\n",
    "3. [Model](#model)\n",
    "5. [Train](#train)\n",
    "6. [Predict](#predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184bbb54",
   "metadata": {},
   "source": [
    "<a name=imports></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f68681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68972792",
   "metadata": {},
   "source": [
    "<a name=data></a>\n",
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8f3b4",
   "metadata": {},
   "source": [
    "### Ingestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6ed14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Directory /covid19-prediction/models\n",
      "Path: /covid19-prediction/models/../cleaned_datasets/india/daily_cases_india.csv\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "# Get the path of the current working directory\n",
    "curPath = os.getcwd()\n",
    "# Appened the parent directory to the current path to step out of the current folder\n",
    "parentDir = os.path.abspath(os.path.join(curPath, os.pardir))\n",
    "print(\"Parent Directory\", parentDir)\n",
    "# Save the path to all of the datasets\n",
    "india_cases_path = os.path.join(parentDir, \"../cleaned_datasets/india/daily_cases_india.csv\")\n",
    "india_vacc_path = os.path.join(parentDir, \"../cleaned_datasets/india/daily_vacc_india.csv\")\n",
    "usa_cases_path = os.path.join(parentDir, \"../cleaned_datasets/usa/daily_cases_usa.csv\")\n",
    "usa_vacc_path = os.path.join(parentDir, \"../cleaned_datasets/usa/vacc_usa.csv\")\n",
    "\n",
    "# Quick check to make sure the path exists\n",
    "print(\"Path:\", india_cases_path)\n",
    "print(\"Exists:\", os.path.exists(india_cases_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c18b18a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "    Unnamed: 0        Date  Confirmed  Deaths  Recovered  Active\n",
      "0           0  2020-01-30        1.0     0.0        0.0     0.0\n",
      "1           1  2020-01-31        0.0     0.0        0.0     0.0\n",
      "2           2  2020-02-01        0.0     0.0        0.0     0.0\n",
      "3           3  2020-02-02        1.0     0.0        0.0     0.0\n",
      "4           4  2020-02-03        1.0     0.0        0.0     0.0 \n",
      "\n",
      "India Vacc:\n",
      "    Updated On  Total_Doses  First_Dose  Second_Dose\n",
      "0  2021-01-16          NaN         NaN          NaN\n",
      "1  2021-01-17      20656.0     20656.0          0.0\n",
      "2  2021-01-18      81690.0     81690.0          0.0\n",
      "3  2021-01-19     192152.0    192152.0          0.0\n",
      "4  2021-01-20     111510.0    111510.0          0.0 \n",
      "\n",
      "USA Cases:\n",
      "          Date  Confirmed  Deaths  Recovered\n",
      "0  2020-04-14    26713.0  2305.0     6484.0\n",
      "1  2020-04-15    29380.0  2478.0     6093.0\n",
      "2  2020-04-16    31542.0  4616.0     5234.0\n",
      "3  2020-04-17    32022.0  3879.0     5904.0\n",
      "4  2020-04-18    32502.0  1859.0    13591.0 \n",
      "\n",
      "USA Vacc:\n",
      "          date  total_doses  people_vacc  people_fully_vacc  daily_vacc\n",
      "0  2020-12-20     556208.0          0.0                0.0         0.0\n",
      "1  2020-12-21     614117.0          0.0                0.0     57909.0\n",
      "2  2020-12-22          0.0          0.0                0.0    127432.0\n",
      "3  2020-12-23    1008025.0          0.0                0.0    150606.0\n",
      "4  2020-12-24          0.0          0.0                0.0    191001.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data as a pandas dataframe\n",
    "india_cases_df = pd.read_csv(india_cases_path)\n",
    "india_vacc_df =  pd.read_csv(india_vacc_path)\n",
    "\n",
    "usa_cases_df = pd.read_csv(usa_cases_path)\n",
    "usa_vacc_df = pd.read_csv(usa_vacc_path)\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('India Vacc:\\n',india_vacc_df.head(),'\\n')\n",
    "\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')\n",
    "print('USA Vacc:\\n',usa_vacc_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f3fa3",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897297ae",
   "metadata": {},
   "source": [
    "### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03503052",
   "metadata": {},
   "outputs": [],
   "source": [
    "india_cases_multi_df = india_cases_df[[\"Date\",\"Confirmed\",\"Deaths\",\"Recovered\",\"Active\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd4455",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d328699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "    Confirmed\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "5        0.0 \n",
      "\n",
      "USA Cases:\n",
      "    Confirmed\n",
      "1    29380.0\n",
      "2    31542.0\n",
      "3    32022.0\n",
      "4    32502.0\n",
      "5    26588.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select only the Confirmed column for univariate analysis\n",
    "# Selecting from the first index because the 0th index is NaN\n",
    "india_cases_df = india_cases_df[[\"Confirmed\"]][1:]\n",
    "usa_cases_df = usa_cases_df[[\"Confirmed\"]][1:]\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dcbb1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "    Confirmed\n",
      "1  -0.687995\n",
      "2  -0.687995\n",
      "3  -0.687983\n",
      "4  -0.687983\n",
      "5  -0.687995 \n",
      "\n",
      "USA Cases:\n",
      "    Confirmed\n",
      "1  -0.759976\n",
      "2  -0.727837\n",
      "3  -0.720702\n",
      "4  -0.713566\n",
      "5  -0.801480 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "india_cases_mean = india_cases_df.mean()\n",
    "india_cases_std = india_cases_df.std()\n",
    "\n",
    "usa_cases_mean = usa_cases_df.mean()\n",
    "usa_cases_std = usa_cases_df.std()\n",
    "\n",
    "\n",
    "india_cases_normalized_df = (india_cases_df-india_cases_mean)/india_cases_std\n",
    "usa_cases_normalized_df = (usa_cases_df-usa_cases_mean)/usa_cases_std\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_normalized_df.head(),'\\n')\n",
    "print('USA Cases:\\n',usa_cases_normalized_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285d674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      "      Confirmed\n",
      "1    -0.687995\n",
      "2    -0.687995\n",
      "3    -0.687983\n",
      "4    -0.687983\n",
      "5    -0.687995\n",
      "..         ...\n",
      "492   0.750239\n",
      "493   0.576535\n",
      "494   0.398886\n",
      "495   0.475509\n",
      "496   0.486403\n",
      "\n",
      "[496 rows x 1 columns] \n",
      "\n",
      "USA Cases:\n",
      "      Confirmed\n",
      "1    -0.759976\n",
      "2    -0.727837\n",
      "3    -0.720702\n",
      "4    -0.713566\n",
      "5    -0.801480\n",
      "..         ...\n",
      "432  -1.130479\n",
      "433  -1.022988\n",
      "434  -1.037824\n",
      "435  -1.003589\n",
      "436  -0.992157\n",
      "\n",
      "[436 rows x 1 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create train test splits\n",
    "india_cases_train, india_cases_test = train_test_split(india_cases_normalized_df, test_size=0.2, shuffle=False)\n",
    "india_vacc_train, india_vacc_test = train_test_split(india_vacc_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "usa_cases_train, usa_cases_test = train_test_split(usa_cases_normalized_df, test_size=0.2, shuffle=False)\n",
    "usa_vacc_train, usa_vacc_test = train_test_split(usa_vacc_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Visualize splits\n",
    "print('India Cases:\\n',india_cases_train,'\\n')\n",
    "print('USA Cases:\\n',usa_cases_train,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17fa1445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      " [-6.87995117e-01 -6.87995117e-01 -6.87982552e-01 -6.87982552e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87995117e-01\n",
      " -6.87995117e-01 -6.87995117e-01 -6.87995117e-01 -6.87969986e-01\n",
      " -6.87995117e-01 -6.87706113e-01 -6.87969986e-01 -6.87982552e-01\n",
      " -6.87957421e-01 -6.87932290e-01 -6.87944855e-01 -6.87831767e-01\n",
      " -6.87919725e-01 -6.87856898e-01 -6.87882028e-01 -6.87743809e-01\n",
      " -6.87856898e-01 -6.87919725e-01 -6.87706113e-01 -6.87819202e-01\n",
      " -6.87517632e-01 -6.87366848e-01 -6.86914494e-01 -6.87165802e-01\n",
      " -6.86700882e-01 -6.87530198e-01 -6.86474705e-01 -6.87115540e-01\n",
      " -6.85984655e-01 -6.86738578e-01 -6.87530198e-01 -6.85142775e-01\n",
      " -6.86160571e-01 -6.80443321e-01 -6.81146982e-01 -6.87693548e-01\n",
      " -6.81523944e-01 -6.81637032e-01 -6.73042309e-01 -6.81297767e-01\n",
      " -6.80393059e-01 -6.77829721e-01 -6.77025536e-01 -6.77339671e-01\n",
      " -6.78457990e-01 -6.72313517e-01 -6.75002509e-01 -6.77503021e-01\n",
      " -6.74072671e-01 -6.76409832e-01 -6.70780540e-01 -6.64208844e-01\n",
      " -6.76384702e-01 -6.68631859e-01 -6.71785771e-01 -6.66546005e-01\n",
      " -6.69737613e-01 -6.65967998e-01 -6.67802544e-01 -6.68380551e-01\n",
      " -6.64460151e-01 -6.66156478e-01 -6.65364859e-01 -6.57913586e-01\n",
      " -6.57310448e-01 -6.52736648e-01 -6.38588024e-01 -6.50763882e-01\n",
      " -6.42923082e-01 -6.45725163e-01 -6.45976471e-01 -6.48879074e-01\n",
      " -6.33297997e-01 -6.42671774e-01 -6.43714701e-01 -6.40711574e-01\n",
      " -6.38462371e-01 -6.40410005e-01 -6.26877086e-01 -6.24539924e-01\n",
      " -6.29817386e-01 -6.10755697e-01 -6.18219536e-01 -6.10114863e-01\n",
      " -6.05465670e-01 -6.04699182e-01 -5.98617536e-01 -6.07400740e-01\n",
      " -6.14575574e-01 -5.96355767e-01 -5.96267809e-01 -5.86152674e-01\n",
      " -5.83250070e-01 -5.77645909e-01 -5.90475167e-01 -5.77155859e-01\n",
      " -5.66952766e-01 -5.63736028e-01 -5.68988359e-01 -5.56837632e-01\n",
      " -5.51484778e-01 -5.81918140e-01 -5.59602016e-01 -6.82504044e-01\n",
      " -4.24725177e-01 -6.87995117e-01 -5.44020939e-01 -5.38102643e-01\n",
      " -4.09433104e-01 -5.50102586e-01 -5.26140397e-01 -5.17281801e-01\n",
      " -5.05595993e-01 -4.94324843e-01 -5.01763551e-01 -5.00356228e-01\n",
      " -4.87351055e-01 -4.75363678e-01 -4.70664224e-01 -4.54882101e-01\n",
      " -4.37868570e-01 -4.43485297e-01 -4.55259062e-01 -4.53612997e-01\n",
      " -4.47393131e-01 -4.25340881e-01 -4.01868743e-01 -3.75745308e-01\n",
      " -3.83309670e-01 -4.08402743e-01 -4.02094920e-01 -3.75380912e-01\n",
      " -3.54937031e-01 -3.47297277e-01 -3.28549723e-01 -3.26966485e-01\n",
      " -3.29906785e-01 -3.18208412e-01 -2.77408608e-01 -2.48520788e-01\n",
      " -2.45040177e-01 -2.01752426e-01 -1.80039442e-01 -2.21417253e-01\n",
      " -2.13777500e-01 -1.13505730e-01 -6.83959989e-02 -7.33467605e-02\n",
      " -7.71792028e-02 -5.99646258e-02 -1.29375811e-01 -6.49256036e-01\n",
      "  5.53552846e-01 -2.47564180e-02  8.15341709e-02 -2.28787125e-04\n",
      " -2.23815603e-02 -3.39668450e-02 -2.81993334e-02  1.92098630e-02\n",
      "  9.78189094e-02  8.52409594e-02  1.21203090e-01  9.18629171e-02\n",
      " -1.44779333e-02  7.80284286e-02  1.53873090e-01  1.23138160e-01\n",
      "  1.25387363e-01  1.16566463e-01  3.71657976e-02  3.32721674e-03\n",
      "  1.23376902e-01  1.87460364e-01  1.77759887e-01  1.90023702e-01\n",
      "  1.82019552e-01  8.36200248e-02  7.81792132e-02  3.10464553e-02\n",
      "  3.88694999e-01  2.82881895e-01  2.72904979e-01  3.01667145e-01\n",
      "  2.98538364e-01  1.90589144e-01  2.96590730e-01  3.66027045e-01\n",
      "  3.59216607e-01  3.98056211e-01  4.50830826e-01  4.52966942e-01\n",
      "  2.64574129e-01  4.39195280e-01  5.14951984e-01  5.25205338e-01\n",
      "  5.38009465e-01  4.97825365e-01  4.68912415e-01 -6.87995117e-01\n",
      "  1.49752737e+00  5.42080650e-01  5.23609534e-01  4.84820192e-01\n",
      "  4.75622330e-01  4.04703299e-01  2.55451660e-01  3.59291999e-01\n",
      "  3.99011180e-01  3.93281365e-01  3.84611249e-01  4.25297965e-01\n",
      "  3.44502541e-01  1.98982821e-01  3.23166518e-01  4.02944145e-01\n",
      "  2.41114556e-01  4.05419526e-01  2.64825437e-01  2.47397249e-01\n",
      "  8.18483055e-02  2.17328283e-01  2.98689149e-01  1.97814241e-01\n",
      "  2.32695748e-01  2.46655891e-01  1.50518133e-01  7.39840137e-03\n",
      "  1.10019898e-01  1.62781948e-01  1.08285875e-01  9.37225940e-02\n",
      "  8.94377979e-02  1.21732475e-02 -1.00060768e-01 -8.91146793e-03\n",
      "  1.36433975e-02 -4.86541407e-03 -1.73805372e-02 -5.81049489e-02\n",
      " -1.20693130e-01 -2.29735538e-01 -1.36462688e-01 -6.12211643e-02\n",
      " -7.67142836e-02 -8.14891298e-02 -9.78869568e-02 -1.19650203e-01\n",
      " -2.06615230e-01 -1.06808380e-01 -5.70871527e-02 -8.94053221e-02\n",
      " -5.52526066e-02 -1.14083738e-01 -1.11206265e-01 -2.09593226e-01\n",
      " -1.31587318e-01 -8.60503644e-02 -1.24073218e-01 -1.26523468e-01\n",
      " -1.71557807e-01 -3.04147746e-01 -3.30962277e-01 -1.93346184e-01\n",
      " -1.15315145e-01 -1.11470138e-01 -1.07072253e-01 -1.19926641e-01\n",
      " -1.34376834e-01 -2.10824634e-01 -1.30393607e-01 -1.28973718e-01\n",
      " -1.46653215e-01 -1.68768292e-01 -1.62636384e-01 -2.00810023e-01\n",
      " -2.96985477e-01 -2.28051777e-01 -2.41283127e-01 -2.28164865e-01\n",
      " -2.27448638e-01 -2.35503050e-01 -2.73576165e-01 -3.54170542e-01\n",
      " -2.84897577e-01 -2.91921627e-01 -3.18912073e-01 -3.10644050e-01\n",
      " -3.07841969e-01 -3.47837589e-01 -4.10739904e-01 -3.56495139e-01\n",
      " -3.86300231e-01 -4.00373462e-01 -3.71950562e-01 -3.53454316e-01\n",
      " -3.82191350e-01 -4.42266454e-01 -3.87054154e-01 -3.77479331e-01\n",
      " -3.98149389e-01 -4.08126304e-01 -4.52620331e-01 -4.36423550e-01\n",
      " -4.81520716e-01 -4.29789027e-01 -4.13793293e-01 -4.36247635e-01\n",
      " -1.96512661e-01 -7.11341602e-01 -4.80616008e-01 -4.82236943e-01\n",
      " -4.60712439e-01 -4.32339800e-01 -4.60071604e-01 -6.87995117e-01\n",
      " -2.24747080e-01 -4.83041128e-01 -5.29872316e-01 -4.87351055e-01\n",
      " -4.75062108e-01 -4.92100770e-01 -4.97529016e-01 -4.97704932e-01\n",
      " -5.14743593e-01 -5.61713001e-01 -5.14391762e-01 -4.96448393e-01\n",
      " -5.05231597e-01 -5.08862993e-01 -5.01411720e-01 -5.22094343e-01\n",
      " -5.73624986e-01 -5.28552951e-01 -5.41407339e-01 -4.51074789e-01\n",
      " -5.23614755e-01 -5.24092239e-01 -5.44297378e-01 -5.79493020e-01\n",
      " -5.49285836e-01 -5.25914220e-01 -5.32083824e-01 -5.40816766e-01\n",
      " -5.36469143e-01 -5.39334051e-01 -5.73524463e-01 -5.48934005e-01\n",
      " -5.25612651e-01 -5.71023951e-01 -5.35413651e-01 -5.34772816e-01\n",
      " -5.41620951e-01 -5.73386243e-01 -5.42111001e-01 -5.26140397e-01\n",
      " -5.22219997e-01 -5.12167689e-01 -5.08762470e-01 -5.09579220e-01\n",
      " -5.55003086e-01 -5.15321601e-01 -4.77675708e-01 -4.79698735e-01\n",
      " -4.80817055e-01 -4.77499793e-01 -4.93106001e-01 -5.33616801e-01\n",
      " -4.99652566e-01 -4.69269466e-01 -4.76419170e-01 -4.58249624e-01\n",
      " -4.52343893e-01 -4.54291527e-01 -4.94638978e-01 -4.62810858e-01\n",
      " -4.00825816e-01 -3.95410135e-01 -3.75343216e-01 -3.69839577e-01\n",
      " -3.57638589e-01 -3.80243716e-01 -3.24817804e-01 -2.37262204e-01\n",
      " -1.88822646e-01 -1.73404919e-01 -1.37053261e-01 -9.80377414e-02\n",
      " -1.76395480e-01 -9.41299067e-02 -1.60486064e-02  5.48452939e-02\n",
      "  9.43006017e-02  1.00030417e-01  1.66702348e-01  1.83177206e-02\n",
      " -1.59983449e-02  2.20859156e-01  3.35656510e-01  4.31945053e-01\n",
      "  4.83714438e-01  6.13250989e-01  5.30621019e-01  7.66272243e-01\n",
      "  9.05157440e-01  9.70233567e-01  1.13881077e+00  1.23298833e+00\n",
      "  1.43444914e+00  1.34427994e+00  1.62870999e+00  1.83436764e+00\n",
      "  2.04312894e+00  2.26100014e+00  2.59652104e+00  2.75243234e+00\n",
      "  2.56853793e+00  3.02077869e+00  3.26562778e+00  3.49528531e+00\n",
      "  3.66950437e+00  3.70600681e+00  3.74747258e+00  3.37091313e+00\n",
      "  3.84719148e+00  4.07815581e+00  4.16921715e+00  4.36320156e+00\n",
      "  4.24376758e+00  3.93682036e+00  3.80181787e+00  4.11381637e+00\n",
      "  4.49435905e+00  4.51643643e+00  4.35170423e+00  4.38094389e+00\n",
      "  3.91714297e+00  3.45785303e+00  3.69004877e+00  3.86980917e+00\n",
      "  3.62374124e+00  3.40955169e+00  3.22197563e+00  2.84772821e+00\n",
      "  2.62339840e+00  2.67115943e+00  2.78143324e+00  2.57336304e+00\n",
      "  2.54506579e+00  2.33827726e+00  2.10547838e+00  1.78018570e+00\n",
      "  1.93717761e+00  1.96704553e+00  1.65374023e+00  1.49574308e+00\n",
      "  1.39224201e+00  1.23116634e+00  9.14217082e-01  9.80537182e-01\n",
      "  9.97701498e-01  9.75209459e-01  8.26498132e-01  7.50238812e-01\n",
      "  5.76534935e-01  3.98885526e-01  4.75509242e-01  4.86403430e-01] \n",
      "\n",
      "USA Cases:\n",
      " [-0.75997589 -0.72783707 -0.72070172 -0.71356636 -0.80147986 -0.82067099\n",
      " -0.77961298 -0.7701735  -0.77350333 -0.65841603 -0.70701076 -0.78972139\n",
      " -0.85961812 -0.83074967 -0.78790782 -0.7594556  -0.68835478 -0.76650176\n",
      " -0.82076018 -0.86094114 -0.83889587 -0.8370823  -0.77180868 -0.79049439\n",
      " -0.81857498 -0.90320324 -0.92625935 -0.86679807 -0.88708923 -0.79638106\n",
      " -0.82409001 -0.82230617 -0.90914937 -0.87594024 -0.89541381 -0.85203681\n",
      " -0.81769792 -0.8411554  -0.87924035 -0.88870955 -0.91628472 -0.92501066\n",
      " -0.90959533 -0.86950356 -0.830824   -0.82826717 -0.90078019 -0.89368944\n",
      " -0.88426482 -0.90144913 -0.87772408 -0.75391084 -0.85399903 -0.91995645\n",
      " -0.94803704 -0.93045137 -0.87495913 -0.8683738  -0.81032473 -0.81453161\n",
      " -0.90491275 -0.92017943 -0.84009996 -0.79437424 -0.77996974 -0.72260448\n",
      " -0.70460257 -0.80623676 -0.72828303 -0.65565108 -0.65355507 -0.59613034\n",
      " -0.50893038 -0.57029442 -0.57169176 -0.60494547 -0.49317314 -0.43842417\n",
      " -0.3811035  -0.38822398 -0.48438774 -0.45446385 -0.5134197  -0.31698937\n",
      " -0.3167664  -0.29298188 -0.18737866 -0.2858168  -0.30149971 -0.33971845\n",
      " -0.19490051 -0.18764623 -0.06814393 -0.13497841 -0.22538928 -0.27581244\n",
      " -0.30573633 -0.21534032 -0.15455603 -0.17905408 -0.08816752 -0.22345679\n",
      " -0.33903464 -0.35299318 -0.25339554 -0.17608101 -0.17957436 -0.18039196\n",
      " -0.31313926 -0.50014497 -0.51325619 -0.36904772 -0.38080619 -0.3391833\n",
      " -0.293963   -0.36454353 -0.46485471 -0.51383593 -0.41386666 -0.42003577\n",
      " -0.43353348 -0.22595416 -0.45212999 -0.59214643 -0.67302864 -0.55707915\n",
      " -0.54618287 -0.53492982 -0.4612573  -0.52868639 -0.68056535 -0.67111101\n",
      " -0.59149236 -0.56711324 -0.50959932 -0.50125987 -0.5200645  -0.67913828\n",
      " -0.67826123 -0.54784778 -0.60518332 -0.64667243 -0.43753225 -0.54490445\n",
      " -0.73231153 -0.83312812 -0.81970474 -0.67264214 -0.68130862 -0.48016598\n",
      " -0.56815381 -0.68651148 -0.69813616 -0.61114431 -0.62688669 -0.52181861\n",
      " -0.46341277 -0.55331822 -0.60329542 -0.44203644 -0.59534248 -0.63721808\n",
      " -0.4862013  -0.40622589 -0.51957395 -0.61817561 -0.70894325 -0.537338\n",
      " -0.59629386 -0.51233454 -0.37306136 -0.45553415 -0.66665141 -0.62180275\n",
      " -0.51941043 -0.45291785 -0.31691505 -0.35030256 -0.36901799 -0.50335588\n",
      " -0.57106741 -0.42776573 -0.31678126 -0.22607308 -0.16760778 -0.34411858\n",
      " -0.43895932 -0.19418697 -0.27619894 -0.26690811 -0.06218294  0.04209728\n",
      "  0.04377706 -0.26277556 -0.20129259 -0.03532131 -0.02681834  0.16256582\n",
      "  0.29627937  0.1470167   0.36908971  0.0624033   0.70955011  0.34167806\n",
      "  0.73559415  0.70836089  0.76102871  0.64221022 -0.05515164  0.95655226\n",
      "  1.00366045  1.22716053  1.49434978  1.34547361  0.83779322  1.19264326\n",
      "  1.23701624  1.38107604  1.65226406  1.80131862  1.49158483  0.97580285\n",
      "  1.37682456  1.43854537  1.55110557  0.53024463  1.85035931  1.146204\n",
      "  0.88991103  1.13399957  1.68474479  1.83796163  2.14066413  2.29226065\n",
      "  2.0843097   1.4580784   1.65067347  2.23009389  2.09645467  2.28554153\n",
      "  2.38167555  2.07433507  1.58129703  1.80528766  2.09529517  2.37737947\n",
      "  2.33398761  2.49719395  1.79335081  1.55806254  1.64660038  1.79431705\n",
      "  2.15428076  1.85478917  0.40851253  2.05124923  1.09961609  1.30007492\n",
      "  1.79422786  2.0997845   2.65067837  1.2513464   3.21029818  1.82184763\n",
      "  1.51846133  2.24048475  2.61336642  3.09461626  3.30759169  2.65490012\n",
      "  1.96511957  1.95484764  2.05035731  2.21475288  2.35054757  2.46300371\n",
      "  1.89663505  1.42611796  0.89558958  1.26224268  1.55776523  1.65719935\n",
      "  1.61810356  1.39348859  0.84861517  0.92760948  0.9491196   1.11182052\n",
      "  1.27948645  1.28214734  0.95430759  0.51511174  0.7303021   0.50125726\n",
      "  0.63266668  0.64582249  0.75502312  0.44924351  0.16357667  0.08043494\n",
      "  0.20353464  0.22809215  0.38101169  0.28725612  0.12021453 -0.21117803\n",
      " -0.38688611 -0.31725695 -0.15573039 -0.13668792 -0.03521725 -0.10963304\n",
      " -0.33826165 -0.3770304  -0.12750115 -0.0817011  -0.03737272 -0.0419661\n",
      " -0.21953234 -0.42382642 -0.37283838 -0.35064446 -0.19778438 -0.18227985\n",
      " -0.20185748 -0.32214764 -0.57200393 -0.53259597 -0.36500436 -0.33189929\n",
      " -0.26345936 -0.28091124 -0.4005622  -0.62140138 -0.37560333 -0.38926456\n",
      " -0.31434335 -0.29981993 -0.27554486 -0.3549554  -0.68234919 -0.45181782\n",
      " -0.40328255  0.0948097  -0.18801786 -0.04519188 -0.24798456 -0.54804103\n",
      " -0.18098657 -0.28675332 -0.20322509 -0.02035193 -0.14267864 -0.2489954\n",
      " -0.65914443 -0.08379711 -0.29148049 -0.08192408 -0.00570959  0.05476253\n",
      " -0.17627426 -0.51191831 -0.18233931 -0.03630242 -0.07261839 -0.09722049\n",
      " -0.00398521 -0.40372851 -0.56385773 -0.19854251 -0.29362109 -0.24847512\n",
      " -0.20842795 -0.25917815 -0.39935811 -0.70646074 -0.50573433 -0.44676361\n",
      " -0.37539521 -0.32711266 -0.33305878 -0.50970337 -0.75434193 -0.46035051\n",
      " -0.60084265 -0.52480654 -0.48609725 -0.48978385 -0.68685338 -0.87179282\n",
      " -0.6642135  -0.69733343 -0.66286076 -0.6178783  -0.5781433  -0.76052591\n",
      " -0.94070844 -0.77496013 -0.78902272 -0.76180432 -0.74787552 -0.77794806\n",
      " -0.89299077 -0.99944132 -0.82446164 -0.86049518 -0.83425789 -0.79089575\n",
      " -0.87296718 -1.0113633  -1.09376177 -1.10890953 -0.86791297 -0.9455248\n",
      " -0.9117508  -0.94533155 -0.98408544 -1.11237315 -0.97140532 -1.00550637\n",
      " -0.91570497 -0.9823016  -0.82909962 -1.06756908 -1.12005852 -1.01314714\n",
      " -1.03568297 -1.01017408 -1.03864116 -0.88166339 -1.07058673 -1.13047911\n",
      " -1.02298798 -1.03782357 -1.00358874 -0.99215731] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "india_cases_train, india_cases_test = india_cases_train.to_numpy().flatten(), india_cases_test.to_numpy()\n",
    "usa_cases_train, usa_cases_test = usa_cases_train.to_numpy().flatten(), usa_cases_test.to_numpy()\n",
    "\n",
    "# Visualize outputs\n",
    "print('India Cases:\\n',india_cases_train,'\\n')\n",
    "print('USA Cases:\\n',usa_cases_train,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80961213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate data preparation\n",
    "from numpy import array\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a9fb009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68799512 -0.68799512 -0.68798255] -0.687982551549953\n",
      "[-0.68799512 -0.68798255 -0.68798255] -0.6879951169346211\n",
      "[-0.68798255 -0.68798255 -0.68799512] -0.6879951169346211\n",
      "[-0.68798255 -0.68799512 -0.68799512] -0.6879951169346211\n",
      "[-0.68799512 -0.68799512 -0.68799512] -0.6879951169346211\n",
      "\n",
      "[-0.75997589 -0.72783707 -0.72070172] -0.7135663621434901\n",
      "[-0.72783707 -0.72070172 -0.71356636] -0.8014798602697645\n",
      "[-0.72070172 -0.71356636 -0.80147986] -0.8206709874393655\n",
      "[-0.71356636 -0.80147986 -0.82067099] -0.7796129756326746\n",
      "[-0.80147986 -0.82067099 -0.77961298] -0.7701734979001443\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "india_cases_train_X, india_cases_train_y = split_sequence(india_cases_train, n_steps)\n",
    "india_cases_test_X, india_cases_test_y = split_sequence(india_cases_test, n_steps)\n",
    "usa_cases_train_X, usa_cases_train_y = split_sequence(usa_cases_train, n_steps)\n",
    "usa_cases_test_X, usa_cases_test_y = split_sequence(usa_cases_test, n_steps)\n",
    "\n",
    "# summarize the data\n",
    "for i in range(0,5):\n",
    "    print(india_cases_train_X[i], india_cases_train_y[i])\n",
    "print()\n",
    "# summarize the data\n",
    "for i in range(0,5):\n",
    "    print(usa_cases_train_X[i], usa_cases_train_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f0269a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Cases:\n",
      " [[[-0.68799512]\n",
      "  [-0.68799512]\n",
      "  [-0.68798255]]\n",
      "\n",
      " [[-0.68799512]\n",
      "  [-0.68798255]\n",
      "  [-0.68798255]]\n",
      "\n",
      " [[-0.68798255]\n",
      "  [-0.68798255]\n",
      "  [-0.68799512]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.82649813]\n",
      "  [ 0.75023881]\n",
      "  [ 0.57653493]]\n",
      "\n",
      " [[ 0.75023881]\n",
      "  [ 0.57653493]\n",
      "  [ 0.39888553]]\n",
      "\n",
      " [[ 0.57653493]\n",
      "  [ 0.39888553]\n",
      "  [ 0.47550924]]] \n",
      "\n",
      "USA Cases:\n",
      " [[[-0.75997589]\n",
      "  [-0.72783707]\n",
      "  [-0.72070172]]\n",
      "\n",
      " [[-0.72783707]\n",
      "  [-0.72070172]\n",
      "  [-0.71356636]]\n",
      "\n",
      " [[-0.72070172]\n",
      "  [-0.71356636]\n",
      "  [-0.80147986]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.07058673]\n",
      "  [-1.13047911]\n",
      "  [-1.02298798]]\n",
      "\n",
      " [[-1.13047911]\n",
      "  [-1.02298798]\n",
      "  [-1.03782357]]\n",
      "\n",
      " [[-1.02298798]\n",
      "  [-1.03782357]\n",
      "  [-1.00358874]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data into [samples, timesteps, features]\n",
    "# univariate\n",
    "n_features = 1\n",
    "\n",
    "india_cases_train_X = india_cases_train_X.reshape((india_cases_train_X.shape[0], \n",
    "                                                   india_cases_train_X.shape[1], n_features))\n",
    "india_cases_test_X = india_cases_test_X.reshape((india_cases_test_X.shape[0], \n",
    "                                                 india_cases_test_X.shape[1], n_features))\n",
    "\n",
    "usa_cases_train_X = usa_cases_train_X.reshape((usa_cases_train_X.shape[0], \n",
    "                                                   usa_cases_train_X.shape[1], n_features))\n",
    "usa_cases_test_X = usa_cases_test_X.reshape((usa_cases_test_X.shape[0], \n",
    "                                                   usa_cases_test_X.shape[1], n_features))\n",
    "\n",
    "# Visualize outputs\n",
    "print('India Cases:\\n',india_cases_train_X,'\\n')\n",
    "print('USA Cases:\\n',usa_cases_train_X,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a237a15",
   "metadata": {},
   "source": [
    "<a name=model></a>\n",
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6209e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for model components\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.losses import MeanAbsolutePercentageError, MeanAbsoluteError\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0500ceb",
   "metadata": {},
   "source": [
    "### Univariate non-stacked -- Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a3bf1a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_univariate_non_stacked(optimizer=\"adam\", lstm_nparams=100, n_steps=3, n_features=1):\n",
    "    model_uni = Sequential()\n",
    "    model_uni.add(LSTM(lstm_nparams, activation='relu', input_shape=(n_steps, n_features)))\n",
    "    model_uni.add(Dense(1))\n",
    "    model_uni.compile(optimizer=optimizer,loss='mae', metrics=[\"mae\"])\n",
    "    model_uni.summary()\n",
    "    return model_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95b68f",
   "metadata": {},
   "source": [
    "### Univariate non-stacked -- Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f238b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_univariate_non_stacked_long(optimizer=\"adam\", lstm_nparams=100, n_steps=3, n_features=1):\n",
    "    model_uni = Sequential()\n",
    "    model_uni.add(LSTM(lstm_nparams, activation='relu', input_shape=(n_steps, n_features)))\n",
    "    model_uni.add(Dense(10))\n",
    "    model_uni.compile(optimizer=optimizer,loss='mae', metrics=[\"mae\"])\n",
    "    model_uni.summary()\n",
    "    return model_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3174c71e",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba6dd043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KerasClassifier wrapper \n",
    "keras_estimator = KerasRegressor(build_fn=build_univariate_non_stacked, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e65a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for the gridserach\n",
    "param_grid = {\n",
    "#     'epochs': [10,100,300,],\n",
    "    'lstm_nparams':[15,50],\n",
    "#     'n_steps': [3, 6, 15],\n",
    "#     'optimizer': ['RMSprop','Adam','Adamax','sgd']\n",
    "}\n",
    "\n",
    "kfold_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GridSearch\n",
    "grid = GridSearchCV(estimator=keras_estimator,\n",
    "                    verbose=-1,\n",
    "                    return_train_score=True,\n",
    "                    cv=kfold_splits,\n",
    "                    param_grid=param_grid,\n",
    "#                     scoring=\"neg_mean_absolute_error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc73262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting GridSearch\n",
    "grid_result = grid.fit(india_cases_train_X, india_cases_train_y, )\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the gridsearch results to file\n",
    "file1 = open(\"univariate_non_stacked_india.txt\", \"w\")\n",
    "file1.write(\"mean,stdev,pram\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    file1.write(\"%f,%f,%r\" % (mean, stdev, param))\n",
    "    file1.write(\"\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc006cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(grid_result.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab879991",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.cv_results_['split2_train_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70513f80",
   "metadata": {},
   "source": [
    "### Univariate stacked -- Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fca1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_univariate_stacked(optimizer=\"adam\",lstm_nparams_l1=100, lstm_nparams_l2=150, n_steps=3, n_features=1):\n",
    "    model_uni_stacked = Sequential()\n",
    "    model_uni_stacked.add(LSTM(lstm_nparams_l1, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    model_uni_stacked.add(LSTM(lstm_nparams_l2, activation='relu'))\n",
    "    model_uni_stacked.add(Dense(1))\n",
    "    model_uni_stacked.compile(optimizer=optimizer,loss='mae')\n",
    "    model_uni_stacked.summary()\n",
    "    return model_uni_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bae526",
   "metadata": {},
   "source": [
    "### Univariate stacked -- Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52440f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_univariate_stacked_long(optimizer=\"adam\",lstm_nparams_l1=100, lstm_nparams_l2=150, n_steps=3, n_features=1):\n",
    "    model_uni_stacked = Sequential()\n",
    "    model_uni_stacked.add(LSTM(lstm_nparams_l1, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    model_uni_stacked.add(LSTM(lstm_nparams_l2, activation='relu'))\n",
    "    model_uni_stacked.add(Dense(10))\n",
    "    model_uni_stacked.compile(optimizer=optimizer,loss='mae')\n",
    "    model_uni_stacked.summary()\n",
    "    return model_uni_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31103e54",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d090ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KerasClassifier wrapper \n",
    "keras_estimator = KerasRegressor(build_fn=build_univariate_stacked, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5796d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for the gridserach\n",
    "param_grid = {\n",
    "    'epochs': [10,100,300,],\n",
    "    'lstm_nparams_l1':[15,50,100,150],\n",
    "    'lstm_nparams_l2':[15,50,100,150],\n",
    "    'n_steps': [3, 6, 15],\n",
    "#     'optimizer': ['RMSprop','Adam','Adamax','sgd']\n",
    "}\n",
    "\n",
    "kfold_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac03a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GridSearch\n",
    "grid = GridSearchCV(estimator=keras_estimator,\n",
    "                    verbose=-1,\n",
    "                    return_train_score=True,\n",
    "                    cv=kfold_splits,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring=\"neg_mean_absolute_error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1044188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting GridSearch\n",
    "grid_result = grid.fit(india_cases_train_X, india_cases_train_y, )\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the gridsearch results to file\n",
    "file1 = open(\"univariate_stacked_india.txt\", \"w\")\n",
    "file1.write(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "file1.write(\"\\n\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    file1.write(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    file1.write(\"\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f9fbe",
   "metadata": {},
   "source": [
    "## Multivariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "826f821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 150)               91200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 91,351\n",
      "Trainable params: 91,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model_uni = Sequential()\n",
    "model_uni.add(LSTM(150, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model_uni.add(Dense(1))\n",
    "model_uni.compile(optimizer='adam',loss='mae')\n",
    "model_uni.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8629c",
   "metadata": {},
   "source": [
    "<a name=train></a>\n",
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c1eb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard callback\n",
    "logdir = os.path.join(parentDir+\"/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d35b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a390c1c",
   "metadata": {},
   "source": [
    "### Univariate non-stacked -- Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e165ffb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 41,810\n",
      "Trainable params: 41,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 1s 28ms/step - loss: 0.6689 - mae: 0.6689 - val_loss: 0.1987 - val_mae: 0.1987\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5964 - mae: 0.5964 - val_loss: 0.1539 - val_mae: 0.1539\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4135 - mae: 0.4135 - val_loss: 0.0981 - val_mae: 0.0981\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2050 - mae: 0.2050 - val_loss: 0.0841 - val_mae: 0.0841\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1238 - mae: 0.1238 - val_loss: 0.0877 - val_mae: 0.0877\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1077 - mae: 0.1077 - val_loss: 0.0820 - val_mae: 0.0820\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1037 - mae: 0.1037 - val_loss: 0.0744 - val_mae: 0.0744\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0999 - mae: 0.0999 - val_loss: 0.0810 - val_mae: 0.0810\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0997 - mae: 0.0997 - val_loss: 0.0785 - val_mae: 0.0785\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0976 - mae: 0.0976 - val_loss: 0.0724 - val_mae: 0.0724\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0961 - mae: 0.0961 - val_loss: 0.0750 - val_mae: 0.0750\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0933 - mae: 0.0933 - val_loss: 0.0722 - val_mae: 0.0722\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0921 - mae: 0.0921 - val_loss: 0.0727 - val_mae: 0.0727\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0895 - mae: 0.0895 - val_loss: 0.0734 - val_mae: 0.0734\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0905 - mae: 0.0905 - val_loss: 0.0751 - val_mae: 0.0751\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0889 - mae: 0.0889 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0889 - mae: 0.0889 - val_loss: 0.0706 - val_mae: 0.0706\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0879 - mae: 0.0879 - val_loss: 0.0736 - val_mae: 0.0736\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0888 - mae: 0.0888 - val_loss: 0.0763 - val_mae: 0.0763\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0844 - mae: 0.0844 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0828 - mae: 0.0828 - val_loss: 0.0807 - val_mae: 0.0807\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0840 - mae: 0.0840 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0835 - mae: 0.0835 - val_loss: 0.0741 - val_mae: 0.0741\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0793 - mae: 0.0793 - val_loss: 0.0730 - val_mae: 0.0730\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0799 - mae: 0.0799 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0801 - mae: 0.0801 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0838 - mae: 0.0838 - val_loss: 0.0788 - val_mae: 0.0788\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0850 - mae: 0.0850 - val_loss: 0.0718 - val_mae: 0.0718\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0774 - mae: 0.0774 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0751 - mae: 0.0751 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0768 - mae: 0.0768 - val_loss: 0.0719 - val_mae: 0.0719\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0750 - mae: 0.0750 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0721 - mae: 0.0721 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0727 - mae: 0.0727 - val_loss: 0.0726 - val_mae: 0.0726\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0743 - mae: 0.0743 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0758 - mae: 0.0758 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0753 - mae: 0.0753 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0746 - mae: 0.0746 - val_loss: 0.0704 - val_mae: 0.0704\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0718 - mae: 0.0718 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0714 - mae: 0.0714 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0753 - mae: 0.0753 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0716 - val_mae: 0.0716\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0738 - mae: 0.0738 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0717 - mae: 0.0717 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0709 - mae: 0.0709 - val_loss: 0.0726 - val_mae: 0.0726\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0707 - mae: 0.0707 - val_loss: 0.0725 - val_mae: 0.0725\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0730 - mae: 0.0730 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0745 - mae: 0.0745 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0740 - mae: 0.0740 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0698 - mae: 0.0698 - val_loss: 0.0698 - val_mae: 0.0698\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0721 - mae: 0.0721 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0688 - mae: 0.0688 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0704 - mae: 0.0704 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0711 - mae: 0.0711 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0695 - mae: 0.0695 - val_loss: 0.0699 - val_mae: 0.0699\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0702 - mae: 0.0702 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0701 - mae: 0.0701 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0721 - mae: 0.0721 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0836 - mae: 0.0836 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0849 - mae: 0.0849 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0835 - mae: 0.0835 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0788 - mae: 0.0788 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0705 - mae: 0.0705 - val_loss: 0.0696 - val_mae: 0.0696\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0731 - mae: 0.0731 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0691 - mae: 0.0691 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0692 - mae: 0.0692 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0692 - mae: 0.0692 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0713 - mae: 0.0713 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0722 - mae: 0.0722 - val_loss: 0.0723 - val_mae: 0.0723\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0714 - mae: 0.0714 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0743 - mae: 0.0743 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0717 - mae: 0.0717 - val_loss: 0.0718 - val_mae: 0.0718\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0703 - mae: 0.0703 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0687 - mae: 0.0687 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0694 - mae: 0.0694 - val_loss: 0.0715 - val_mae: 0.0715\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0695 - mae: 0.0695 - val_loss: 0.0697 - val_mae: 0.0697\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0692 - mae: 0.0692 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0685 - mae: 0.0685 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0687 - mae: 0.0687 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0670 - mae: 0.0670 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0729 - val_mae: 0.0729\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0713 - mae: 0.0713 - val_loss: 0.0701 - val_mae: 0.0701\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0698 - mae: 0.0698 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0664 - mae: 0.0664 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0670 - mae: 0.0670 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0685 - mae: 0.0685 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0713 - mae: 0.0713 - val_loss: 0.0701 - val_mae: 0.0701\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0661 - mae: 0.0661 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0663 - mae: 0.0663 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0705 - mae: 0.0705 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0650 - mae: 0.0650 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0717 - mae: 0.0717 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0689 - mae: 0.0689 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0670 - mae: 0.0670 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0722 - mae: 0.0722 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0714 - mae: 0.0714 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0709 - mae: 0.0709 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0694 - mae: 0.0694 - val_loss: 0.0717 - val_mae: 0.0717\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0701 - mae: 0.0701 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0680 - mae: 0.0680 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0716 - mae: 0.0716 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0728 - mae: 0.0728 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0672 - mae: 0.0672 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0684 - mae: 0.0684 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0672 - mae: 0.0672 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0660 - mae: 0.0660 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0713 - mae: 0.0713 - val_loss: 0.0630 - val_mae: 0.0630\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0664 - mae: 0.0664 - val_loss: 0.0724 - val_mae: 0.0724\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0720 - mae: 0.0720 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0654 - mae: 0.0654 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0672 - mae: 0.0672 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0634 - val_mae: 0.0634\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0709 - mae: 0.0709 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0665 - mae: 0.0665 - val_loss: 0.0634 - val_mae: 0.0634\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0677 - mae: 0.0677 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0663 - mae: 0.0663 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0696 - mae: 0.0696 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0670 - mae: 0.0670 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0653 - mae: 0.0653 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0648 - mae: 0.0648 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0683 - mae: 0.0683 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0680 - mae: 0.0680 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0701 - mae: 0.0701 - val_loss: 0.0622 - val_mae: 0.0622\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0730 - mae: 0.0730 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0747 - mae: 0.0747 - val_loss: 0.0696 - val_mae: 0.0696\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0615 - val_mae: 0.0615\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0735 - mae: 0.0735 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0711 - mae: 0.0711 - val_loss: 0.0732 - val_mae: 0.0732\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0740 - mae: 0.0740 - val_loss: 0.0632 - val_mae: 0.0632\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0664 - mae: 0.0664 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0673 - val_mae: 0.0673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0665 - mae: 0.0665 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0665 - mae: 0.0665 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0695 - mae: 0.0695 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0701 - mae: 0.0701 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0661 - mae: 0.0661 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0614 - val_mae: 0.0614\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0691 - mae: 0.0691 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0677 - mae: 0.0677 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0663 - mae: 0.0663 - val_loss: 0.0621 - val_mae: 0.0621\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0650 - mae: 0.0650 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0642 - mae: 0.0642 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0676 - val_mae: 0.0676\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0658 - mae: 0.0658 - val_loss: 0.0621 - val_mae: 0.0621\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0706 - mae: 0.0706 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0704 - val_mae: 0.0704\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0754 - mae: 0.0754 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0670 - mae: 0.0670 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0648 - mae: 0.0648 - val_loss: 0.0643 - val_mae: 0.0643\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0657 - mae: 0.0657 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0638 - mae: 0.0638 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0636 - mae: 0.0636 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0708 - mae: 0.0708 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0630 - mae: 0.0630 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0642 - mae: 0.0642 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0644 - mae: 0.0644 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0643 - mae: 0.0643 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0643 - val_mae: 0.0643\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0658 - mae: 0.0658 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0638 - mae: 0.0638 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0637 - mae: 0.0637 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0653 - mae: 0.0653 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0631 - mae: 0.0631 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0619 - mae: 0.0619 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0622 - mae: 0.0622 - val_loss: 0.0615 - val_mae: 0.0615\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0634 - mae: 0.0634 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0624 - mae: 0.0624 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0634 - val_mae: 0.0634\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0622 - mae: 0.0622 - val_loss: 0.0632 - val_mae: 0.0632\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0620 - val_mae: 0.0620\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0641 - val_mae: 0.0641\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0625 - mae: 0.0625 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0622 - mae: 0.0622 - val_loss: 0.0627 - val_mae: 0.0627\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0632 - mae: 0.0632 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0650 - mae: 0.0650 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0635 - mae: 0.0635 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0638 - mae: 0.0638 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0624 - mae: 0.0624 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0620 - mae: 0.0620 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0614 - mae: 0.0614 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0625 - mae: 0.0625 - val_loss: 0.0628 - val_mae: 0.0628\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0642 - mae: 0.0642 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0612 - val_mae: 0.0612\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0654 - mae: 0.0654 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0696 - mae: 0.0696 - val_loss: 0.0617 - val_mae: 0.0617\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0631 - mae: 0.0631 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0614 - mae: 0.0614 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0664 - mae: 0.0664 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0622 - mae: 0.0622 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0623 - mae: 0.0623 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0653 - mae: 0.0653 - val_loss: 0.0623 - val_mae: 0.0623\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.0610 - val_mae: 0.0610\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0660 - mae: 0.0660 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0630 - mae: 0.0630 - val_loss: 0.0625 - val_mae: 0.0625\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0612 - mae: 0.0612 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0616 - mae: 0.0616 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0599 - mae: 0.0599 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0608 - val_mae: 0.0608\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0643 - mae: 0.0643 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0626 - val_mae: 0.0626\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0635 - mae: 0.0635 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0616 - mae: 0.0616 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0612 - mae: 0.0612 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0614 - mae: 0.0614 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0621 - mae: 0.0621 - val_loss: 0.0619 - val_mae: 0.0619\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0618 - mae: 0.0618 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0621 - mae: 0.0621 - val_loss: 0.0608 - val_mae: 0.0608\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0636 - mae: 0.0636 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.0657 - val_mae: 0.0657\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni_non_stacked_india = build_univariate_non_stacked()\n",
    "model_uni_non_stacked_india.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni_non_stacked_india.save('univar_non_stack_rolling_india.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b66ad93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_20 (LSTM)               (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 41,810\n",
      "Trainable params: 41,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "14/14 [==============================] - 1s 32ms/step - loss: 0.7451 - mae: 0.7451 - val_loss: 0.9488 - val_mae: 0.9488\n",
      "Epoch 2/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6822 - mae: 0.6822 - val_loss: 0.9262 - val_mae: 0.9262\n",
      "Epoch 3/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5778 - mae: 0.5778 - val_loss: 0.8806 - val_mae: 0.8806\n",
      "Epoch 4/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3872 - mae: 0.3872 - val_loss: 0.8315 - val_mae: 0.8315\n",
      "Epoch 5/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2466 - mae: 0.2466 - val_loss: 0.8253 - val_mae: 0.8253\n",
      "Epoch 6/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2113 - mae: 0.2113 - val_loss: 0.7992 - val_mae: 0.7992\n",
      "Epoch 7/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1986 - mae: 0.1986 - val_loss: 0.7805 - val_mae: 0.7805\n",
      "Epoch 8/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1926 - mae: 0.1926 - val_loss: 0.7881 - val_mae: 0.7881\n",
      "Epoch 9/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1914 - mae: 0.1914 - val_loss: 0.7866 - val_mae: 0.7866\n",
      "Epoch 10/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1880 - mae: 0.1880 - val_loss: 0.7839 - val_mae: 0.7839\n",
      "Epoch 11/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1861 - mae: 0.1861 - val_loss: 0.7844 - val_mae: 0.7844\n",
      "Epoch 12/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1881 - mae: 0.1881 - val_loss: 0.7885 - val_mae: 0.7885\n",
      "Epoch 13/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1823 - mae: 0.1823 - val_loss: 0.7862 - val_mae: 0.7862\n",
      "Epoch 14/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1831 - mae: 0.1831 - val_loss: 0.7985 - val_mae: 0.7985\n",
      "Epoch 15/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1838 - mae: 0.1838 - val_loss: 0.7852 - val_mae: 0.7852\n",
      "Epoch 16/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1806 - mae: 0.1806 - val_loss: 0.7913 - val_mae: 0.7913\n",
      "Epoch 17/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1772 - mae: 0.1772 - val_loss: 0.7936 - val_mae: 0.7936\n",
      "Epoch 18/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1762 - mae: 0.1762 - val_loss: 0.7929 - val_mae: 0.7929\n",
      "Epoch 19/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1772 - mae: 0.1772 - val_loss: 0.7942 - val_mae: 0.7942\n",
      "Epoch 20/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1756 - mae: 0.1756 - val_loss: 0.8090 - val_mae: 0.8090\n",
      "Epoch 21/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1739 - mae: 0.1739 - val_loss: 0.8026 - val_mae: 0.8026\n",
      "Epoch 22/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1738 - mae: 0.1738 - val_loss: 0.7930 - val_mae: 0.7930\n",
      "Epoch 23/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1716 - mae: 0.1716 - val_loss: 0.7939 - val_mae: 0.7939\n",
      "Epoch 24/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1710 - mae: 0.1710 - val_loss: 0.8013 - val_mae: 0.8013\n",
      "Epoch 25/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1757 - mae: 0.1757 - val_loss: 0.8022 - val_mae: 0.8022\n",
      "Epoch 26/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1698 - mae: 0.1698 - val_loss: 0.7983 - val_mae: 0.7983\n",
      "Epoch 27/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1672 - mae: 0.1672 - val_loss: 0.7947 - val_mae: 0.7947\n",
      "Epoch 28/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1669 - mae: 0.1669 - val_loss: 0.8055 - val_mae: 0.8055\n",
      "Epoch 29/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.8116 - val_mae: 0.8116\n",
      "Epoch 30/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1695 - mae: 0.1695 - val_loss: 0.7959 - val_mae: 0.7959\n",
      "Epoch 31/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1670 - mae: 0.1670 - val_loss: 0.7958 - val_mae: 0.7958\n",
      "Epoch 32/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1648 - mae: 0.1648 - val_loss: 0.7980 - val_mae: 0.7980\n",
      "Epoch 33/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1644 - mae: 0.1644 - val_loss: 0.8033 - val_mae: 0.8033\n",
      "Epoch 34/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1623 - mae: 0.1623 - val_loss: 0.8024 - val_mae: 0.8024\n",
      "Epoch 35/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1614 - mae: 0.1614 - val_loss: 0.8084 - val_mae: 0.8084\n",
      "Epoch 36/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1619 - mae: 0.1619 - val_loss: 0.8017 - val_mae: 0.8017\n",
      "Epoch 37/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1639 - mae: 0.1639 - val_loss: 0.8044 - val_mae: 0.8044\n",
      "Epoch 38/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1619 - mae: 0.1619 - val_loss: 0.8113 - val_mae: 0.8113\n",
      "Epoch 39/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1629 - mae: 0.1629 - val_loss: 0.8140 - val_mae: 0.8140\n",
      "Epoch 40/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1608 - mae: 0.1608 - val_loss: 0.8178 - val_mae: 0.8178\n",
      "Epoch 41/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1626 - mae: 0.1626 - val_loss: 0.8064 - val_mae: 0.8064\n",
      "Epoch 42/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1592 - mae: 0.1592 - val_loss: 0.8075 - val_mae: 0.8075\n",
      "Epoch 43/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1607 - mae: 0.1607 - val_loss: 0.8093 - val_mae: 0.8093\n",
      "Epoch 44/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1584 - mae: 0.1584 - val_loss: 0.8113 - val_mae: 0.8113\n",
      "Epoch 45/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1594 - mae: 0.1594 - val_loss: 0.8125 - val_mae: 0.8125\n",
      "Epoch 46/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1577 - mae: 0.1577 - val_loss: 0.8109 - val_mae: 0.8109\n",
      "Epoch 47/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1581 - mae: 0.1581 - val_loss: 0.8081 - val_mae: 0.8081\n",
      "Epoch 48/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1578 - mae: 0.1578 - val_loss: 0.8072 - val_mae: 0.8072\n",
      "Epoch 49/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1566 - mae: 0.1566 - val_loss: 0.8074 - val_mae: 0.8074\n",
      "Epoch 50/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1560 - mae: 0.1560 - val_loss: 0.8070 - val_mae: 0.8070\n",
      "Epoch 51/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1558 - mae: 0.1558 - val_loss: 0.8073 - val_mae: 0.8073\n",
      "Epoch 52/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1551 - mae: 0.1551 - val_loss: 0.8141 - val_mae: 0.8141\n",
      "Epoch 53/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1553 - mae: 0.1553 - val_loss: 0.8069 - val_mae: 0.8069\n",
      "Epoch 54/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1551 - mae: 0.1551 - val_loss: 0.8094 - val_mae: 0.8094\n",
      "Epoch 55/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1572 - mae: 0.1572 - val_loss: 0.8109 - val_mae: 0.8109\n",
      "Epoch 56/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1544 - mae: 0.1544 - val_loss: 0.8073 - val_mae: 0.8073\n",
      "Epoch 57/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1534 - mae: 0.1534 - val_loss: 0.8070 - val_mae: 0.8070\n",
      "Epoch 58/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1541 - mae: 0.1541 - val_loss: 0.8070 - val_mae: 0.8070\n",
      "Epoch 59/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1568 - mae: 0.1568 - val_loss: 0.7994 - val_mae: 0.7994\n",
      "Epoch 60/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1513 - mae: 0.1513 - val_loss: 0.8084 - val_mae: 0.8084\n",
      "Epoch 61/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1584 - mae: 0.1584 - val_loss: 0.8006 - val_mae: 0.8006\n",
      "Epoch 62/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1584 - mae: 0.1584 - val_loss: 0.8086 - val_mae: 0.8086\n",
      "Epoch 63/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1573 - mae: 0.1573 - val_loss: 0.8052 - val_mae: 0.8052\n",
      "Epoch 64/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1581 - mae: 0.1581 - val_loss: 0.8025 - val_mae: 0.8025\n",
      "Epoch 65/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1548 - mae: 0.1548 - val_loss: 0.8051 - val_mae: 0.8051\n",
      "Epoch 66/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1550 - mae: 0.1550 - val_loss: 0.8065 - val_mae: 0.8065\n",
      "Epoch 67/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1617 - mae: 0.1617 - val_loss: 0.8167 - val_mae: 0.8167\n",
      "Epoch 68/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1574 - mae: 0.1574 - val_loss: 0.8188 - val_mae: 0.8188\n",
      "Epoch 69/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1626 - mae: 0.1626 - val_loss: 0.8066 - val_mae: 0.8066\n",
      "Epoch 70/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1542 - mae: 0.1542 - val_loss: 0.8016 - val_mae: 0.8016\n",
      "Epoch 71/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1531 - mae: 0.1531 - val_loss: 0.8005 - val_mae: 0.8005\n",
      "Epoch 72/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1535 - mae: 0.1535 - val_loss: 0.8102 - val_mae: 0.8102\n",
      "Epoch 73/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1533 - mae: 0.1533 - val_loss: 0.8061 - val_mae: 0.8061\n",
      "Epoch 74/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1521 - mae: 0.1521 - val_loss: 0.8078 - val_mae: 0.8078\n",
      "Epoch 75/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1542 - mae: 0.1542 - val_loss: 0.8173 - val_mae: 0.8173\n",
      "Epoch 76/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1522 - mae: 0.1522 - val_loss: 0.8057 - val_mae: 0.8057\n",
      "Epoch 77/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1515 - mae: 0.1515 - val_loss: 0.8077 - val_mae: 0.8077\n",
      "Epoch 78/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1524 - mae: 0.1524 - val_loss: 0.8029 - val_mae: 0.8029\n",
      "Epoch 79/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1538 - mae: 0.1538 - val_loss: 0.8054 - val_mae: 0.8054\n",
      "Epoch 80/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1522 - mae: 0.1522 - val_loss: 0.8076 - val_mae: 0.8076\n",
      "Epoch 81/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1531 - mae: 0.1531 - val_loss: 0.8104 - val_mae: 0.8104\n",
      "Epoch 82/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1522 - mae: 0.1522 - val_loss: 0.8068 - val_mae: 0.8068\n",
      "Epoch 83/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1537 - mae: 0.1537 - val_loss: 0.8057 - val_mae: 0.8057\n",
      "Epoch 84/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1530 - mae: 0.1530 - val_loss: 0.8046 - val_mae: 0.8046\n",
      "Epoch 85/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1531 - mae: 0.1531 - val_loss: 0.8063 - val_mae: 0.8063\n",
      "Epoch 86/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1519 - mae: 0.1519 - val_loss: 0.8088 - val_mae: 0.8088\n",
      "Epoch 87/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1487 - mae: 0.1487 - val_loss: 0.8144 - val_mae: 0.8144\n",
      "Epoch 88/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1499 - mae: 0.1499 - val_loss: 0.8137 - val_mae: 0.8137\n",
      "Epoch 89/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1496 - mae: 0.1496 - val_loss: 0.8123 - val_mae: 0.8123\n",
      "Epoch 90/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1492 - mae: 0.1492 - val_loss: 0.8177 - val_mae: 0.8177\n",
      "Epoch 91/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1527 - mae: 0.1527 - val_loss: 0.8209 - val_mae: 0.8209\n",
      "Epoch 92/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1577 - mae: 0.1577 - val_loss: 0.8102 - val_mae: 0.8102\n",
      "Epoch 93/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.8025 - val_mae: 0.8025\n",
      "Epoch 94/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1494 - mae: 0.1494 - val_loss: 0.8149 - val_mae: 0.8149\n",
      "Epoch 95/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1476 - mae: 0.1476 - val_loss: 0.8098 - val_mae: 0.8098\n",
      "Epoch 96/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1480 - mae: 0.1480 - val_loss: 0.8081 - val_mae: 0.8081\n",
      "Epoch 97/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1488 - mae: 0.1488 - val_loss: 0.8151 - val_mae: 0.8151\n",
      "Epoch 98/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1507 - mae: 0.1507 - val_loss: 0.8163 - val_mae: 0.8163\n",
      "Epoch 99/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1526 - mae: 0.1526 - val_loss: 0.8147 - val_mae: 0.8147\n",
      "Epoch 100/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1547 - mae: 0.1547 - val_loss: 0.8300 - val_mae: 0.8300\n",
      "Epoch 101/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1550 - mae: 0.1550 - val_loss: 0.8133 - val_mae: 0.8133\n",
      "Epoch 102/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1512 - mae: 0.1512 - val_loss: 0.8138 - val_mae: 0.8138\n",
      "Epoch 103/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1486 - mae: 0.1486 - val_loss: 0.8199 - val_mae: 0.8199\n",
      "Epoch 104/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1544 - mae: 0.1544 - val_loss: 0.8132 - val_mae: 0.8132\n",
      "Epoch 105/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1488 - mae: 0.1488 - val_loss: 0.8157 - val_mae: 0.8157\n",
      "Epoch 106/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1456 - mae: 0.1456 - val_loss: 0.8087 - val_mae: 0.8087\n",
      "Epoch 107/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1501 - mae: 0.1501 - val_loss: 0.8136 - val_mae: 0.8136\n",
      "Epoch 108/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1477 - mae: 0.1477 - val_loss: 0.8114 - val_mae: 0.8114\n",
      "Epoch 109/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1471 - mae: 0.1471 - val_loss: 0.8091 - val_mae: 0.8091\n",
      "Epoch 110/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1481 - mae: 0.1481 - val_loss: 0.8070 - val_mae: 0.8070\n",
      "Epoch 111/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1497 - mae: 0.1497 - val_loss: 0.8143 - val_mae: 0.8143\n",
      "Epoch 112/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1463 - mae: 0.1463 - val_loss: 0.8081 - val_mae: 0.8081\n",
      "Epoch 113/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1505 - mae: 0.1505 - val_loss: 0.8108 - val_mae: 0.8108\n",
      "Epoch 114/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1480 - mae: 0.1480 - val_loss: 0.8084 - val_mae: 0.8084\n",
      "Epoch 115/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1491 - mae: 0.1491 - val_loss: 0.8060 - val_mae: 0.8060\n",
      "Epoch 116/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1539 - mae: 0.1539 - val_loss: 0.8156 - val_mae: 0.8156\n",
      "Epoch 117/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1462 - mae: 0.1462 - val_loss: 0.8112 - val_mae: 0.8112\n",
      "Epoch 118/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1454 - mae: 0.1454 - val_loss: 0.8094 - val_mae: 0.8094\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1457 - mae: 0.1457 - val_loss: 0.8156 - val_mae: 0.8156\n",
      "Epoch 120/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1456 - mae: 0.1456 - val_loss: 0.8124 - val_mae: 0.8124\n",
      "Epoch 121/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1463 - mae: 0.1463 - val_loss: 0.8104 - val_mae: 0.8104\n",
      "Epoch 122/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1485 - mae: 0.1485 - val_loss: 0.8128 - val_mae: 0.8128\n",
      "Epoch 123/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1471 - mae: 0.1471 - val_loss: 0.8102 - val_mae: 0.8102\n",
      "Epoch 124/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1491 - mae: 0.1491 - val_loss: 0.8086 - val_mae: 0.8086\n",
      "Epoch 125/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1443 - mae: 0.1443 - val_loss: 0.8069 - val_mae: 0.8069\n",
      "Epoch 126/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1448 - mae: 0.1448 - val_loss: 0.8070 - val_mae: 0.8070\n",
      "Epoch 127/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1461 - mae: 0.1461 - val_loss: 0.8084 - val_mae: 0.8084\n",
      "Epoch 128/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1527 - mae: 0.1527 - val_loss: 0.8080 - val_mae: 0.8080\n",
      "Epoch 129/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1459 - mae: 0.1459 - val_loss: 0.8022 - val_mae: 0.8022\n",
      "Epoch 130/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1454 - mae: 0.1454 - val_loss: 0.8086 - val_mae: 0.8086\n",
      "Epoch 131/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1451 - mae: 0.1451 - val_loss: 0.8035 - val_mae: 0.8035\n",
      "Epoch 132/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1437 - mae: 0.1437 - val_loss: 0.8137 - val_mae: 0.8137\n",
      "Epoch 133/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1430 - mae: 0.1430 - val_loss: 0.8002 - val_mae: 0.8002\n",
      "Epoch 134/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1456 - mae: 0.1456 - val_loss: 0.8078 - val_mae: 0.8078\n",
      "Epoch 135/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1433 - mae: 0.1433 - val_loss: 0.8058 - val_mae: 0.8058\n",
      "Epoch 136/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1435 - mae: 0.1435 - val_loss: 0.8060 - val_mae: 0.8060\n",
      "Epoch 137/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1464 - mae: 0.1464 - val_loss: 0.8041 - val_mae: 0.8041\n",
      "Epoch 138/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1453 - mae: 0.1453 - val_loss: 0.8072 - val_mae: 0.8072\n",
      "Epoch 139/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1424 - mae: 0.1424 - val_loss: 0.8072 - val_mae: 0.8072\n",
      "Epoch 140/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1418 - mae: 0.1418 - val_loss: 0.8099 - val_mae: 0.8099\n",
      "Epoch 141/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1436 - mae: 0.1436 - val_loss: 0.8151 - val_mae: 0.8151\n",
      "Epoch 142/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1440 - mae: 0.1440 - val_loss: 0.8106 - val_mae: 0.8106\n",
      "Epoch 143/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1455 - mae: 0.1455 - val_loss: 0.8101 - val_mae: 0.8101\n",
      "Epoch 144/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1454 - mae: 0.1454 - val_loss: 0.8020 - val_mae: 0.8020\n",
      "Epoch 145/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1438 - mae: 0.1438 - val_loss: 0.8043 - val_mae: 0.8043\n",
      "Epoch 146/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1442 - mae: 0.1442 - val_loss: 0.8015 - val_mae: 0.8015\n",
      "Epoch 147/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1428 - mae: 0.1428 - val_loss: 0.8016 - val_mae: 0.8016\n",
      "Epoch 148/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1430 - mae: 0.1430 - val_loss: 0.8141 - val_mae: 0.8141\n",
      "Epoch 149/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1411 - mae: 0.1411 - val_loss: 0.8001 - val_mae: 0.8001\n",
      "Epoch 150/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1460 - mae: 0.1460 - val_loss: 0.8150 - val_mae: 0.8150\n",
      "Epoch 151/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1463 - mae: 0.1463 - val_loss: 0.7888 - val_mae: 0.7888\n",
      "Epoch 152/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1453 - mae: 0.1453 - val_loss: 0.8006 - val_mae: 0.8006\n",
      "Epoch 153/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1420 - mae: 0.1420 - val_loss: 0.7941 - val_mae: 0.7941\n",
      "Epoch 154/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1445 - mae: 0.1445 - val_loss: 0.8060 - val_mae: 0.8060\n",
      "Epoch 155/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1422 - mae: 0.1422 - val_loss: 0.8006 - val_mae: 0.8006\n",
      "Epoch 156/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1413 - mae: 0.1413 - val_loss: 0.8083 - val_mae: 0.8083\n",
      "Epoch 157/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1395 - mae: 0.1395 - val_loss: 0.8053 - val_mae: 0.8053\n",
      "Epoch 158/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1400 - mae: 0.1400 - val_loss: 0.8105 - val_mae: 0.8105\n",
      "Epoch 159/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1444 - mae: 0.1444 - val_loss: 0.7971 - val_mae: 0.7971\n",
      "Epoch 160/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1436 - mae: 0.1436 - val_loss: 0.8006 - val_mae: 0.8006\n",
      "Epoch 161/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1398 - mae: 0.1398 - val_loss: 0.8129 - val_mae: 0.8129\n",
      "Epoch 162/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1435 - mae: 0.1435 - val_loss: 0.8157 - val_mae: 0.8157\n",
      "Epoch 163/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1482 - mae: 0.1482 - val_loss: 0.8112 - val_mae: 0.8112\n",
      "Epoch 164/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1439 - mae: 0.1439 - val_loss: 0.8061 - val_mae: 0.8061\n",
      "Epoch 165/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1402 - mae: 0.1402 - val_loss: 0.8054 - val_mae: 0.8054\n",
      "Epoch 166/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1393 - mae: 0.1393 - val_loss: 0.8114 - val_mae: 0.8114\n",
      "Epoch 167/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1413 - mae: 0.1413 - val_loss: 0.8080 - val_mae: 0.8080\n",
      "Epoch 168/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1399 - mae: 0.1399 - val_loss: 0.8040 - val_mae: 0.8040\n",
      "Epoch 169/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1400 - mae: 0.1400 - val_loss: 0.8079 - val_mae: 0.8079\n",
      "Epoch 170/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1397 - mae: 0.1397 - val_loss: 0.8042 - val_mae: 0.8042\n",
      "Epoch 171/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1414 - mae: 0.1414 - val_loss: 0.8057 - val_mae: 0.8057\n",
      "Epoch 172/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1396 - mae: 0.1396 - val_loss: 0.8058 - val_mae: 0.8058\n",
      "Epoch 173/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1391 - mae: 0.1391 - val_loss: 0.8086 - val_mae: 0.8086\n",
      "Epoch 174/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1401 - mae: 0.1401 - val_loss: 0.8053 - val_mae: 0.8053\n",
      "Epoch 175/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1409 - mae: 0.1409 - val_loss: 0.8035 - val_mae: 0.8035\n",
      "Epoch 176/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1404 - mae: 0.1404 - val_loss: 0.8028 - val_mae: 0.8028\n",
      "Epoch 177/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1407 - mae: 0.1407 - val_loss: 0.7977 - val_mae: 0.7977\n",
      "Epoch 178/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1388 - mae: 0.1388 - val_loss: 0.8008 - val_mae: 0.8008\n",
      "Epoch 179/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1410 - mae: 0.1410 - val_loss: 0.8035 - val_mae: 0.8035\n",
      "Epoch 180/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1375 - mae: 0.1375 - val_loss: 0.8075 - val_mae: 0.8075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1373 - mae: 0.1373 - val_loss: 0.8050 - val_mae: 0.8050\n",
      "Epoch 182/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1382 - mae: 0.1382 - val_loss: 0.8058 - val_mae: 0.8058\n",
      "Epoch 183/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1398 - mae: 0.1398 - val_loss: 0.8005 - val_mae: 0.8005\n",
      "Epoch 184/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1438 - mae: 0.1438 - val_loss: 0.8052 - val_mae: 0.8052\n",
      "Epoch 185/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1502 - mae: 0.1502 - val_loss: 0.7938 - val_mae: 0.7938\n",
      "Epoch 186/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1435 - mae: 0.1435 - val_loss: 0.7860 - val_mae: 0.7860\n",
      "Epoch 187/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1412 - mae: 0.1412 - val_loss: 0.7953 - val_mae: 0.7953\n",
      "Epoch 188/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1375 - mae: 0.1375 - val_loss: 0.8014 - val_mae: 0.8014\n",
      "Epoch 189/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1421 - mae: 0.1421 - val_loss: 0.8023 - val_mae: 0.8023\n",
      "Epoch 190/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1397 - mae: 0.1397 - val_loss: 0.8010 - val_mae: 0.8010\n",
      "Epoch 191/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1363 - mae: 0.1363 - val_loss: 0.8011 - val_mae: 0.8011\n",
      "Epoch 192/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1375 - mae: 0.1375 - val_loss: 0.8029 - val_mae: 0.8029\n",
      "Epoch 193/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1372 - mae: 0.1372 - val_loss: 0.8009 - val_mae: 0.8009\n",
      "Epoch 194/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1371 - mae: 0.1371 - val_loss: 0.8021 - val_mae: 0.8021\n",
      "Epoch 195/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1362 - mae: 0.1362 - val_loss: 0.8067 - val_mae: 0.8067\n",
      "Epoch 196/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1372 - mae: 0.1372 - val_loss: 0.8074 - val_mae: 0.8074\n",
      "Epoch 197/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1360 - mae: 0.1360 - val_loss: 0.8018 - val_mae: 0.8018\n",
      "Epoch 198/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1432 - mae: 0.1432 - val_loss: 0.7996 - val_mae: 0.7996\n",
      "Epoch 199/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1368 - mae: 0.1368 - val_loss: 0.7918 - val_mae: 0.7918\n",
      "Epoch 200/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1377 - mae: 0.1377 - val_loss: 0.7957 - val_mae: 0.7957\n",
      "Epoch 201/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1391 - mae: 0.1391 - val_loss: 0.7952 - val_mae: 0.7952\n",
      "Epoch 202/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1370 - mae: 0.1370 - val_loss: 0.7939 - val_mae: 0.7939\n",
      "Epoch 203/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1376 - mae: 0.1376 - val_loss: 0.7948 - val_mae: 0.7948\n",
      "Epoch 204/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1411 - mae: 0.1411 - val_loss: 0.7988 - val_mae: 0.7988\n",
      "Epoch 205/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1385 - mae: 0.1385 - val_loss: 0.7976 - val_mae: 0.7976\n",
      "Epoch 206/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1358 - mae: 0.1358 - val_loss: 0.8037 - val_mae: 0.8037\n",
      "Epoch 207/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1380 - mae: 0.1380 - val_loss: 0.7922 - val_mae: 0.7922\n",
      "Epoch 208/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1395 - mae: 0.1395 - val_loss: 0.7916 - val_mae: 0.7916\n",
      "Epoch 209/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1352 - mae: 0.1352 - val_loss: 0.8020 - val_mae: 0.8020\n",
      "Epoch 210/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1358 - mae: 0.1358 - val_loss: 0.7931 - val_mae: 0.7931\n",
      "Epoch 211/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1371 - mae: 0.1371 - val_loss: 0.7919 - val_mae: 0.7919\n",
      "Epoch 212/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1364 - mae: 0.1364 - val_loss: 0.7991 - val_mae: 0.7991\n",
      "Epoch 213/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1356 - mae: 0.1356 - val_loss: 0.7964 - val_mae: 0.7964\n",
      "Epoch 214/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1472 - mae: 0.1472 - val_loss: 0.7657 - val_mae: 0.7657\n",
      "Epoch 215/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1402 - mae: 0.1402 - val_loss: 0.7737 - val_mae: 0.7737\n",
      "Epoch 216/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1365 - mae: 0.1365 - val_loss: 0.7829 - val_mae: 0.7829\n",
      "Epoch 217/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1398 - mae: 0.1398 - val_loss: 0.7831 - val_mae: 0.7831\n",
      "Epoch 218/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1369 - mae: 0.1369 - val_loss: 0.7893 - val_mae: 0.7893\n",
      "Epoch 219/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1346 - mae: 0.1346 - val_loss: 0.7954 - val_mae: 0.7954\n",
      "Epoch 220/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1409 - mae: 0.1409 - val_loss: 0.7836 - val_mae: 0.7836\n",
      "Epoch 221/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1390 - mae: 0.1390 - val_loss: 0.7721 - val_mae: 0.7721\n",
      "Epoch 222/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1356 - mae: 0.1356 - val_loss: 0.7848 - val_mae: 0.7848\n",
      "Epoch 223/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1372 - mae: 0.1372 - val_loss: 0.7849 - val_mae: 0.7849\n",
      "Epoch 224/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1352 - mae: 0.1352 - val_loss: 0.7812 - val_mae: 0.7812\n",
      "Epoch 225/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1350 - mae: 0.1350 - val_loss: 0.7876 - val_mae: 0.7876\n",
      "Epoch 226/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1362 - mae: 0.1362 - val_loss: 0.7833 - val_mae: 0.7833\n",
      "Epoch 227/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1346 - mae: 0.1346 - val_loss: 0.7847 - val_mae: 0.7847\n",
      "Epoch 228/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1371 - mae: 0.1371 - val_loss: 0.7836 - val_mae: 0.7836\n",
      "Epoch 229/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1366 - mae: 0.1366 - val_loss: 0.7777 - val_mae: 0.7777\n",
      "Epoch 230/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1326 - mae: 0.1326 - val_loss: 0.7896 - val_mae: 0.7896\n",
      "Epoch 231/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1344 - mae: 0.1344 - val_loss: 0.7839 - val_mae: 0.7839\n",
      "Epoch 232/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1340 - mae: 0.1340 - val_loss: 0.7811 - val_mae: 0.7811\n",
      "Epoch 233/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1362 - mae: 0.1362 - val_loss: 0.7836 - val_mae: 0.7836\n",
      "Epoch 234/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1361 - mae: 0.1361 - val_loss: 0.7826 - val_mae: 0.7826\n",
      "Epoch 235/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1334 - mae: 0.1334 - val_loss: 0.7878 - val_mae: 0.7878\n",
      "Epoch 236/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1337 - mae: 0.1337 - val_loss: 0.7875 - val_mae: 0.7875\n",
      "Epoch 237/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1333 - mae: 0.1333 - val_loss: 0.7824 - val_mae: 0.7824\n",
      "Epoch 238/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1379 - mae: 0.1379 - val_loss: 0.7809 - val_mae: 0.7809\n",
      "Epoch 239/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1381 - mae: 0.1381 - val_loss: 0.7753 - val_mae: 0.7753\n",
      "Epoch 240/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1360 - mae: 0.1360 - val_loss: 0.7694 - val_mae: 0.7694\n",
      "Epoch 241/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1339 - mae: 0.1339 - val_loss: 0.7800 - val_mae: 0.7800\n",
      "Epoch 242/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1373 - mae: 0.1373 - val_loss: 0.7760 - val_mae: 0.7760\n",
      "Epoch 243/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1392 - mae: 0.1392 - val_loss: 0.7560 - val_mae: 0.7560\n",
      "Epoch 244/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1327 - mae: 0.1327 - val_loss: 0.7760 - val_mae: 0.7760\n",
      "Epoch 245/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1343 - mae: 0.1343 - val_loss: 0.7767 - val_mae: 0.7767\n",
      "Epoch 246/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1328 - mae: 0.1328 - val_loss: 0.7720 - val_mae: 0.7720\n",
      "Epoch 247/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1330 - mae: 0.1330 - val_loss: 0.7796 - val_mae: 0.7796\n",
      "Epoch 248/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1323 - mae: 0.1323 - val_loss: 0.7816 - val_mae: 0.7816\n",
      "Epoch 249/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1344 - mae: 0.1344 - val_loss: 0.7691 - val_mae: 0.7691\n",
      "Epoch 250/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1309 - mae: 0.1309 - val_loss: 0.7794 - val_mae: 0.7794\n",
      "Epoch 251/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1325 - mae: 0.1325 - val_loss: 0.7698 - val_mae: 0.7698\n",
      "Epoch 252/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1336 - mae: 0.1336 - val_loss: 0.7776 - val_mae: 0.7776\n",
      "Epoch 253/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1355 - mae: 0.1355 - val_loss: 0.7778 - val_mae: 0.7778\n",
      "Epoch 254/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1369 - mae: 0.1369 - val_loss: 0.7752 - val_mae: 0.7752\n",
      "Epoch 255/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1362 - mae: 0.1362 - val_loss: 0.7586 - val_mae: 0.7586\n",
      "Epoch 256/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1372 - mae: 0.1372 - val_loss: 0.7636 - val_mae: 0.7636\n",
      "Epoch 257/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1375 - mae: 0.1375 - val_loss: 0.7456 - val_mae: 0.7456\n",
      "Epoch 258/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1342 - mae: 0.1342 - val_loss: 0.7589 - val_mae: 0.7589\n",
      "Epoch 259/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1324 - mae: 0.1324 - val_loss: 0.7623 - val_mae: 0.7623\n",
      "Epoch 260/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1328 - mae: 0.1328 - val_loss: 0.7701 - val_mae: 0.7701\n",
      "Epoch 261/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1321 - mae: 0.1321 - val_loss: 0.7627 - val_mae: 0.7627\n",
      "Epoch 262/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1344 - mae: 0.1344 - val_loss: 0.7653 - val_mae: 0.7653\n",
      "Epoch 263/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1319 - mae: 0.1319 - val_loss: 0.7705 - val_mae: 0.7705\n",
      "Epoch 264/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1322 - mae: 0.1322 - val_loss: 0.7614 - val_mae: 0.7614\n",
      "Epoch 265/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1317 - mae: 0.1317 - val_loss: 0.7645 - val_mae: 0.7645\n",
      "Epoch 266/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1330 - mae: 0.1330 - val_loss: 0.7739 - val_mae: 0.7739\n",
      "Epoch 267/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1323 - mae: 0.1323 - val_loss: 0.7639 - val_mae: 0.7639\n",
      "Epoch 268/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1338 - mae: 0.1338 - val_loss: 0.7635 - val_mae: 0.7635\n",
      "Epoch 269/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1337 - mae: 0.1337 - val_loss: 0.7538 - val_mae: 0.7538\n",
      "Epoch 270/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1340 - mae: 0.1340 - val_loss: 0.7473 - val_mae: 0.7473\n",
      "Epoch 271/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1350 - mae: 0.1350 - val_loss: 0.7455 - val_mae: 0.7455\n",
      "Epoch 272/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1320 - mae: 0.1320 - val_loss: 0.7608 - val_mae: 0.7608\n",
      "Epoch 273/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1325 - mae: 0.1325 - val_loss: 0.7649 - val_mae: 0.7649\n",
      "Epoch 274/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1336 - mae: 0.1336 - val_loss: 0.7606 - val_mae: 0.7606\n",
      "Epoch 275/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1320 - mae: 0.1320 - val_loss: 0.7630 - val_mae: 0.7630\n",
      "Epoch 276/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1314 - mae: 0.1314 - val_loss: 0.7654 - val_mae: 0.7654\n",
      "Epoch 277/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1312 - mae: 0.1312 - val_loss: 0.7713 - val_mae: 0.7713\n",
      "Epoch 278/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1328 - mae: 0.1328 - val_loss: 0.7588 - val_mae: 0.7588\n",
      "Epoch 279/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1343 - mae: 0.1343 - val_loss: 0.7618 - val_mae: 0.7618\n",
      "Epoch 280/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1330 - mae: 0.1330 - val_loss: 0.7487 - val_mae: 0.7487\n",
      "Epoch 281/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1316 - mae: 0.1316 - val_loss: 0.7638 - val_mae: 0.7638\n",
      "Epoch 282/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1310 - mae: 0.1310 - val_loss: 0.7609 - val_mae: 0.7609\n",
      "Epoch 283/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1329 - mae: 0.1329 - val_loss: 0.7601 - val_mae: 0.7601\n",
      "Epoch 284/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1348 - mae: 0.1348 - val_loss: 0.7590 - val_mae: 0.7590\n",
      "Epoch 285/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1306 - mae: 0.1306 - val_loss: 0.7605 - val_mae: 0.7605\n",
      "Epoch 286/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1297 - mae: 0.1297 - val_loss: 0.7536 - val_mae: 0.7536\n",
      "Epoch 287/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1313 - mae: 0.1313 - val_loss: 0.7600 - val_mae: 0.7600\n",
      "Epoch 288/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1312 - mae: 0.1312 - val_loss: 0.7548 - val_mae: 0.7548\n",
      "Epoch 289/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1330 - mae: 0.1330 - val_loss: 0.7599 - val_mae: 0.7599\n",
      "Epoch 290/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1308 - mae: 0.1308 - val_loss: 0.7615 - val_mae: 0.7615\n",
      "Epoch 291/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1315 - mae: 0.1315 - val_loss: 0.7592 - val_mae: 0.7592\n",
      "Epoch 292/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1324 - mae: 0.1324 - val_loss: 0.7509 - val_mae: 0.7509\n",
      "Epoch 293/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1341 - mae: 0.1341 - val_loss: 0.7560 - val_mae: 0.7560\n",
      "Epoch 294/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1322 - mae: 0.1322 - val_loss: 0.7659 - val_mae: 0.7659\n",
      "Epoch 295/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1295 - mae: 0.1295 - val_loss: 0.7635 - val_mae: 0.7635\n",
      "Epoch 296/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1348 - mae: 0.1348 - val_loss: 0.7581 - val_mae: 0.7581\n",
      "Epoch 297/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1320 - mae: 0.1320 - val_loss: 0.7450 - val_mae: 0.7450\n",
      "Epoch 298/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1295 - mae: 0.1295 - val_loss: 0.7579 - val_mae: 0.7579\n",
      "Epoch 299/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1298 - mae: 0.1298 - val_loss: 0.7567 - val_mae: 0.7567\n",
      "Epoch 300/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1337 - mae: 0.1337 - val_loss: 0.7630 - val_mae: 0.7630\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni_non_stacked_usa = build_univariate_non_stacked()\n",
    "model_uni_non_stacked_usa.fit(usa_cases_train_X,\n",
    "          usa_cases_train_y, \n",
    "          validation_data=(usa_cases_test_X, usa_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni_non_stacked_usa.save('univar_non_stack_rolling_usa.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ff373",
   "metadata": {},
   "source": [
    "### Univariate non-stacked -- Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a473ca46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 41,810\n",
      "Trainable params: 41,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 1s 28ms/step - loss: 0.6773 - mae: 0.6773 - val_loss: 0.2030 - val_mae: 0.2030\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6114 - mae: 0.6114 - val_loss: 0.1584 - val_mae: 0.1584\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4672 - mae: 0.4672 - val_loss: 0.0957 - val_mae: 0.0957\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2136 - mae: 0.2136 - val_loss: 0.0805 - val_mae: 0.0805\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1245 - mae: 0.1245 - val_loss: 0.0797 - val_mae: 0.0797\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1076 - mae: 0.1076 - val_loss: 0.0817 - val_mae: 0.0817\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1014 - mae: 0.1014 - val_loss: 0.0775 - val_mae: 0.0775\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0966 - mae: 0.0966 - val_loss: 0.0769 - val_mae: 0.0769\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0954 - mae: 0.0954 - val_loss: 0.0742 - val_mae: 0.0742\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0936 - mae: 0.0936 - val_loss: 0.0781 - val_mae: 0.0781\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0936 - mae: 0.0936 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0942 - mae: 0.0942 - val_loss: 0.0774 - val_mae: 0.0774\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.0740 - val_mae: 0.0740\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0913 - mae: 0.0913 - val_loss: 0.0706 - val_mae: 0.0706\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0914 - mae: 0.0914 - val_loss: 0.0759 - val_mae: 0.0759\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0896 - mae: 0.0896 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1008 - mae: 0.1008 - val_loss: 0.0820 - val_mae: 0.0820\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0883 - mae: 0.0883 - val_loss: 0.0697 - val_mae: 0.0697\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0859 - mae: 0.0859 - val_loss: 0.0744 - val_mae: 0.0744\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0914 - mae: 0.0914 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0864 - mae: 0.0864 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0850 - mae: 0.0850 - val_loss: 0.0765 - val_mae: 0.0765\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0837 - mae: 0.0837 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0807 - mae: 0.0807 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0799 - mae: 0.0799 - val_loss: 0.0740 - val_mae: 0.0740\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0798 - mae: 0.0798 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0782 - mae: 0.0782 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0778 - mae: 0.0778 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0759 - mae: 0.0759 - val_loss: 0.0756 - val_mae: 0.0756\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0808 - mae: 0.0808 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0809 - mae: 0.0809 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0761 - mae: 0.0761 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0740 - mae: 0.0740 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0841 - mae: 0.0841 - val_loss: 0.0742 - val_mae: 0.0742\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0751 - mae: 0.0751 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0765 - mae: 0.0765 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0726 - mae: 0.0726 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0798 - mae: 0.0798 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0831 - mae: 0.0831 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0769 - mae: 0.0769 - val_loss: 0.0727 - val_mae: 0.0727\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0768 - mae: 0.0768 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0737 - mae: 0.0737 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0784 - mae: 0.0784 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0805 - mae: 0.0805 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0751 - mae: 0.0751 - val_loss: 0.0729 - val_mae: 0.0729\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0733 - mae: 0.0733 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0716 - mae: 0.0716 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0707 - mae: 0.0707 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0725 - mae: 0.0725 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0701 - mae: 0.0701 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0757 - mae: 0.0757 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0701 - mae: 0.0701 - val_loss: 0.0742 - val_mae: 0.0742\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0743 - mae: 0.0743 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0711 - mae: 0.0711 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0716 - mae: 0.0716 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0709 - mae: 0.0709 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0716 - mae: 0.0716 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0715 - mae: 0.0715 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0692 - mae: 0.0692 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0742 - mae: 0.0742 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0710 - mae: 0.0710 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0683 - mae: 0.0683 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0709 - mae: 0.0709 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0694 - mae: 0.0694 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0698 - mae: 0.0698 - val_loss: 0.0641 - val_mae: 0.0641\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0794 - mae: 0.0794 - val_loss: 0.0714 - val_mae: 0.0714\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0797 - mae: 0.0797 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0852 - mae: 0.0852 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0741 - mae: 0.0741 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0740 - mae: 0.0740 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0730 - mae: 0.0730 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0663 - mae: 0.0663 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0758 - mae: 0.0758 - val_loss: 0.0733 - val_mae: 0.0733\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0698 - mae: 0.0698 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0677 - mae: 0.0677 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0695 - mae: 0.0695 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0712 - mae: 0.0712 - val_loss: 0.0643 - val_mae: 0.0643\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0696 - mae: 0.0696 - val_loss: 0.0706 - val_mae: 0.0706\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0702 - mae: 0.0702 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0722 - mae: 0.0722 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0705 - mae: 0.0705 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0745 - mae: 0.0745 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0751 - mae: 0.0751 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0705 - mae: 0.0705 - val_loss: 0.0708 - val_mae: 0.0708\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0696 - mae: 0.0696 - val_loss: 0.0641 - val_mae: 0.0641\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0702 - mae: 0.0702 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0765 - mae: 0.0765 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0704 - mae: 0.0704 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0688 - mae: 0.0688 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0714 - mae: 0.0714 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0704 - mae: 0.0704 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.0728 - val_mae: 0.0728\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0701 - mae: 0.0701 - val_loss: 0.0699 - val_mae: 0.0699\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0716 - mae: 0.0716 - val_loss: 0.0628 - val_mae: 0.0628\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0702 - mae: 0.0702 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0665 - mae: 0.0665 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0712 - mae: 0.0712 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0684 - mae: 0.0684 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0698 - mae: 0.0698 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0719 - mae: 0.0719 - val_loss: 0.0718 - val_mae: 0.0718\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0704 - mae: 0.0704 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0685 - mae: 0.0685 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0670 - mae: 0.0670 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0685 - mae: 0.0685 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0734 - val_mae: 0.0734\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0705 - mae: 0.0705 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0731 - mae: 0.0731 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0676 - mae: 0.0676 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0668 - mae: 0.0668 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0677 - mae: 0.0677 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0680 - mae: 0.0680 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0694 - mae: 0.0694 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0729 - mae: 0.0729 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0672 - mae: 0.0672 - val_loss: 0.0722 - val_mae: 0.0722\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0726 - mae: 0.0726 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0664 - mae: 0.0664 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0650 - mae: 0.0650 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0677 - mae: 0.0677 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0660 - mae: 0.0660 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0734 - mae: 0.0734 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0634 - val_mae: 0.0634\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0660 - mae: 0.0660 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0665 - mae: 0.0665 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0661 - mae: 0.0661 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0654 - mae: 0.0654 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0685 - mae: 0.0685 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0663 - mae: 0.0663 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0687 - mae: 0.0687 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0670 - mae: 0.0670 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.0709 - val_mae: 0.0709\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0678 - mae: 0.0678 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0665 - val_mae: 0.0665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0654 - mae: 0.0654 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0687 - mae: 0.0687 - val_loss: 0.0641 - val_mae: 0.0641\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0676 - mae: 0.0676 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0652 - mae: 0.0652 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0693 - mae: 0.0693 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0648 - mae: 0.0648 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0706 - mae: 0.0706 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0644 - val_mae: 0.0644\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0702 - mae: 0.0702 - val_loss: 0.0698 - val_mae: 0.0698\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0681 - mae: 0.0681 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0657 - mae: 0.0657 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0657 - mae: 0.0657 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0762 - mae: 0.0762 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0685 - mae: 0.0685 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0625 - val_mae: 0.0625\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0641 - val_mae: 0.0641\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0657 - mae: 0.0657 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0665 - mae: 0.0665 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0680 - mae: 0.0680 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0664 - mae: 0.0664 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0689 - mae: 0.0689 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0644 - mae: 0.0644 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0642 - mae: 0.0642 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0635 - mae: 0.0635 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0643 - mae: 0.0643 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0677 - mae: 0.0677 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0653 - mae: 0.0653 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0670 - mae: 0.0670 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0653 - mae: 0.0653 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0634 - mae: 0.0634 - val_loss: 0.0643 - val_mae: 0.0643\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0653 - mae: 0.0653 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0632 - mae: 0.0632 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0674 - mae: 0.0674 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0642 - mae: 0.0642 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0618 - val_mae: 0.0618\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0689 - mae: 0.0689 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0672 - mae: 0.0672 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0661 - mae: 0.0661 - val_loss: 0.0626 - val_mae: 0.0626\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0696 - mae: 0.0696 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0648 - mae: 0.0648 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0639 - mae: 0.0639 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.0647 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0665 - mae: 0.0665 - val_loss: 0.0627 - val_mae: 0.0627\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0679 - mae: 0.0679 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0632 - mae: 0.0632 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0641 - mae: 0.0641 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0648 - mae: 0.0648 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0675 - mae: 0.0675 - val_loss: 0.0624 - val_mae: 0.0624\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.0686 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0685 - mae: 0.0685 - val_loss: 0.0696 - val_mae: 0.0696\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0676 - val_mae: 0.0676\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0706 - mae: 0.0706 - val_loss: 0.0606 - val_mae: 0.0606\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0642 - mae: 0.0642 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0632 - mae: 0.0632 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0632 - mae: 0.0632 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0634 - mae: 0.0634 - val_loss: 0.0621 - val_mae: 0.0621\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0637 - mae: 0.0637 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0638 - mae: 0.0638 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0645 - mae: 0.0645 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0638 - mae: 0.0638 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.0659 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0628 - mae: 0.0628 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0636 - mae: 0.0636 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0630 - mae: 0.0630 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0631 - mae: 0.0631 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0625 - mae: 0.0625 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0699 - mae: 0.0699 - val_loss: 0.0634 - val_mae: 0.0634\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0694 - mae: 0.0694 - val_loss: 0.0632 - val_mae: 0.0632\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0658 - mae: 0.0658 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0648 - mae: 0.0648 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0656 - mae: 0.0656 - val_loss: 0.0612 - val_mae: 0.0612\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0701 - mae: 0.0701 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.0673 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0626 - mae: 0.0626 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0676 - mae: 0.0676 - val_loss: 0.0704 - val_mae: 0.0704\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0676 - mae: 0.0676 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0617 - mae: 0.0617 - val_loss: 0.0674 - val_mae: 0.0674\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni_non_stacked_long_india = build_univariate_non_stacked_long()\n",
    "model_uni_non_stacked_long_india.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni_non_stacked_long_india.save('univar_non_stacked_long_term_india.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0ce2e35e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 41,810\n",
      "Trainable params: 41,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.1251 - mae: 0.1251 - val_loss: 0.7980 - val_mae: 0.7980\n",
      "Epoch 2/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1273 - mae: 0.1273 - val_loss: 0.8031 - val_mae: 0.8031\n",
      "Epoch 3/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1269 - mae: 0.1269 - val_loss: 0.8008 - val_mae: 0.8008\n",
      "Epoch 4/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1283 - mae: 0.1283 - val_loss: 0.8030 - val_mae: 0.8030\n",
      "Epoch 5/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1282 - mae: 0.1282 - val_loss: 0.7913 - val_mae: 0.7913\n",
      "Epoch 6/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1344 - mae: 0.1344 - val_loss: 0.7796 - val_mae: 0.7796\n",
      "Epoch 7/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1296 - mae: 0.1296 - val_loss: 0.7871 - val_mae: 0.7871\n",
      "Epoch 8/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1258 - mae: 0.1258 - val_loss: 0.7913 - val_mae: 0.7913\n",
      "Epoch 9/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1264 - mae: 0.1264 - val_loss: 0.8028 - val_mae: 0.8028\n",
      "Epoch 10/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1272 - mae: 0.1272 - val_loss: 0.8017 - val_mae: 0.8017\n",
      "Epoch 11/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1278 - mae: 0.1278 - val_loss: 0.7816 - val_mae: 0.7816\n",
      "Epoch 12/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1253 - mae: 0.1253 - val_loss: 0.7940 - val_mae: 0.7940\n",
      "Epoch 13/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.8053 - val_mae: 0.8053\n",
      "Epoch 14/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1255 - mae: 0.1255 - val_loss: 0.7849 - val_mae: 0.7849\n",
      "Epoch 15/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1275 - mae: 0.1275 - val_loss: 0.7879 - val_mae: 0.7879\n",
      "Epoch 16/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1241 - mae: 0.1241 - val_loss: 0.7881 - val_mae: 0.7881\n",
      "Epoch 17/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1271 - mae: 0.1271 - val_loss: 0.8054 - val_mae: 0.8054\n",
      "Epoch 18/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1251 - mae: 0.1251 - val_loss: 0.7970 - val_mae: 0.7970\n",
      "Epoch 19/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1267 - mae: 0.1267 - val_loss: 0.7913 - val_mae: 0.7913\n",
      "Epoch 20/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1232 - mae: 0.1232 - val_loss: 0.7967 - val_mae: 0.7967\n",
      "Epoch 21/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1248 - mae: 0.1248 - val_loss: 0.7998 - val_mae: 0.7998\n",
      "Epoch 22/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1257 - mae: 0.1257 - val_loss: 0.7890 - val_mae: 0.7890\n",
      "Epoch 23/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1241 - mae: 0.1241 - val_loss: 0.8033 - val_mae: 0.8033\n",
      "Epoch 24/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1261 - mae: 0.1261 - val_loss: 0.8025 - val_mae: 0.8025\n",
      "Epoch 25/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1280 - mae: 0.1280 - val_loss: 0.7972 - val_mae: 0.7972\n",
      "Epoch 26/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1242 - mae: 0.1242 - val_loss: 0.8039 - val_mae: 0.8039\n",
      "Epoch 27/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1230 - mae: 0.1230 - val_loss: 0.8047 - val_mae: 0.8047\n",
      "Epoch 28/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1251 - mae: 0.1251 - val_loss: 0.8106 - val_mae: 0.8106\n",
      "Epoch 29/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1279 - mae: 0.1279 - val_loss: 0.8006 - val_mae: 0.8006\n",
      "Epoch 30/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1259 - mae: 0.1259 - val_loss: 0.8032 - val_mae: 0.8032\n",
      "Epoch 31/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1220 - mae: 0.1220 - val_loss: 0.8018 - val_mae: 0.8018\n",
      "Epoch 32/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1223 - mae: 0.1223 - val_loss: 0.8098 - val_mae: 0.8098\n",
      "Epoch 33/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1228 - mae: 0.1228 - val_loss: 0.8126 - val_mae: 0.8126\n",
      "Epoch 34/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1270 - mae: 0.1270 - val_loss: 0.7958 - val_mae: 0.7958\n",
      "Epoch 35/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1266 - mae: 0.1266 - val_loss: 0.8032 - val_mae: 0.8032\n",
      "Epoch 36/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1254 - mae: 0.1254 - val_loss: 0.8132 - val_mae: 0.8132\n",
      "Epoch 37/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1255 - mae: 0.1255 - val_loss: 0.8033 - val_mae: 0.8033\n",
      "Epoch 38/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1239 - mae: 0.1239 - val_loss: 0.8044 - val_mae: 0.8044\n",
      "Epoch 39/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1265 - mae: 0.1265 - val_loss: 0.7977 - val_mae: 0.7977\n",
      "Epoch 40/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1254 - mae: 0.1254 - val_loss: 0.8054 - val_mae: 0.8054\n",
      "Epoch 41/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1225 - mae: 0.1225 - val_loss: 0.8090 - val_mae: 0.8090\n",
      "Epoch 42/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1254 - mae: 0.1254 - val_loss: 0.8108 - val_mae: 0.8108\n",
      "Epoch 43/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1211 - mae: 0.1211 - val_loss: 0.8033 - val_mae: 0.8033\n",
      "Epoch 44/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1217 - mae: 0.1217 - val_loss: 0.8070 - val_mae: 0.8070\n",
      "Epoch 45/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.8092 - val_mae: 0.8092\n",
      "Epoch 46/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1205 - mae: 0.1205 - val_loss: 0.8135 - val_mae: 0.8135\n",
      "Epoch 47/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1220 - mae: 0.1220 - val_loss: 0.8153 - val_mae: 0.8153\n",
      "Epoch 48/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1225 - mae: 0.1225 - val_loss: 0.8125 - val_mae: 0.8125\n",
      "Epoch 49/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1236 - mae: 0.1236 - val_loss: 0.8036 - val_mae: 0.8036\n",
      "Epoch 50/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1203 - mae: 0.1203 - val_loss: 0.8098 - val_mae: 0.8098\n",
      "Epoch 51/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1223 - mae: 0.1223 - val_loss: 0.8151 - val_mae: 0.8151\n",
      "Epoch 52/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1250 - mae: 0.1250 - val_loss: 0.8071 - val_mae: 0.8071\n",
      "Epoch 53/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1249 - mae: 0.1249 - val_loss: 0.7974 - val_mae: 0.7974\n",
      "Epoch 54/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1219 - mae: 0.1219 - val_loss: 0.8090 - val_mae: 0.8090\n",
      "Epoch 55/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1206 - mae: 0.1206 - val_loss: 0.8174 - val_mae: 0.8174\n",
      "Epoch 56/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1211 - mae: 0.1211 - val_loss: 0.8190 - val_mae: 0.8190\n",
      "Epoch 57/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1202 - mae: 0.1202 - val_loss: 0.8170 - val_mae: 0.8170\n",
      "Epoch 58/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1212 - mae: 0.1212 - val_loss: 0.8141 - val_mae: 0.8141\n",
      "Epoch 59/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1207 - mae: 0.1207 - val_loss: 0.8197 - val_mae: 0.8197\n",
      "Epoch 60/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1223 - mae: 0.1223 - val_loss: 0.8252 - val_mae: 0.8252\n",
      "Epoch 61/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1235 - mae: 0.1235 - val_loss: 0.8163 - val_mae: 0.8163\n",
      "Epoch 62/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1250 - mae: 0.1250 - val_loss: 0.8061 - val_mae: 0.8061\n",
      "Epoch 63/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1241 - mae: 0.1241 - val_loss: 0.8147 - val_mae: 0.8147\n",
      "Epoch 64/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1202 - mae: 0.1202 - val_loss: 0.8202 - val_mae: 0.8202\n",
      "Epoch 65/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1201 - mae: 0.1201 - val_loss: 0.8140 - val_mae: 0.8140\n",
      "Epoch 66/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1201 - mae: 0.1201 - val_loss: 0.8252 - val_mae: 0.8252\n",
      "Epoch 67/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1222 - mae: 0.1222 - val_loss: 0.8264 - val_mae: 0.8264\n",
      "Epoch 68/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1225 - mae: 0.1225 - val_loss: 0.8125 - val_mae: 0.8125\n",
      "Epoch 69/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1215 - mae: 0.1215 - val_loss: 0.8276 - val_mae: 0.8276\n",
      "Epoch 70/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1231 - mae: 0.1231 - val_loss: 0.8216 - val_mae: 0.8216\n",
      "Epoch 71/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1190 - mae: 0.1190 - val_loss: 0.8161 - val_mae: 0.8161\n",
      "Epoch 72/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1242 - mae: 0.1242 - val_loss: 0.8213 - val_mae: 0.8213\n",
      "Epoch 73/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1229 - mae: 0.1229 - val_loss: 0.8173 - val_mae: 0.8173\n",
      "Epoch 74/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1221 - mae: 0.1221 - val_loss: 0.8107 - val_mae: 0.8107\n",
      "Epoch 75/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1215 - mae: 0.1215 - val_loss: 0.8233 - val_mae: 0.8233\n",
      "Epoch 76/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1208 - mae: 0.1208 - val_loss: 0.8163 - val_mae: 0.8163\n",
      "Epoch 77/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1213 - mae: 0.1213 - val_loss: 0.8239 - val_mae: 0.8239\n",
      "Epoch 78/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1243 - mae: 0.1243 - val_loss: 0.8226 - val_mae: 0.8226\n",
      "Epoch 79/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1254 - mae: 0.1254 - val_loss: 0.8019 - val_mae: 0.8019\n",
      "Epoch 80/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1292 - mae: 0.1292 - val_loss: 0.8137 - val_mae: 0.8137\n",
      "Epoch 81/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1266 - mae: 0.1266 - val_loss: 0.8262 - val_mae: 0.8262\n",
      "Epoch 82/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1298 - mae: 0.1298 - val_loss: 0.8202 - val_mae: 0.8202\n",
      "Epoch 83/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1310 - mae: 0.1310 - val_loss: 0.8098 - val_mae: 0.8098\n",
      "Epoch 84/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1267 - mae: 0.1267 - val_loss: 0.8114 - val_mae: 0.8114\n",
      "Epoch 85/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1197 - mae: 0.1197 - val_loss: 0.8294 - val_mae: 0.8294\n",
      "Epoch 86/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1197 - mae: 0.1197 - val_loss: 0.8301 - val_mae: 0.8301\n",
      "Epoch 87/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1227 - mae: 0.1227 - val_loss: 0.8198 - val_mae: 0.8198\n",
      "Epoch 88/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1190 - mae: 0.1190 - val_loss: 0.8382 - val_mae: 0.8382\n",
      "Epoch 89/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1196 - mae: 0.1196 - val_loss: 0.8325 - val_mae: 0.8325\n",
      "Epoch 90/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1205 - mae: 0.1205 - val_loss: 0.8305 - val_mae: 0.8305\n",
      "Epoch 91/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1199 - mae: 0.1199 - val_loss: 0.8382 - val_mae: 0.8382\n",
      "Epoch 92/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1198 - mae: 0.1198 - val_loss: 0.8311 - val_mae: 0.8311\n",
      "Epoch 93/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1211 - mae: 0.1211 - val_loss: 0.8413 - val_mae: 0.8413\n",
      "Epoch 94/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1233 - mae: 0.1233 - val_loss: 0.8342 - val_mae: 0.8342\n",
      "Epoch 95/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1184 - mae: 0.1184 - val_loss: 0.8314 - val_mae: 0.8314\n",
      "Epoch 96/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1190 - mae: 0.1190 - val_loss: 0.8317 - val_mae: 0.8317\n",
      "Epoch 97/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1189 - mae: 0.1189 - val_loss: 0.8360 - val_mae: 0.8360\n",
      "Epoch 98/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1174 - mae: 0.1174 - val_loss: 0.8377 - val_mae: 0.8377\n",
      "Epoch 99/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1209 - mae: 0.1209 - val_loss: 0.8361 - val_mae: 0.8361\n",
      "Epoch 100/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1184 - mae: 0.1184 - val_loss: 0.8385 - val_mae: 0.8385\n",
      "Epoch 101/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1181 - mae: 0.1181 - val_loss: 0.8390 - val_mae: 0.8390\n",
      "Epoch 102/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1204 - mae: 0.1204 - val_loss: 0.8362 - val_mae: 0.8362\n",
      "Epoch 103/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1194 - mae: 0.1194 - val_loss: 0.8255 - val_mae: 0.8255\n",
      "Epoch 104/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1193 - mae: 0.1193 - val_loss: 0.8416 - val_mae: 0.8416\n",
      "Epoch 105/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1172 - mae: 0.1172 - val_loss: 0.8375 - val_mae: 0.8375\n",
      "Epoch 106/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1185 - mae: 0.1185 - val_loss: 0.8411 - val_mae: 0.8411\n",
      "Epoch 107/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1176 - mae: 0.1176 - val_loss: 0.8359 - val_mae: 0.8359\n",
      "Epoch 108/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1181 - mae: 0.1181 - val_loss: 0.8367 - val_mae: 0.8367\n",
      "Epoch 109/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1181 - mae: 0.1181 - val_loss: 0.8403 - val_mae: 0.8403\n",
      "Epoch 110/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1198 - mae: 0.1198 - val_loss: 0.8321 - val_mae: 0.8321\n",
      "Epoch 111/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1190 - mae: 0.1190 - val_loss: 0.8419 - val_mae: 0.8419\n",
      "Epoch 112/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1169 - mae: 0.1169 - val_loss: 0.8567 - val_mae: 0.8567\n",
      "Epoch 113/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1182 - mae: 0.1182 - val_loss: 0.8443 - val_mae: 0.8443\n",
      "Epoch 114/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1166 - mae: 0.1166 - val_loss: 0.8545 - val_mae: 0.8545\n",
      "Epoch 115/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1162 - mae: 0.1162 - val_loss: 0.8510 - val_mae: 0.8510\n",
      "Epoch 116/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1186 - mae: 0.1186 - val_loss: 0.8493 - val_mae: 0.8493\n",
      "Epoch 117/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1178 - mae: 0.1178 - val_loss: 0.8361 - val_mae: 0.8361\n",
      "Epoch 118/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1172 - mae: 0.1172 - val_loss: 0.8607 - val_mae: 0.8607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1250 - mae: 0.1250 - val_loss: 0.8412 - val_mae: 0.8412\n",
      "Epoch 120/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.8273 - val_mae: 0.8273\n",
      "Epoch 121/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1210 - mae: 0.1210 - val_loss: 0.8470 - val_mae: 0.8470\n",
      "Epoch 122/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1183 - mae: 0.1183 - val_loss: 0.8594 - val_mae: 0.8594\n",
      "Epoch 123/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.8404 - val_mae: 0.8404\n",
      "Epoch 124/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1197 - mae: 0.1197 - val_loss: 0.8516 - val_mae: 0.8516\n",
      "Epoch 125/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1164 - mae: 0.1164 - val_loss: 0.8557 - val_mae: 0.8557\n",
      "Epoch 126/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1180 - mae: 0.1180 - val_loss: 0.8621 - val_mae: 0.8621\n",
      "Epoch 127/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1161 - mae: 0.1161 - val_loss: 0.8538 - val_mae: 0.8538\n",
      "Epoch 128/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1154 - mae: 0.1154 - val_loss: 0.8604 - val_mae: 0.8604\n",
      "Epoch 129/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1175 - mae: 0.1175 - val_loss: 0.8616 - val_mae: 0.8616\n",
      "Epoch 130/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1168 - mae: 0.1168 - val_loss: 0.8640 - val_mae: 0.8640\n",
      "Epoch 131/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1149 - mae: 0.1149 - val_loss: 0.8621 - val_mae: 0.8621\n",
      "Epoch 132/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1155 - mae: 0.1155 - val_loss: 0.8736 - val_mae: 0.8736\n",
      "Epoch 133/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1158 - mae: 0.1158 - val_loss: 0.8683 - val_mae: 0.8683\n",
      "Epoch 134/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1172 - mae: 0.1172 - val_loss: 0.8589 - val_mae: 0.8589\n",
      "Epoch 135/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1183 - mae: 0.1183 - val_loss: 0.8767 - val_mae: 0.8767\n",
      "Epoch 136/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1174 - mae: 0.1174 - val_loss: 0.8692 - val_mae: 0.8692\n",
      "Epoch 137/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1197 - mae: 0.1197 - val_loss: 0.8440 - val_mae: 0.8440\n",
      "Epoch 138/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1170 - mae: 0.1170 - val_loss: 0.8707 - val_mae: 0.8707\n",
      "Epoch 139/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1155 - mae: 0.1155 - val_loss: 0.8704 - val_mae: 0.8704\n",
      "Epoch 140/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1161 - mae: 0.1161 - val_loss: 0.8719 - val_mae: 0.8719\n",
      "Epoch 141/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1197 - mae: 0.1197 - val_loss: 0.8663 - val_mae: 0.8663\n",
      "Epoch 142/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1169 - mae: 0.1169 - val_loss: 0.8776 - val_mae: 0.8776\n",
      "Epoch 143/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1183 - mae: 0.1183 - val_loss: 0.8698 - val_mae: 0.8698\n",
      "Epoch 144/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1194 - mae: 0.1194 - val_loss: 0.8587 - val_mae: 0.8587\n",
      "Epoch 145/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1169 - mae: 0.1169 - val_loss: 0.8784 - val_mae: 0.8784\n",
      "Epoch 146/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1201 - mae: 0.1201 - val_loss: 0.8749 - val_mae: 0.8749\n",
      "Epoch 147/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1190 - mae: 0.1190 - val_loss: 0.8680 - val_mae: 0.8680\n",
      "Epoch 148/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1197 - mae: 0.1197 - val_loss: 0.8769 - val_mae: 0.8769\n",
      "Epoch 149/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1172 - mae: 0.1172 - val_loss: 0.8748 - val_mae: 0.8748\n",
      "Epoch 150/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1160 - mae: 0.1160 - val_loss: 0.8809 - val_mae: 0.8809\n",
      "Epoch 151/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1160 - mae: 0.1160 - val_loss: 0.8780 - val_mae: 0.8780\n",
      "Epoch 152/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1156 - mae: 0.1156 - val_loss: 0.8761 - val_mae: 0.8761\n",
      "Epoch 153/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1162 - mae: 0.1162 - val_loss: 0.8836 - val_mae: 0.8836\n",
      "Epoch 154/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1176 - mae: 0.1176 - val_loss: 0.8723 - val_mae: 0.8723\n",
      "Epoch 155/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1169 - mae: 0.1169 - val_loss: 0.8771 - val_mae: 0.8771\n",
      "Epoch 156/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1147 - mae: 0.1147 - val_loss: 0.8866 - val_mae: 0.8866\n",
      "Epoch 157/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1173 - mae: 0.1173 - val_loss: 0.8902 - val_mae: 0.8902\n",
      "Epoch 158/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1142 - mae: 0.1142 - val_loss: 0.8820 - val_mae: 0.8820\n",
      "Epoch 159/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1156 - mae: 0.1156 - val_loss: 0.8883 - val_mae: 0.8883\n",
      "Epoch 160/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1159 - mae: 0.1159 - val_loss: 0.8861 - val_mae: 0.8861\n",
      "Epoch 161/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1181 - mae: 0.1181 - val_loss: 0.8721 - val_mae: 0.8721\n",
      "Epoch 162/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1144 - mae: 0.1144 - val_loss: 0.8902 - val_mae: 0.8902\n",
      "Epoch 163/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1140 - mae: 0.1140 - val_loss: 0.8870 - val_mae: 0.8870\n",
      "Epoch 164/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1159 - mae: 0.1159 - val_loss: 0.8874 - val_mae: 0.8874\n",
      "Epoch 165/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1140 - mae: 0.1140 - val_loss: 0.8898 - val_mae: 0.8898\n",
      "Epoch 166/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1149 - mae: 0.1149 - val_loss: 0.8869 - val_mae: 0.8869\n",
      "Epoch 167/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1139 - mae: 0.1139 - val_loss: 0.8937 - val_mae: 0.8937\n",
      "Epoch 168/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1160 - mae: 0.1160 - val_loss: 0.8943 - val_mae: 0.8943\n",
      "Epoch 169/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1183 - mae: 0.1183 - val_loss: 0.8609 - val_mae: 0.8609\n",
      "Epoch 170/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1198 - mae: 0.1198 - val_loss: 0.8768 - val_mae: 0.8768\n",
      "Epoch 171/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1164 - mae: 0.1164 - val_loss: 0.8916 - val_mae: 0.8916\n",
      "Epoch 172/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1155 - mae: 0.1155 - val_loss: 0.8969 - val_mae: 0.8969\n",
      "Epoch 173/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1150 - mae: 0.1150 - val_loss: 0.9045 - val_mae: 0.9045\n",
      "Epoch 174/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1127 - mae: 0.1127 - val_loss: 0.9029 - val_mae: 0.9029\n",
      "Epoch 175/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1150 - mae: 0.1150 - val_loss: 0.9043 - val_mae: 0.9043\n",
      "Epoch 176/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1188 - mae: 0.1188 - val_loss: 0.8852 - val_mae: 0.8852\n",
      "Epoch 177/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1134 - mae: 0.1134 - val_loss: 0.9161 - val_mae: 0.9161\n",
      "Epoch 178/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1151 - mae: 0.1151 - val_loss: 0.8923 - val_mae: 0.8923\n",
      "Epoch 179/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1168 - mae: 0.1168 - val_loss: 0.9001 - val_mae: 0.9001\n",
      "Epoch 180/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1143 - mae: 0.1143 - val_loss: 0.9069 - val_mae: 0.9069\n",
      "Epoch 181/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1152 - mae: 0.1152 - val_loss: 0.8976 - val_mae: 0.8976\n",
      "Epoch 182/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1145 - mae: 0.1145 - val_loss: 0.9112 - val_mae: 0.9112\n",
      "Epoch 183/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1147 - mae: 0.1147 - val_loss: 0.9037 - val_mae: 0.9037\n",
      "Epoch 184/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1151 - mae: 0.1151 - val_loss: 0.8883 - val_mae: 0.8883\n",
      "Epoch 185/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1122 - mae: 0.1122 - val_loss: 0.9118 - val_mae: 0.9118\n",
      "Epoch 186/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1194 - mae: 0.1194 - val_loss: 0.9062 - val_mae: 0.9062\n",
      "Epoch 187/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1139 - mae: 0.1139 - val_loss: 0.8975 - val_mae: 0.8975\n",
      "Epoch 188/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1147 - mae: 0.1147 - val_loss: 0.9208 - val_mae: 0.9208\n",
      "Epoch 189/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1159 - mae: 0.1159 - val_loss: 0.9069 - val_mae: 0.9069\n",
      "Epoch 190/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1138 - mae: 0.1138 - val_loss: 0.9051 - val_mae: 0.9051\n",
      "Epoch 191/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1163 - mae: 0.1163 - val_loss: 0.9127 - val_mae: 0.9127\n",
      "Epoch 192/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1145 - mae: 0.1145 - val_loss: 0.9086 - val_mae: 0.9086\n",
      "Epoch 193/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1155 - mae: 0.1155 - val_loss: 0.9048 - val_mae: 0.9048\n",
      "Epoch 194/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1126 - mae: 0.1126 - val_loss: 0.9174 - val_mae: 0.9174\n",
      "Epoch 195/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1135 - mae: 0.1135 - val_loss: 0.9131 - val_mae: 0.9131\n",
      "Epoch 196/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1144 - mae: 0.1144 - val_loss: 0.9125 - val_mae: 0.9125\n",
      "Epoch 197/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1130 - mae: 0.1130 - val_loss: 0.9231 - val_mae: 0.9231\n",
      "Epoch 198/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1141 - mae: 0.1141 - val_loss: 0.9127 - val_mae: 0.9127\n",
      "Epoch 199/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1119 - mae: 0.1119 - val_loss: 0.9213 - val_mae: 0.9213\n",
      "Epoch 200/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1132 - mae: 0.1132 - val_loss: 0.9334 - val_mae: 0.9334\n",
      "Epoch 201/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1121 - mae: 0.1121 - val_loss: 0.9032 - val_mae: 0.9032\n",
      "Epoch 202/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1135 - mae: 0.1135 - val_loss: 0.9142 - val_mae: 0.9142\n",
      "Epoch 203/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1130 - mae: 0.1130 - val_loss: 0.9296 - val_mae: 0.9296\n",
      "Epoch 204/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1142 - mae: 0.1142 - val_loss: 0.9119 - val_mae: 0.9119\n",
      "Epoch 205/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1127 - mae: 0.1127 - val_loss: 0.9360 - val_mae: 0.9360\n",
      "Epoch 206/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1175 - mae: 0.1175 - val_loss: 0.9091 - val_mae: 0.9091\n",
      "Epoch 207/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1140 - mae: 0.1140 - val_loss: 0.9218 - val_mae: 0.9218\n",
      "Epoch 208/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1131 - mae: 0.1131 - val_loss: 0.9231 - val_mae: 0.9231\n",
      "Epoch 209/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1122 - mae: 0.1122 - val_loss: 0.9176 - val_mae: 0.9176\n",
      "Epoch 210/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1117 - mae: 0.1117 - val_loss: 0.9195 - val_mae: 0.9195\n",
      "Epoch 211/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1142 - mae: 0.1142 - val_loss: 0.9261 - val_mae: 0.9261\n",
      "Epoch 212/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1137 - mae: 0.1137 - val_loss: 0.9127 - val_mae: 0.9127\n",
      "Epoch 213/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1148 - mae: 0.1148 - val_loss: 0.9362 - val_mae: 0.9362\n",
      "Epoch 214/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1115 - mae: 0.1115 - val_loss: 0.9211 - val_mae: 0.9211\n",
      "Epoch 215/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1132 - mae: 0.1132 - val_loss: 0.9171 - val_mae: 0.9171\n",
      "Epoch 216/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1119 - mae: 0.1119 - val_loss: 0.9179 - val_mae: 0.9179\n",
      "Epoch 217/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1176 - mae: 0.1176 - val_loss: 0.9272 - val_mae: 0.9272\n",
      "Epoch 218/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1133 - mae: 0.1133 - val_loss: 0.9238 - val_mae: 0.9238\n",
      "Epoch 219/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1113 - mae: 0.1113 - val_loss: 0.9278 - val_mae: 0.9278\n",
      "Epoch 220/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1100 - mae: 0.1100 - val_loss: 0.9252 - val_mae: 0.9252\n",
      "Epoch 221/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1172 - mae: 0.1172 - val_loss: 0.9315 - val_mae: 0.9315\n",
      "Epoch 222/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1164 - mae: 0.1164 - val_loss: 0.9220 - val_mae: 0.9220\n",
      "Epoch 223/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1156 - mae: 0.1156 - val_loss: 0.9346 - val_mae: 0.9346\n",
      "Epoch 224/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1143 - mae: 0.1143 - val_loss: 0.9387 - val_mae: 0.9387\n",
      "Epoch 225/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1132 - mae: 0.1132 - val_loss: 0.9277 - val_mae: 0.9277\n",
      "Epoch 226/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1132 - mae: 0.1132 - val_loss: 0.9272 - val_mae: 0.9272\n",
      "Epoch 227/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1128 - mae: 0.1128 - val_loss: 0.9272 - val_mae: 0.9272\n",
      "Epoch 228/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1114 - mae: 0.1114 - val_loss: 0.9363 - val_mae: 0.9363\n",
      "Epoch 229/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1111 - mae: 0.1111 - val_loss: 0.9247 - val_mae: 0.9247\n",
      "Epoch 230/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1118 - mae: 0.1118 - val_loss: 0.9377 - val_mae: 0.9377\n",
      "Epoch 231/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1136 - mae: 0.1136 - val_loss: 0.9455 - val_mae: 0.9455\n",
      "Epoch 232/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1165 - mae: 0.1165 - val_loss: 0.9293 - val_mae: 0.9293\n",
      "Epoch 233/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1144 - mae: 0.1144 - val_loss: 0.9267 - val_mae: 0.9267\n",
      "Epoch 234/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1125 - mae: 0.1125 - val_loss: 0.9437 - val_mae: 0.9437\n",
      "Epoch 235/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1113 - mae: 0.1113 - val_loss: 0.9395 - val_mae: 0.9395\n",
      "Epoch 236/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1104 - mae: 0.1104 - val_loss: 0.9419 - val_mae: 0.9419\n",
      "Epoch 237/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1117 - mae: 0.1117 - val_loss: 0.9378 - val_mae: 0.9378\n",
      "Epoch 238/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1108 - mae: 0.1108 - val_loss: 0.9453 - val_mae: 0.9453\n",
      "Epoch 239/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1117 - mae: 0.1117 - val_loss: 0.9349 - val_mae: 0.9349\n",
      "Epoch 240/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1157 - mae: 0.1157 - val_loss: 0.9317 - val_mae: 0.9317\n",
      "Epoch 241/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1185 - mae: 0.1185 - val_loss: 0.9468 - val_mae: 0.9468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1120 - mae: 0.1120 - val_loss: 0.9235 - val_mae: 0.9235\n",
      "Epoch 243/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1100 - mae: 0.1100 - val_loss: 0.9547 - val_mae: 0.9547\n",
      "Epoch 244/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1104 - mae: 0.1104 - val_loss: 0.9461 - val_mae: 0.9461\n",
      "Epoch 245/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1111 - mae: 0.1111 - val_loss: 0.9481 - val_mae: 0.9481\n",
      "Epoch 246/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1130 - mae: 0.1130 - val_loss: 0.9467 - val_mae: 0.9467\n",
      "Epoch 247/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1108 - mae: 0.1108 - val_loss: 0.9400 - val_mae: 0.9400\n",
      "Epoch 248/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1109 - mae: 0.1109 - val_loss: 0.9473 - val_mae: 0.9473\n",
      "Epoch 249/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1129 - mae: 0.1129 - val_loss: 0.9441 - val_mae: 0.9441\n",
      "Epoch 250/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1106 - mae: 0.1106 - val_loss: 0.9514 - val_mae: 0.9514\n",
      "Epoch 251/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1103 - mae: 0.1103 - val_loss: 0.9369 - val_mae: 0.9369\n",
      "Epoch 252/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1099 - mae: 0.1099 - val_loss: 0.9472 - val_mae: 0.9472\n",
      "Epoch 253/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1094 - mae: 0.1094 - val_loss: 0.9496 - val_mae: 0.9496\n",
      "Epoch 254/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1112 - mae: 0.1112 - val_loss: 0.9523 - val_mae: 0.9523\n",
      "Epoch 255/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1114 - mae: 0.1114 - val_loss: 0.9373 - val_mae: 0.9373\n",
      "Epoch 256/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1099 - mae: 0.1099 - val_loss: 0.9422 - val_mae: 0.9422\n",
      "Epoch 257/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1114 - mae: 0.1114 - val_loss: 0.9514 - val_mae: 0.9514\n",
      "Epoch 258/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1105 - mae: 0.1105 - val_loss: 0.9422 - val_mae: 0.9422\n",
      "Epoch 259/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1103 - mae: 0.1103 - val_loss: 0.9641 - val_mae: 0.9641\n",
      "Epoch 260/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1115 - mae: 0.1115 - val_loss: 0.9510 - val_mae: 0.9510\n",
      "Epoch 261/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1145 - mae: 0.1145 - val_loss: 0.9709 - val_mae: 0.9709\n",
      "Epoch 262/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1098 - mae: 0.1098 - val_loss: 0.9577 - val_mae: 0.9577\n",
      "Epoch 263/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1099 - mae: 0.1099 - val_loss: 0.9599 - val_mae: 0.9599\n",
      "Epoch 264/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1156 - mae: 0.1156 - val_loss: 0.9538 - val_mae: 0.9538\n",
      "Epoch 265/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1145 - mae: 0.1145 - val_loss: 0.9542 - val_mae: 0.9542\n",
      "Epoch 266/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1094 - mae: 0.1094 - val_loss: 0.9720 - val_mae: 0.9720\n",
      "Epoch 267/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1096 - mae: 0.1096 - val_loss: 0.9595 - val_mae: 0.9595\n",
      "Epoch 268/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1112 - mae: 0.1112 - val_loss: 0.9698 - val_mae: 0.9698\n",
      "Epoch 269/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1113 - mae: 0.1113 - val_loss: 0.9675 - val_mae: 0.9675\n",
      "Epoch 270/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1150 - mae: 0.1150 - val_loss: 0.9536 - val_mae: 0.9536\n",
      "Epoch 271/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1107 - mae: 0.1107 - val_loss: 0.9646 - val_mae: 0.9646\n",
      "Epoch 272/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1089 - mae: 0.1089 - val_loss: 0.9669 - val_mae: 0.9669\n",
      "Epoch 273/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1099 - mae: 0.1099 - val_loss: 0.9643 - val_mae: 0.9643\n",
      "Epoch 274/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1083 - mae: 0.1083 - val_loss: 0.9624 - val_mae: 0.9624\n",
      "Epoch 275/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1110 - mae: 0.1110 - val_loss: 0.9833 - val_mae: 0.9833\n",
      "Epoch 276/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1110 - mae: 0.1110 - val_loss: 0.9573 - val_mae: 0.9573\n",
      "Epoch 277/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1103 - mae: 0.1103 - val_loss: 0.9666 - val_mae: 0.9666\n",
      "Epoch 278/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1133 - mae: 0.1133 - val_loss: 0.9541 - val_mae: 0.9541\n",
      "Epoch 279/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1097 - mae: 0.1097 - val_loss: 0.9712 - val_mae: 0.9712\n",
      "Epoch 280/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1110 - mae: 0.1110 - val_loss: 0.9569 - val_mae: 0.9569\n",
      "Epoch 281/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1095 - mae: 0.1095 - val_loss: 0.9624 - val_mae: 0.9624\n",
      "Epoch 282/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1102 - mae: 0.1102 - val_loss: 0.9674 - val_mae: 0.9674\n",
      "Epoch 283/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1090 - mae: 0.1090 - val_loss: 0.9734 - val_mae: 0.9734\n",
      "Epoch 284/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1122 - mae: 0.1122 - val_loss: 0.9765 - val_mae: 0.9765\n",
      "Epoch 285/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1133 - mae: 0.1133 - val_loss: 0.9686 - val_mae: 0.9686\n",
      "Epoch 286/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1153 - mae: 0.1153 - val_loss: 0.9752 - val_mae: 0.9752\n",
      "Epoch 287/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1169 - mae: 0.1169 - val_loss: 0.9546 - val_mae: 0.9546\n",
      "Epoch 288/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1166 - mae: 0.1166 - val_loss: 0.9660 - val_mae: 0.9660\n",
      "Epoch 289/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1116 - mae: 0.1116 - val_loss: 0.9642 - val_mae: 0.9642\n",
      "Epoch 290/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1105 - mae: 0.1105 - val_loss: 0.9672 - val_mae: 0.9672\n",
      "Epoch 291/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1095 - mae: 0.1095 - val_loss: 0.9858 - val_mae: 0.9858\n",
      "Epoch 292/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1101 - mae: 0.1101 - val_loss: 0.9805 - val_mae: 0.9805\n",
      "Epoch 293/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1099 - mae: 0.1099 - val_loss: 0.9856 - val_mae: 0.9856\n",
      "Epoch 294/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1117 - mae: 0.1117 - val_loss: 0.9848 - val_mae: 0.9848\n",
      "Epoch 295/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1093 - mae: 0.1093 - val_loss: 0.9703 - val_mae: 0.9703\n",
      "Epoch 296/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1096 - mae: 0.1096 - val_loss: 0.9723 - val_mae: 0.9723\n",
      "Epoch 297/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1098 - mae: 0.1098 - val_loss: 0.9796 - val_mae: 0.9796\n",
      "Epoch 298/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1107 - mae: 0.1107 - val_loss: 0.9612 - val_mae: 0.9612\n",
      "Epoch 299/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1097 - mae: 0.1097 - val_loss: 0.9802 - val_mae: 0.9802\n",
      "Epoch 300/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1092 - mae: 0.1092 - val_loss: 0.9773 - val_mae: 0.9773\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni_non_stacked_usa = build_univariate_non_stacked()\n",
    "model_uni_non_stacked.fit(usa_cases_train_X,\n",
    "          usa_cases_train_y, \n",
    "          validation_data=(usa_cases_test_X, usa_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni_non_stacked_usa.save('univar_non_stack_rolling_usa.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee706d9a",
   "metadata": {},
   "source": [
    "### Univariate stacked -- Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "77e800ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 3, 100)            40800     \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 191,551\n",
      "Trainable params: 191,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 2s 52ms/step - loss: 0.6412 - val_loss: 0.1539\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3482 - val_loss: 0.1294\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1309 - val_loss: 0.0822\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1164 - val_loss: 0.0704\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0972 - val_loss: 0.0787\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1046 - val_loss: 0.0769\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1005 - val_loss: 0.0780\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0983 - val_loss: 0.0798\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1087 - val_loss: 0.0667\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1109 - val_loss: 0.0919\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0927 - val_loss: 0.0708\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0970 - val_loss: 0.0684\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0981 - val_loss: 0.0784\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0884 - val_loss: 0.0693\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0901 - val_loss: 0.0837\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0823 - val_loss: 0.0682\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0830 - val_loss: 0.0666\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0820 - val_loss: 0.0684\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0823 - val_loss: 0.0679\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0840 - val_loss: 0.0786\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0913 - val_loss: 0.0671\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0769 - val_loss: 0.0645\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0852 - val_loss: 0.0633\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0905 - val_loss: 0.0665\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0927 - val_loss: 0.0681\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0841 - val_loss: 0.0695\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0778 - val_loss: 0.0703\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0750 - val_loss: 0.0737\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0940 - val_loss: 0.0650\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0764 - val_loss: 0.0655\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0836 - val_loss: 0.0737\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0746 - val_loss: 0.0738\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0797 - val_loss: 0.0666\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0807 - val_loss: 0.0689\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0773 - val_loss: 0.0681\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0712 - val_loss: 0.0700\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0734 - val_loss: 0.0696\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0818 - val_loss: 0.0631\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0829 - val_loss: 0.0668\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0764 - val_loss: 0.0667\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0718 - val_loss: 0.0697\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0688 - val_loss: 0.0641\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0705 - val_loss: 0.0639\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0902 - val_loss: 0.0688\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0870 - val_loss: 0.0737\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0716 - val_loss: 0.0627\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0784 - val_loss: 0.0643\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0806 - val_loss: 0.0626\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0743 - val_loss: 0.0725\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0723 - val_loss: 0.0652\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0722 - val_loss: 0.0714\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0725 - val_loss: 0.0656\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0717 - val_loss: 0.0636\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0706 - val_loss: 0.0675\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0690 - val_loss: 0.0653\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0668 - val_loss: 0.0632\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0694 - val_loss: 0.0670\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0678 - val_loss: 0.0638\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0714 - val_loss: 0.0673\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0682 - val_loss: 0.0609\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0859 - val_loss: 0.0736\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0763 - val_loss: 0.0713\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0752 - val_loss: 0.0686\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0775 - val_loss: 0.0634\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0713 - val_loss: 0.0634\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0710 - val_loss: 0.0653\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0690 - val_loss: 0.0671\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0678 - val_loss: 0.0665\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0694 - val_loss: 0.0629\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0707 - val_loss: 0.0631\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0746 - val_loss: 0.0645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0735 - val_loss: 0.0707\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0772 - val_loss: 0.0631\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0788 - val_loss: 0.0686\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0749 - val_loss: 0.0660\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0692 - val_loss: 0.0642\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0683 - val_loss: 0.0625\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0733 - val_loss: 0.0688\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0682 - val_loss: 0.0669\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0689 - val_loss: 0.0635\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0712 - val_loss: 0.0632\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0711 - val_loss: 0.0688\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0669 - val_loss: 0.0625\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0755 - val_loss: 0.0666\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0696 - val_loss: 0.0655\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0698 - val_loss: 0.0672\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0758 - val_loss: 0.0707\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0734 - val_loss: 0.0698\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0733 - val_loss: 0.0649\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0708 - val_loss: 0.0607\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0722 - val_loss: 0.0661\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0704 - val_loss: 0.0624\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0704 - val_loss: 0.0692\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0723 - val_loss: 0.0630\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0666 - val_loss: 0.0644\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0672 - val_loss: 0.0655\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0657 - val_loss: 0.0656\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0665 - val_loss: 0.0654\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0672 - val_loss: 0.0634\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0660 - val_loss: 0.0653\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0670 - val_loss: 0.0666\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0666 - val_loss: 0.0640\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0695 - val_loss: 0.0656\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0678 - val_loss: 0.0648\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0673 - val_loss: 0.0654\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0677 - val_loss: 0.0641\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0697 - val_loss: 0.0660\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0697 - val_loss: 0.0643\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0684 - val_loss: 0.0682\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0704 - val_loss: 0.0650\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0717 - val_loss: 0.0644\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0701 - val_loss: 0.0644\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0677 - val_loss: 0.0661\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0680 - val_loss: 0.0611\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0722 - val_loss: 0.0619\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0716 - val_loss: 0.0661\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0823 - val_loss: 0.0703\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0722 - val_loss: 0.0645\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0663 - val_loss: 0.0660\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0666 - val_loss: 0.0630\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0665 - val_loss: 0.0717\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0705 - val_loss: 0.0654\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0687 - val_loss: 0.0624\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0665 - val_loss: 0.0607\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0750 - val_loss: 0.0625\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0784 - val_loss: 0.0676\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0680 - val_loss: 0.0664\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0718 - val_loss: 0.0685\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0694 - val_loss: 0.0647\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0683 - val_loss: 0.0625\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0662 - val_loss: 0.0666\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0663 - val_loss: 0.0658\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0658 - val_loss: 0.0683\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0675 - val_loss: 0.0663\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0686 - val_loss: 0.0627\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0680 - val_loss: 0.0632\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0660 - val_loss: 0.0662\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0655 - val_loss: 0.0623\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0674 - val_loss: 0.0636\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0676 - val_loss: 0.0631\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0655 - val_loss: 0.0641\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0693 - val_loss: 0.0670\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0684 - val_loss: 0.0638\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0712 - val_loss: 0.0605\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0724 - val_loss: 0.0611\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0764 - val_loss: 0.0678\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0685 - val_loss: 0.0652\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0745 - val_loss: 0.0660\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0685 - val_loss: 0.0629\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0653 - val_loss: 0.0627\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0651 - val_loss: 0.0687\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0681 - val_loss: 0.0654\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0647 - val_loss: 0.0654\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0728 - val_loss: 0.0682\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0669 - val_loss: 0.0655\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0651 - val_loss: 0.0620\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0665 - val_loss: 0.0666\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0684 - val_loss: 0.0622\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0652 - val_loss: 0.0677\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0687 - val_loss: 0.0642\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0690 - val_loss: 0.0619\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0693 - val_loss: 0.0706\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0668 - val_loss: 0.0636\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0637 - val_loss: 0.0639\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0660 - val_loss: 0.0677\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0668 - val_loss: 0.0633\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0681 - val_loss: 0.0690\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0678 - val_loss: 0.0653\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0631 - val_loss: 0.0651\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0678 - val_loss: 0.0653\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0628 - val_loss: 0.0632\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0660 - val_loss: 0.0636\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0652 - val_loss: 0.0608\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0707 - val_loss: 0.0632\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0741 - val_loss: 0.0637\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0648 - val_loss: 0.0659\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0646 - val_loss: 0.0613\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0664 - val_loss: 0.0661\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0652 - val_loss: 0.0688\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0624 - val_loss: 0.0642\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0640 - val_loss: 0.0657\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0648 - val_loss: 0.0627\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0651 - val_loss: 0.0640\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0628 - val_loss: 0.0645\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0635 - val_loss: 0.0636\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0626 - val_loss: 0.0650\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0628 - val_loss: 0.0636\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0662 - val_loss: 0.0600\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0681 - val_loss: 0.0599\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0622 - val_loss: 0.0664\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0620 - val_loss: 0.0648\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0663 - val_loss: 0.0616\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0680 - val_loss: 0.0602\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0709 - val_loss: 0.0670\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0614 - val_loss: 0.0631\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0647 - val_loss: 0.0638\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0657 - val_loss: 0.0669\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0700 - val_loss: 0.0712\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0781 - val_loss: 0.0605\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0632 - val_loss: 0.0613\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0680 - val_loss: 0.0666\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0672 - val_loss: 0.0686\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0653 - val_loss: 0.0671\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0646 - val_loss: 0.0636\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0668 - val_loss: 0.0620\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0677 - val_loss: 0.0692\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0660 - val_loss: 0.0664\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0641 - val_loss: 0.0612\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0630 - val_loss: 0.0616\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0705 - val_loss: 0.0631\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0705 - val_loss: 0.0649\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0622 - val_loss: 0.0634\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0641 - val_loss: 0.0643\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0630 - val_loss: 0.0668\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0628 - val_loss: 0.0631\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0615 - val_loss: 0.0613\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0625 - val_loss: 0.0618\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0629 - val_loss: 0.0632\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0622 - val_loss: 0.0647\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0685 - val_loss: 0.0639\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0617 - val_loss: 0.0637\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0617 - val_loss: 0.0613\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0614 - val_loss: 0.0628\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0611 - val_loss: 0.0638\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0610 - val_loss: 0.0624\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0617 - val_loss: 0.0593\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0613 - val_loss: 0.0628\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0633 - val_loss: 0.0609\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0608 - val_loss: 0.0632\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0629 - val_loss: 0.0620\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0637 - val_loss: 0.0598\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0635 - val_loss: 0.0631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0641 - val_loss: 0.0689\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0632 - val_loss: 0.0597\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0646 - val_loss: 0.0618\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0667 - val_loss: 0.0638\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0635 - val_loss: 0.0634\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0679 - val_loss: 0.0616\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0645 - val_loss: 0.0608\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0636 - val_loss: 0.0600\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0631 - val_loss: 0.0651\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0653 - val_loss: 0.0642\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0628 - val_loss: 0.0606\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0641 - val_loss: 0.0632\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0620 - val_loss: 0.0622\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0655 - val_loss: 0.0732\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0674 - val_loss: 0.0632\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0642 - val_loss: 0.0611\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0713 - val_loss: 0.0610\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0688 - val_loss: 0.0639\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0648 - val_loss: 0.0604\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0634 - val_loss: 0.0603\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0613 - val_loss: 0.0629\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0645 - val_loss: 0.0629\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0612 - val_loss: 0.0646\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0656 - val_loss: 0.0616\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0621 - val_loss: 0.0608\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0610 - val_loss: 0.0625\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0614 - val_loss: 0.0623\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0615 - val_loss: 0.0655\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0711 - val_loss: 0.0603\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0637 - val_loss: 0.0598\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0623 - val_loss: 0.0658\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0607 - val_loss: 0.0642\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0638 - val_loss: 0.0620\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0607 - val_loss: 0.0616\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0609 - val_loss: 0.0604\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0635 - val_loss: 0.0616\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0715 - val_loss: 0.0578\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0661 - val_loss: 0.0636\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0666 - val_loss: 0.0602\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0620 - val_loss: 0.0620\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0604 - val_loss: 0.0618\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0620 - val_loss: 0.0621\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0614 - val_loss: 0.0604\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0593 - val_loss: 0.0607\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0626 - val_loss: 0.0599\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0637 - val_loss: 0.0599\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0598 - val_loss: 0.0628\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0612 - val_loss: 0.0638\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0650 - val_loss: 0.0712\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0705 - val_loss: 0.0586\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0637 - val_loss: 0.0594\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0606 - val_loss: 0.0640\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0600 - val_loss: 0.0587\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0664 - val_loss: 0.0607\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0605 - val_loss: 0.0652\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0647 - val_loss: 0.0644\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0647 - val_loss: 0.0619\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0600 - val_loss: 0.0613\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0598 - val_loss: 0.0597\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0608 - val_loss: 0.0612\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0608 - val_loss: 0.0624\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0589 - val_loss: 0.0614\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0591 - val_loss: 0.0583\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0609 - val_loss: 0.0592\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0641 - val_loss: 0.0597\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0613 - val_loss: 0.0594\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0589 - val_loss: 0.0605\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni_stacked_india = build_univariate_stacked()\n",
    "model_uni_stacked_india.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni_stacked_india.save('univar_stacked_rolling_india.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a63fe62b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 3, 100)            40800     \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 191,551\n",
      "Trainable params: 191,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "14/14 [==============================] - 2s 46ms/step - loss: 0.7173 - val_loss: 0.9302\n",
      "Epoch 2/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.5607 - val_loss: 0.8503\n",
      "Epoch 3/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.2782 - val_loss: 0.8897\n",
      "Epoch 4/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2197 - val_loss: 0.8131\n",
      "Epoch 5/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1990 - val_loss: 0.8025\n",
      "Epoch 6/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1994 - val_loss: 0.8081\n",
      "Epoch 7/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1960 - val_loss: 0.7992\n",
      "Epoch 8/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1887 - val_loss: 0.8150\n",
      "Epoch 9/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1835 - val_loss: 0.8049\n",
      "Epoch 10/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1841 - val_loss: 0.8104\n",
      "Epoch 11/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1817 - val_loss: 0.8028\n",
      "Epoch 12/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1804 - val_loss: 0.8068\n",
      "Epoch 13/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1755 - val_loss: 0.8124\n",
      "Epoch 14/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1729 - val_loss: 0.8125\n",
      "Epoch 15/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1712 - val_loss: 0.8136\n",
      "Epoch 16/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1665 - val_loss: 0.8049\n",
      "Epoch 17/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1651 - val_loss: 0.8080\n",
      "Epoch 18/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1635 - val_loss: 0.8122\n",
      "Epoch 19/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1613 - val_loss: 0.8144\n",
      "Epoch 20/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1643 - val_loss: 0.8090\n",
      "Epoch 21/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1646 - val_loss: 0.8067\n",
      "Epoch 22/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1613 - val_loss: 0.8176\n",
      "Epoch 23/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1622 - val_loss: 0.8043\n",
      "Epoch 24/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1588 - val_loss: 0.8035\n",
      "Epoch 25/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1581 - val_loss: 0.8084\n",
      "Epoch 26/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1589 - val_loss: 0.7928\n",
      "Epoch 27/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1600 - val_loss: 0.7992\n",
      "Epoch 28/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1624 - val_loss: 0.7842\n",
      "Epoch 29/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1626 - val_loss: 0.8005\n",
      "Epoch 30/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1592 - val_loss: 0.7969\n",
      "Epoch 31/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1563 - val_loss: 0.7902\n",
      "Epoch 32/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1570 - val_loss: 0.7944\n",
      "Epoch 33/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1583 - val_loss: 0.7908\n",
      "Epoch 34/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1594 - val_loss: 0.8031\n",
      "Epoch 35/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1615 - val_loss: 0.7975\n",
      "Epoch 36/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1558 - val_loss: 0.7977\n",
      "Epoch 37/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1639 - val_loss: 0.7890\n",
      "Epoch 38/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1603 - val_loss: 0.7904\n",
      "Epoch 39/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1605 - val_loss: 0.7908\n",
      "Epoch 40/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1566 - val_loss: 0.7949\n",
      "Epoch 41/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1559 - val_loss: 0.7982\n",
      "Epoch 42/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1602 - val_loss: 0.7906\n",
      "Epoch 43/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1578 - val_loss: 0.7828\n",
      "Epoch 44/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1562 - val_loss: 0.7843\n",
      "Epoch 45/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1599 - val_loss: 0.7835\n",
      "Epoch 46/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1582 - val_loss: 0.7836\n",
      "Epoch 47/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1521 - val_loss: 0.7956\n",
      "Epoch 48/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1558 - val_loss: 0.7988\n",
      "Epoch 49/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1575 - val_loss: 0.7879\n",
      "Epoch 50/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1545 - val_loss: 0.7995\n",
      "Epoch 51/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1571 - val_loss: 0.7864\n",
      "Epoch 52/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1529 - val_loss: 0.7881\n",
      "Epoch 53/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1533 - val_loss: 0.7899\n",
      "Epoch 54/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1543 - val_loss: 0.7823\n",
      "Epoch 55/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1541 - val_loss: 0.7894\n",
      "Epoch 56/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1507 - val_loss: 0.7873\n",
      "Epoch 57/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1518 - val_loss: 0.7986\n",
      "Epoch 58/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1557 - val_loss: 0.7920\n",
      "Epoch 59/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1568 - val_loss: 0.7868\n",
      "Epoch 60/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1500 - val_loss: 0.7851\n",
      "Epoch 61/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1500 - val_loss: 0.7790\n",
      "Epoch 62/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1513 - val_loss: 0.7823\n",
      "Epoch 63/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1519 - val_loss: 0.7804\n",
      "Epoch 64/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1542 - val_loss: 0.7763\n",
      "Epoch 65/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1538 - val_loss: 0.7859\n",
      "Epoch 66/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1605 - val_loss: 0.7685\n",
      "Epoch 67/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1510 - val_loss: 0.7803\n",
      "Epoch 68/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1546 - val_loss: 0.7783\n",
      "Epoch 69/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1480 - val_loss: 0.7739\n",
      "Epoch 70/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1520 - val_loss: 0.7724\n",
      "Epoch 71/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1512 - val_loss: 0.7737\n",
      "Epoch 72/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1480 - val_loss: 0.7751\n",
      "Epoch 73/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1491 - val_loss: 0.7684\n",
      "Epoch 74/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1523 - val_loss: 0.7693\n",
      "Epoch 75/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1535 - val_loss: 0.7719\n",
      "Epoch 76/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1574 - val_loss: 0.7679\n",
      "Epoch 77/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1463 - val_loss: 0.7676\n",
      "Epoch 78/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1483 - val_loss: 0.7670\n",
      "Epoch 79/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1456 - val_loss: 0.7697\n",
      "Epoch 80/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1469 - val_loss: 0.7647\n",
      "Epoch 81/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1447 - val_loss: 0.7632\n",
      "Epoch 82/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1461 - val_loss: 0.7589\n",
      "Epoch 83/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1492 - val_loss: 0.7596\n",
      "Epoch 84/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1492 - val_loss: 0.7579\n",
      "Epoch 85/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1474 - val_loss: 0.7627\n",
      "Epoch 86/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1446 - val_loss: 0.7640\n",
      "Epoch 87/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1471 - val_loss: 0.7593\n",
      "Epoch 88/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1460 - val_loss: 0.7580\n",
      "Epoch 89/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1447 - val_loss: 0.7580\n",
      "Epoch 90/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1459 - val_loss: 0.7600\n",
      "Epoch 91/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1444 - val_loss: 0.7667\n",
      "Epoch 92/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1454 - val_loss: 0.7584\n",
      "Epoch 93/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1440 - val_loss: 0.7565\n",
      "Epoch 94/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1432 - val_loss: 0.7584\n",
      "Epoch 95/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1427 - val_loss: 0.7600\n",
      "Epoch 96/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1444 - val_loss: 0.7553\n",
      "Epoch 97/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1465 - val_loss: 0.7530\n",
      "Epoch 98/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1446 - val_loss: 0.7624\n",
      "Epoch 99/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1478 - val_loss: 0.7484\n",
      "Epoch 100/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1457 - val_loss: 0.7605\n",
      "Epoch 101/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1414 - val_loss: 0.7518\n",
      "Epoch 102/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1407 - val_loss: 0.7589\n",
      "Epoch 103/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1409 - val_loss: 0.7511\n",
      "Epoch 104/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1406 - val_loss: 0.7552\n",
      "Epoch 105/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1378 - val_loss: 0.7645\n",
      "Epoch 106/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1495 - val_loss: 0.7547\n",
      "Epoch 107/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1453 - val_loss: 0.7653\n",
      "Epoch 108/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1500 - val_loss: 0.7600\n",
      "Epoch 109/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1418 - val_loss: 0.7527\n",
      "Epoch 110/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1431 - val_loss: 0.7620\n",
      "Epoch 111/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1464 - val_loss: 0.7624\n",
      "Epoch 112/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1429 - val_loss: 0.7544\n",
      "Epoch 113/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1380 - val_loss: 0.7601\n",
      "Epoch 114/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1412 - val_loss: 0.7529\n",
      "Epoch 115/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1390 - val_loss: 0.7426\n",
      "Epoch 116/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1400 - val_loss: 0.7569\n",
      "Epoch 117/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1414 - val_loss: 0.7462\n",
      "Epoch 118/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1373 - val_loss: 0.7477\n",
      "Epoch 119/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1370 - val_loss: 0.7512\n",
      "Epoch 120/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1404 - val_loss: 0.7423\n",
      "Epoch 121/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1413 - val_loss: 0.7494\n",
      "Epoch 122/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1412 - val_loss: 0.7643\n",
      "Epoch 123/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1399 - val_loss: 0.7475\n",
      "Epoch 124/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1367 - val_loss: 0.7460\n",
      "Epoch 125/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1370 - val_loss: 0.7475\n",
      "Epoch 126/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1342 - val_loss: 0.7531\n",
      "Epoch 127/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1348 - val_loss: 0.7462\n",
      "Epoch 128/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1380 - val_loss: 0.7553\n",
      "Epoch 129/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1386 - val_loss: 0.7591\n",
      "Epoch 130/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1359 - val_loss: 0.7476\n",
      "Epoch 131/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1348 - val_loss: 0.7553\n",
      "Epoch 132/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1363 - val_loss: 0.7384\n",
      "Epoch 133/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1355 - val_loss: 0.7483\n",
      "Epoch 134/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1372 - val_loss: 0.7532\n",
      "Epoch 135/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1400 - val_loss: 0.7436\n",
      "Epoch 136/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1375 - val_loss: 0.7560\n",
      "Epoch 137/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1368 - val_loss: 0.7516\n",
      "Epoch 138/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1331 - val_loss: 0.7473\n",
      "Epoch 139/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1345 - val_loss: 0.7689\n",
      "Epoch 140/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1381 - val_loss: 0.7479\n",
      "Epoch 141/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1335 - val_loss: 0.7504\n",
      "Epoch 142/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1362 - val_loss: 0.7529\n",
      "Epoch 143/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1345 - val_loss: 0.7474\n",
      "Epoch 144/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1360 - val_loss: 0.7591\n",
      "Epoch 145/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1350 - val_loss: 0.7593\n",
      "Epoch 146/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1391 - val_loss: 0.7549\n",
      "Epoch 147/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1357 - val_loss: 0.7612\n",
      "Epoch 148/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1346 - val_loss: 0.7502\n",
      "Epoch 149/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1311 - val_loss: 0.7568\n",
      "Epoch 150/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1339 - val_loss: 0.7485\n",
      "Epoch 151/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1343 - val_loss: 0.7567\n",
      "Epoch 152/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1345 - val_loss: 0.7500\n",
      "Epoch 153/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1326 - val_loss: 0.7521\n",
      "Epoch 154/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1366 - val_loss: 0.7638\n",
      "Epoch 155/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1319 - val_loss: 0.7437\n",
      "Epoch 156/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1416 - val_loss: 0.7602\n",
      "Epoch 157/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1377 - val_loss: 0.7609\n",
      "Epoch 158/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1330 - val_loss: 0.7607\n",
      "Epoch 159/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1363 - val_loss: 0.7510\n",
      "Epoch 160/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1373 - val_loss: 0.7682\n",
      "Epoch 161/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1330 - val_loss: 0.7544\n",
      "Epoch 162/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1309 - val_loss: 0.7528\n",
      "Epoch 163/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1325 - val_loss: 0.7604\n",
      "Epoch 164/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1314 - val_loss: 0.7560\n",
      "Epoch 165/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1347 - val_loss: 0.7619\n",
      "Epoch 166/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1354 - val_loss: 0.7750\n",
      "Epoch 167/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1347 - val_loss: 0.7668\n",
      "Epoch 168/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1323 - val_loss: 0.7715\n",
      "Epoch 169/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1273 - val_loss: 0.7508\n",
      "Epoch 170/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1392 - val_loss: 0.7656\n",
      "Epoch 171/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1283 - val_loss: 0.7695\n",
      "Epoch 172/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1294 - val_loss: 0.7626\n",
      "Epoch 173/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1310 - val_loss: 0.7624\n",
      "Epoch 174/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1268 - val_loss: 0.7697\n",
      "Epoch 175/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1286 - val_loss: 0.7614\n",
      "Epoch 176/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1285 - val_loss: 0.7703\n",
      "Epoch 177/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1267 - val_loss: 0.7652\n",
      "Epoch 178/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1278 - val_loss: 0.7772\n",
      "Epoch 179/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1284 - val_loss: 0.7642\n",
      "Epoch 180/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1283 - val_loss: 0.7706\n",
      "Epoch 181/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1268 - val_loss: 0.7767\n",
      "Epoch 182/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1262 - val_loss: 0.7703\n",
      "Epoch 183/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1246 - val_loss: 0.7808\n",
      "Epoch 184/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1337 - val_loss: 0.7754\n",
      "Epoch 185/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1276 - val_loss: 0.7754\n",
      "Epoch 186/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1260 - val_loss: 0.7838\n",
      "Epoch 187/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1285 - val_loss: 0.7769\n",
      "Epoch 188/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1304 - val_loss: 0.7655\n",
      "Epoch 189/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1306 - val_loss: 0.7913\n",
      "Epoch 190/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1310 - val_loss: 0.7771\n",
      "Epoch 191/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1342 - val_loss: 0.7755\n",
      "Epoch 192/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1278 - val_loss: 0.7795\n",
      "Epoch 193/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1292 - val_loss: 0.7701\n",
      "Epoch 194/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1313 - val_loss: 0.8017\n",
      "Epoch 195/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1361 - val_loss: 0.7704\n",
      "Epoch 196/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1302 - val_loss: 0.7920\n",
      "Epoch 197/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1300 - val_loss: 0.7799\n",
      "Epoch 198/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1289 - val_loss: 0.7820\n",
      "Epoch 199/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1261 - val_loss: 0.7906\n",
      "Epoch 200/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1294 - val_loss: 0.7747\n",
      "Epoch 201/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1283 - val_loss: 0.7781\n",
      "Epoch 202/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1282 - val_loss: 0.7883\n",
      "Epoch 203/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1232 - val_loss: 0.7836\n",
      "Epoch 204/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1214 - val_loss: 0.7919\n",
      "Epoch 205/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1288 - val_loss: 0.7742\n",
      "Epoch 206/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1302 - val_loss: 0.8004\n",
      "Epoch 207/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1272 - val_loss: 0.7896\n",
      "Epoch 208/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1287 - val_loss: 0.7758\n",
      "Epoch 209/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1237 - val_loss: 0.7952\n",
      "Epoch 210/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1296 - val_loss: 0.7832\n",
      "Epoch 211/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1241 - val_loss: 0.7787\n",
      "Epoch 212/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1234 - val_loss: 0.8015\n",
      "Epoch 213/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1255 - val_loss: 0.7913\n",
      "Epoch 214/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1322 - val_loss: 0.7964\n",
      "Epoch 215/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1262 - val_loss: 0.7889\n",
      "Epoch 216/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1254 - val_loss: 0.8020\n",
      "Epoch 217/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1233 - val_loss: 0.7865\n",
      "Epoch 218/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1236 - val_loss: 0.7990\n",
      "Epoch 219/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1235 - val_loss: 0.7904\n",
      "Epoch 220/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1219 - val_loss: 0.7958\n",
      "Epoch 221/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1226 - val_loss: 0.7928\n",
      "Epoch 222/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1208 - val_loss: 0.8023\n",
      "Epoch 223/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1216 - val_loss: 0.7898\n",
      "Epoch 224/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1233 - val_loss: 0.8125\n",
      "Epoch 225/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1229 - val_loss: 0.7952\n",
      "Epoch 226/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1207 - val_loss: 0.7995\n",
      "Epoch 227/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1237 - val_loss: 0.7962\n",
      "Epoch 228/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1218 - val_loss: 0.7989\n",
      "Epoch 229/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1207 - val_loss: 0.7946\n",
      "Epoch 230/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1189 - val_loss: 0.8143\n",
      "Epoch 231/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1237 - val_loss: 0.8003\n",
      "Epoch 232/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1209 - val_loss: 0.8007\n",
      "Epoch 233/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1201 - val_loss: 0.7980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1198 - val_loss: 0.8051\n",
      "Epoch 235/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1196 - val_loss: 0.8221\n",
      "Epoch 236/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1196 - val_loss: 0.7869\n",
      "Epoch 237/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1229 - val_loss: 0.8071\n",
      "Epoch 238/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1210 - val_loss: 0.8106\n",
      "Epoch 239/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1258 - val_loss: 0.8000\n",
      "Epoch 240/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1207 - val_loss: 0.7980\n",
      "Epoch 241/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1198 - val_loss: 0.8103\n",
      "Epoch 242/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1203 - val_loss: 0.8070\n",
      "Epoch 243/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1243 - val_loss: 0.8235\n",
      "Epoch 244/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1254 - val_loss: 0.8091\n",
      "Epoch 245/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1245 - val_loss: 0.8214\n",
      "Epoch 246/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1213 - val_loss: 0.7970\n",
      "Epoch 247/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1223 - val_loss: 0.8023\n",
      "Epoch 248/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1191 - val_loss: 0.8179\n",
      "Epoch 249/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1183 - val_loss: 0.8092\n",
      "Epoch 250/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1188 - val_loss: 0.8112\n",
      "Epoch 251/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1195 - val_loss: 0.8144\n",
      "Epoch 252/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1183 - val_loss: 0.8083\n",
      "Epoch 253/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1202 - val_loss: 0.8148\n",
      "Epoch 254/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1195 - val_loss: 0.8251\n",
      "Epoch 255/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1266 - val_loss: 0.8102\n",
      "Epoch 256/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1204 - val_loss: 0.8200\n",
      "Epoch 257/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1173 - val_loss: 0.8038\n",
      "Epoch 258/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1266 - val_loss: 0.8108\n",
      "Epoch 259/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1207 - val_loss: 0.8193\n",
      "Epoch 260/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1201 - val_loss: 0.8169\n",
      "Epoch 261/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1193 - val_loss: 0.8308\n",
      "Epoch 262/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1187 - val_loss: 0.8172\n",
      "Epoch 263/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1161 - val_loss: 0.8138\n",
      "Epoch 264/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1175 - val_loss: 0.8309\n",
      "Epoch 265/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1182 - val_loss: 0.8183\n",
      "Epoch 266/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1173 - val_loss: 0.8189\n",
      "Epoch 267/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1151 - val_loss: 0.8236\n",
      "Epoch 268/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1177 - val_loss: 0.8180\n",
      "Epoch 269/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1168 - val_loss: 0.8252\n",
      "Epoch 270/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1178 - val_loss: 0.8208\n",
      "Epoch 271/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1189 - val_loss: 0.8260\n",
      "Epoch 272/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1240 - val_loss: 0.8371\n",
      "Epoch 273/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1216 - val_loss: 0.8255\n",
      "Epoch 274/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1226 - val_loss: 0.8285\n",
      "Epoch 275/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1198 - val_loss: 0.8336\n",
      "Epoch 276/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1146 - val_loss: 0.8334\n",
      "Epoch 277/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1146 - val_loss: 0.8313\n",
      "Epoch 278/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1176 - val_loss: 0.8264\n",
      "Epoch 279/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1168 - val_loss: 0.8296\n",
      "Epoch 280/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1156 - val_loss: 0.8295\n",
      "Epoch 281/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1163 - val_loss: 0.8374\n",
      "Epoch 282/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1157 - val_loss: 0.8329\n",
      "Epoch 283/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1176 - val_loss: 0.8248\n",
      "Epoch 284/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1156 - val_loss: 0.8362\n",
      "Epoch 285/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1208 - val_loss: 0.8351\n",
      "Epoch 286/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1187 - val_loss: 0.8273\n",
      "Epoch 287/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1204 - val_loss: 0.8456\n",
      "Epoch 288/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1187 - val_loss: 0.8290\n",
      "Epoch 289/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1177 - val_loss: 0.8327\n",
      "Epoch 290/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1147 - val_loss: 0.8261\n",
      "Epoch 291/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1121 - val_loss: 0.8387\n",
      "Epoch 292/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1171 - val_loss: 0.8290\n",
      "Epoch 293/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1154 - val_loss: 0.8418\n",
      "Epoch 294/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1151 - val_loss: 0.8387\n",
      "Epoch 295/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1179 - val_loss: 0.8436\n",
      "Epoch 296/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1162 - val_loss: 0.8500\n",
      "Epoch 297/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1132 - val_loss: 0.8318\n",
      "Epoch 298/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1153 - val_loss: 0.8364\n",
      "Epoch 299/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1143 - val_loss: 0.8462\n",
      "Epoch 300/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1166 - val_loss: 0.8422\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni_stacked_usa = build_univariate_stacked()\n",
    "model_uni_stacked_usa.fit(usa_cases_train_X,\n",
    "          usa_cases_train_y, \n",
    "          validation_data=(usa_cases_test_X, usa_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni_stacked_usa.save('univar_stacked_rolling_usa.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a66ef",
   "metadata": {},
   "source": [
    "### Univariate stacked -- Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db1e7d12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 3, 100)            40800     \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                1510      \n",
      "=================================================================\n",
      "Total params: 192,910\n",
      "Trainable params: 192,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 2s 43ms/step - loss: 0.6775 - val_loss: 0.1893\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.5489 - val_loss: 0.0805\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2059 - val_loss: 0.0854\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1318 - val_loss: 0.0837\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1251 - val_loss: 0.0944\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1154 - val_loss: 0.0741\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1103 - val_loss: 0.0762\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1065 - val_loss: 0.0828\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1077 - val_loss: 0.0862\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1028 - val_loss: 0.0718\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0965 - val_loss: 0.0734\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1023 - val_loss: 0.0876\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0962 - val_loss: 0.0773\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0924 - val_loss: 0.0691\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0945 - val_loss: 0.0760\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0862 - val_loss: 0.0700\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0875 - val_loss: 0.0735\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0929 - val_loss: 0.0711\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1024 - val_loss: 0.0729\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0883 - val_loss: 0.0796\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0846 - val_loss: 0.0772\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0883 - val_loss: 0.0724\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0850 - val_loss: 0.0682\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0792 - val_loss: 0.0695\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0755 - val_loss: 0.0697\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0768 - val_loss: 0.0709\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0770 - val_loss: 0.0673\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0753 - val_loss: 0.0681\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0794 - val_loss: 0.0677\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0749 - val_loss: 0.0703\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0841 - val_loss: 0.0658\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0846 - val_loss: 0.0696\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0788 - val_loss: 0.0775\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0842 - val_loss: 0.0740\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0734 - val_loss: 0.0718\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0763 - val_loss: 0.0673\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0732 - val_loss: 0.0700\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0759 - val_loss: 0.0738\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0741 - val_loss: 0.0653\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0805 - val_loss: 0.0651\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0987 - val_loss: 0.0654\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0974 - val_loss: 0.0764\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0775 - val_loss: 0.0724\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0741 - val_loss: 0.0698\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0781 - val_loss: 0.0696\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0756 - val_loss: 0.0688\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0704 - val_loss: 0.0670\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0760 - val_loss: 0.0654\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0754 - val_loss: 0.0664\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0741 - val_loss: 0.0656\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0730 - val_loss: 0.0685\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0702 - val_loss: 0.0660\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0758 - val_loss: 0.0698\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0691 - val_loss: 0.0648\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0740 - val_loss: 0.0647\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0674 - val_loss: 0.0656\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0713 - val_loss: 0.0679\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0690 - val_loss: 0.0666\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0694 - val_loss: 0.0667\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0715 - val_loss: 0.0666\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0817 - val_loss: 0.0642\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0729 - val_loss: 0.0673\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0691 - val_loss: 0.0683\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0738 - val_loss: 0.0659\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0752 - val_loss: 0.0642\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0755 - val_loss: 0.0643\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0830 - val_loss: 0.0801\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0883 - val_loss: 0.0653\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0838 - val_loss: 0.0701\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0722 - val_loss: 0.0698\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0691 - val_loss: 0.0633\n",
      "Epoch 72/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0691 - val_loss: 0.0657\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0712 - val_loss: 0.0629\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0745 - val_loss: 0.0627\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0814 - val_loss: 0.0649\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0696 - val_loss: 0.0646\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0850 - val_loss: 0.0702\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0812 - val_loss: 0.0733\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0832 - val_loss: 0.0653\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0719 - val_loss: 0.0675\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0717 - val_loss: 0.0678\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0687 - val_loss: 0.0657\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0691 - val_loss: 0.0644\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0707 - val_loss: 0.0659\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0709 - val_loss: 0.0727\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0695 - val_loss: 0.0656\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0706 - val_loss: 0.0643\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0866 - val_loss: 0.0663\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0846 - val_loss: 0.0644\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0697 - val_loss: 0.0706\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0690 - val_loss: 0.0646\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0714 - val_loss: 0.0678\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0793 - val_loss: 0.0704\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0729 - val_loss: 0.0670\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0791 - val_loss: 0.0780\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0790 - val_loss: 0.0687\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0706 - val_loss: 0.0649\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0690 - val_loss: 0.0645\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0672 - val_loss: 0.0650\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0698 - val_loss: 0.0654\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0678 - val_loss: 0.0724\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0668 - val_loss: 0.0635\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0777 - val_loss: 0.0627\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0760 - val_loss: 0.0650\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0678 - val_loss: 0.0657\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0685 - val_loss: 0.0705\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0690 - val_loss: 0.0653\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0680 - val_loss: 0.0646\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0696 - val_loss: 0.0648\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0750 - val_loss: 0.0662\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0768 - val_loss: 0.0674\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0769 - val_loss: 0.0676\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0726 - val_loss: 0.0689\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0667 - val_loss: 0.0656\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0686 - val_loss: 0.0734\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0680 - val_loss: 0.0702\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0684 - val_loss: 0.0656\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0682 - val_loss: 0.0661\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0667 - val_loss: 0.0715\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0669 - val_loss: 0.0686\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0682 - val_loss: 0.0650\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0741 - val_loss: 0.0640\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0674 - val_loss: 0.0674\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0691 - val_loss: 0.0647\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0680 - val_loss: 0.0691\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0674 - val_loss: 0.0701\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0707 - val_loss: 0.0737\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0736 - val_loss: 0.0646\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0686 - val_loss: 0.0659\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0660 - val_loss: 0.0681\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0654 - val_loss: 0.0655\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0681 - val_loss: 0.0676\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0700 - val_loss: 0.0711\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0709 - val_loss: 0.0701\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0701 - val_loss: 0.0675\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0673 - val_loss: 0.0663\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0673 - val_loss: 0.0669\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0687 - val_loss: 0.0698\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0732 - val_loss: 0.0619\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0713 - val_loss: 0.0652\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0729 - val_loss: 0.0626\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0690 - val_loss: 0.0689\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0720 - val_loss: 0.0687\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0672 - val_loss: 0.0633\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0669 - val_loss: 0.0700\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0728 - val_loss: 0.0702\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0689 - val_loss: 0.0713\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0686 - val_loss: 0.0664\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0669 - val_loss: 0.0663\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0646 - val_loss: 0.0677\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0662 - val_loss: 0.0663\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0642 - val_loss: 0.0661\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0709 - val_loss: 0.0706\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0721 - val_loss: 0.0634\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0726 - val_loss: 0.0738\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0679 - val_loss: 0.0691\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0685 - val_loss: 0.0673\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0657 - val_loss: 0.0674\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0649 - val_loss: 0.0669\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0656 - val_loss: 0.0701\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0634 - val_loss: 0.0642\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0643 - val_loss: 0.0673\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0650 - val_loss: 0.0647\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0673 - val_loss: 0.0696\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0701 - val_loss: 0.0760\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0755 - val_loss: 0.0719\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0705 - val_loss: 0.0644\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0683 - val_loss: 0.0687\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0680 - val_loss: 0.0694\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0635 - val_loss: 0.0732\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0718 - val_loss: 0.0685\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0662 - val_loss: 0.0687\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0707 - val_loss: 0.0677\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0697 - val_loss: 0.0683\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0690 - val_loss: 0.0663\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0651 - val_loss: 0.0710\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0714 - val_loss: 0.0657\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0665 - val_loss: 0.0656\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0638 - val_loss: 0.0663\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0629 - val_loss: 0.0669\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0642 - val_loss: 0.0646\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0655 - val_loss: 0.0650\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0706 - val_loss: 0.0657\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0728 - val_loss: 0.0752\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0744 - val_loss: 0.0670\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0685 - val_loss: 0.0627\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0705 - val_loss: 0.0644\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0685 - val_loss: 0.0755\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0671 - val_loss: 0.0673\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0647 - val_loss: 0.0669\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0656 - val_loss: 0.0683\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0679 - val_loss: 0.0692\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0649 - val_loss: 0.0678\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0655 - val_loss: 0.0648\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0686 - val_loss: 0.0634\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0687 - val_loss: 0.0625\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0646 - val_loss: 0.0675\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0667 - val_loss: 0.0730\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0693 - val_loss: 0.0662\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0655 - val_loss: 0.0661\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0706 - val_loss: 0.0689\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0698 - val_loss: 0.0702\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0650 - val_loss: 0.0655\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0646 - val_loss: 0.0653\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0637 - val_loss: 0.0651\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0688 - val_loss: 0.0632\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0658 - val_loss: 0.0640\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0690 - val_loss: 0.0661\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0674 - val_loss: 0.0732\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0666 - val_loss: 0.0667\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0682 - val_loss: 0.0732\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0658 - val_loss: 0.0674\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0629 - val_loss: 0.0692\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0626 - val_loss: 0.0647\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0648 - val_loss: 0.0626\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0682 - val_loss: 0.0668\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0657 - val_loss: 0.0642\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0671 - val_loss: 0.0686\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0640 - val_loss: 0.0638\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0663 - val_loss: 0.0639\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0666 - val_loss: 0.0651\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0669 - val_loss: 0.0671\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0639 - val_loss: 0.0651\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0638 - val_loss: 0.0651\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0643 - val_loss: 0.0657\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0648 - val_loss: 0.0686\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0655 - val_loss: 0.0711\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0688 - val_loss: 0.0671\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0648 - val_loss: 0.0659\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0663 - val_loss: 0.0668\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0646 - val_loss: 0.0704\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0647 - val_loss: 0.0706\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0669 - val_loss: 0.0649\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0648 - val_loss: 0.0643\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0629 - val_loss: 0.0651\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0628 - val_loss: 0.0686\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0630 - val_loss: 0.0667\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0632 - val_loss: 0.0708\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0694 - val_loss: 0.0660\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0692 - val_loss: 0.0622\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0657 - val_loss: 0.0652\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0645 - val_loss: 0.0661\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0656 - val_loss: 0.0645\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0649 - val_loss: 0.0633\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0650 - val_loss: 0.0649\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0645 - val_loss: 0.0674\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0666 - val_loss: 0.0657\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0646 - val_loss: 0.0645\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0623 - val_loss: 0.0646\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0619 - val_loss: 0.0667\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0635 - val_loss: 0.0696\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0647 - val_loss: 0.0674\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0644 - val_loss: 0.0684\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0621 - val_loss: 0.0676\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0642 - val_loss: 0.0696\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0645 - val_loss: 0.0659\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0654 - val_loss: 0.0690\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0687 - val_loss: 0.0691\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0653 - val_loss: 0.0695\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0651 - val_loss: 0.0661\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0665 - val_loss: 0.0745\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0688 - val_loss: 0.0644\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0649 - val_loss: 0.0653\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0632 - val_loss: 0.0671\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0628 - val_loss: 0.0714\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0652 - val_loss: 0.0679\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0666 - val_loss: 0.0633\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0662 - val_loss: 0.0631\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0635 - val_loss: 0.0671\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0643 - val_loss: 0.0656\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0635 - val_loss: 0.0637\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0641 - val_loss: 0.0658\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0641 - val_loss: 0.0662\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0647 - val_loss: 0.0659\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0624 - val_loss: 0.0695\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0642 - val_loss: 0.0646\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0642 - val_loss: 0.0617\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0618 - val_loss: 0.0641\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0770 - val_loss: 0.0715\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0791 - val_loss: 0.0671\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0615 - val_loss: 0.0646\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0687 - val_loss: 0.0621\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0683 - val_loss: 0.0679\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0661 - val_loss: 0.0621\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0646 - val_loss: 0.0700\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0678 - val_loss: 0.0702\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0659 - val_loss: 0.0671\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0725 - val_loss: 0.0616\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0715 - val_loss: 0.0643\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0700 - val_loss: 0.0691\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0698 - val_loss: 0.0659\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0631 - val_loss: 0.0695\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0668 - val_loss: 0.0653\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0627 - val_loss: 0.0661\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0607 - val_loss: 0.0685\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0707 - val_loss: 0.0692\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0687 - val_loss: 0.0612\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0628 - val_loss: 0.0658\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0618 - val_loss: 0.0685\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0643 - val_loss: 0.0677\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni_stacked_long_india = build_univariate_stacked_long()\n",
    "model_uni_stacked_long_india.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni_stacked_long_india.save('univar_stacked_long_term.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "145044af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_29 (LSTM)               (None, 3, 100)            40800     \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 191,551\n",
      "Trainable params: 191,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "14/14 [==============================] - 2s 46ms/step - loss: 0.6857 - val_loss: 0.9161\n",
      "Epoch 2/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4468 - val_loss: 0.8429\n",
      "Epoch 3/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.2322 - val_loss: 0.8051\n",
      "Epoch 4/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2025 - val_loss: 0.7825\n",
      "Epoch 5/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1946 - val_loss: 0.7947\n",
      "Epoch 6/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1945 - val_loss: 0.8038\n",
      "Epoch 7/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1908 - val_loss: 0.8030\n",
      "Epoch 8/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1899 - val_loss: 0.7835\n",
      "Epoch 9/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1848 - val_loss: 0.7806\n",
      "Epoch 10/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1820 - val_loss: 0.7946\n",
      "Epoch 11/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1767 - val_loss: 0.8052\n",
      "Epoch 12/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1781 - val_loss: 0.8012\n",
      "Epoch 13/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1714 - val_loss: 0.7894\n",
      "Epoch 14/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1720 - val_loss: 0.7871\n",
      "Epoch 15/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1693 - val_loss: 0.7938\n",
      "Epoch 16/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1680 - val_loss: 0.7868\n",
      "Epoch 17/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1671 - val_loss: 0.7852\n",
      "Epoch 18/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1709 - val_loss: 0.7854\n",
      "Epoch 19/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1712 - val_loss: 0.7972\n",
      "Epoch 20/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1654 - val_loss: 0.7942\n",
      "Epoch 21/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1646 - val_loss: 0.7826\n",
      "Epoch 22/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1617 - val_loss: 0.7943\n",
      "Epoch 23/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1597 - val_loss: 0.7889\n",
      "Epoch 24/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1676 - val_loss: 0.7844\n",
      "Epoch 25/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1590 - val_loss: 0.7729\n",
      "Epoch 26/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1590 - val_loss: 0.7864\n",
      "Epoch 27/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1600 - val_loss: 0.7778\n",
      "Epoch 28/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1570 - val_loss: 0.7799\n",
      "Epoch 29/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1592 - val_loss: 0.7897\n",
      "Epoch 30/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1617 - val_loss: 0.7744\n",
      "Epoch 31/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1572 - val_loss: 0.7748\n",
      "Epoch 32/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1574 - val_loss: 0.7744\n",
      "Epoch 33/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1580 - val_loss: 0.7706\n",
      "Epoch 34/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1556 - val_loss: 0.7770\n",
      "Epoch 35/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1569 - val_loss: 0.7659\n",
      "Epoch 36/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1542 - val_loss: 0.7638\n",
      "Epoch 37/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1544 - val_loss: 0.7714\n",
      "Epoch 38/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1553 - val_loss: 0.7610\n",
      "Epoch 39/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1569 - val_loss: 0.7648\n",
      "Epoch 40/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1570 - val_loss: 0.7652\n",
      "Epoch 41/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1533 - val_loss: 0.7580\n",
      "Epoch 42/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1567 - val_loss: 0.7585\n",
      "Epoch 43/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1603 - val_loss: 0.7521\n",
      "Epoch 44/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1533 - val_loss: 0.7587\n",
      "Epoch 45/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1521 - val_loss: 0.7645\n",
      "Epoch 46/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1569 - val_loss: 0.7639\n",
      "Epoch 47/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1622 - val_loss: 0.7699\n",
      "Epoch 48/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1597 - val_loss: 0.7614\n",
      "Epoch 49/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1550 - val_loss: 0.7596\n",
      "Epoch 50/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1496 - val_loss: 0.7540\n",
      "Epoch 51/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1519 - val_loss: 0.7569\n",
      "Epoch 52/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1560 - val_loss: 0.7451\n",
      "Epoch 53/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1592 - val_loss: 0.7525\n",
      "Epoch 54/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1505 - val_loss: 0.7486\n",
      "Epoch 55/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1512 - val_loss: 0.7550\n",
      "Epoch 56/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1502 - val_loss: 0.7514\n",
      "Epoch 57/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1500 - val_loss: 0.7470\n",
      "Epoch 58/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1559 - val_loss: 0.7559\n",
      "Epoch 59/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1475 - val_loss: 0.7488\n",
      "Epoch 60/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1479 - val_loss: 0.7574\n",
      "Epoch 61/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1478 - val_loss: 0.7563\n",
      "Epoch 62/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1469 - val_loss: 0.7556\n",
      "Epoch 63/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1495 - val_loss: 0.7590\n",
      "Epoch 64/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1474 - val_loss: 0.7625\n",
      "Epoch 65/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1488 - val_loss: 0.7631\n",
      "Epoch 66/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1585 - val_loss: 0.7656\n",
      "Epoch 67/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1500 - val_loss: 0.7664\n",
      "Epoch 68/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1469 - val_loss: 0.7600\n",
      "Epoch 69/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1450 - val_loss: 0.7594\n",
      "Epoch 70/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1456 - val_loss: 0.7655\n",
      "Epoch 71/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1466 - val_loss: 0.7594\n",
      "Epoch 72/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1470 - val_loss: 0.7597\n",
      "Epoch 73/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1470 - val_loss: 0.7612\n",
      "Epoch 74/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1448 - val_loss: 0.7609\n",
      "Epoch 75/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1460 - val_loss: 0.7627\n",
      "Epoch 76/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1434 - val_loss: 0.7608\n",
      "Epoch 77/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1448 - val_loss: 0.7678\n",
      "Epoch 78/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1476 - val_loss: 0.7729\n",
      "Epoch 79/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1485 - val_loss: 0.7639\n",
      "Epoch 80/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1421 - val_loss: 0.7636\n",
      "Epoch 81/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1439 - val_loss: 0.7581\n",
      "Epoch 82/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1458 - val_loss: 0.7651\n",
      "Epoch 83/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1434 - val_loss: 0.7752\n",
      "Epoch 84/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1466 - val_loss: 0.7681\n",
      "Epoch 85/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1420 - val_loss: 0.7681\n",
      "Epoch 86/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1432 - val_loss: 0.7673\n",
      "Epoch 87/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1455 - val_loss: 0.7581\n",
      "Epoch 88/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1427 - val_loss: 0.7607\n",
      "Epoch 89/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1440 - val_loss: 0.7675\n",
      "Epoch 90/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1521 - val_loss: 0.7608\n",
      "Epoch 91/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1461 - val_loss: 0.7675\n",
      "Epoch 92/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1420 - val_loss: 0.7684\n",
      "Epoch 93/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1434 - val_loss: 0.7630\n",
      "Epoch 94/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1439 - val_loss: 0.7654\n",
      "Epoch 95/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1519 - val_loss: 0.7820\n",
      "Epoch 96/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1510 - val_loss: 0.7641\n",
      "Epoch 97/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1421 - val_loss: 0.7635\n",
      "Epoch 98/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1422 - val_loss: 0.7726\n",
      "Epoch 99/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1499 - val_loss: 0.7613\n",
      "Epoch 100/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1438 - val_loss: 0.7726\n",
      "Epoch 101/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1432 - val_loss: 0.7633\n",
      "Epoch 102/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1410 - val_loss: 0.7705\n",
      "Epoch 103/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1383 - val_loss: 0.7786\n",
      "Epoch 104/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1399 - val_loss: 0.7703\n",
      "Epoch 105/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1392 - val_loss: 0.7743\n",
      "Epoch 106/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1409 - val_loss: 0.7712\n",
      "Epoch 107/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1403 - val_loss: 0.7728\n",
      "Epoch 108/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1386 - val_loss: 0.7673\n",
      "Epoch 109/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1404 - val_loss: 0.7724\n",
      "Epoch 110/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1426 - val_loss: 0.7698\n",
      "Epoch 111/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1432 - val_loss: 0.7680\n",
      "Epoch 112/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1398 - val_loss: 0.7716\n",
      "Epoch 113/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1382 - val_loss: 0.7760\n",
      "Epoch 114/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1391 - val_loss: 0.7798\n",
      "Epoch 115/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1376 - val_loss: 0.7744\n",
      "Epoch 116/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1380 - val_loss: 0.7758\n",
      "Epoch 117/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1401 - val_loss: 0.7738\n",
      "Epoch 118/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1389 - val_loss: 0.7885\n",
      "Epoch 119/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1373 - val_loss: 0.7805\n",
      "Epoch 120/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1385 - val_loss: 0.7766\n",
      "Epoch 121/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1396 - val_loss: 0.7708\n",
      "Epoch 122/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1370 - val_loss: 0.7874\n",
      "Epoch 123/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1434 - val_loss: 0.7879\n",
      "Epoch 124/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1391 - val_loss: 0.7753\n",
      "Epoch 125/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1416 - val_loss: 0.7817\n",
      "Epoch 126/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1370 - val_loss: 0.7836\n",
      "Epoch 127/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1419 - val_loss: 0.7735\n",
      "Epoch 128/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1342 - val_loss: 0.7855\n",
      "Epoch 129/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1367 - val_loss: 0.7794\n",
      "Epoch 130/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1342 - val_loss: 0.7868\n",
      "Epoch 131/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1353 - val_loss: 0.7844\n",
      "Epoch 132/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1363 - val_loss: 0.7911\n",
      "Epoch 133/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1389 - val_loss: 0.7817\n",
      "Epoch 134/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1398 - val_loss: 0.7895\n",
      "Epoch 135/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1480 - val_loss: 0.7885\n",
      "Epoch 136/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1385 - val_loss: 0.7874\n",
      "Epoch 137/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1335 - val_loss: 0.7852\n",
      "Epoch 138/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1331 - val_loss: 0.7842\n",
      "Epoch 139/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1373 - val_loss: 0.8001\n",
      "Epoch 140/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1382 - val_loss: 0.7825\n",
      "Epoch 141/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1393 - val_loss: 0.7832\n",
      "Epoch 142/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1424 - val_loss: 0.8015\n",
      "Epoch 143/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1359 - val_loss: 0.7874\n",
      "Epoch 144/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1306 - val_loss: 0.7915\n",
      "Epoch 145/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1366 - val_loss: 0.7815\n",
      "Epoch 146/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1359 - val_loss: 0.7882\n",
      "Epoch 147/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1350 - val_loss: 0.7920\n",
      "Epoch 148/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1378 - val_loss: 0.7934\n",
      "Epoch 149/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1357 - val_loss: 0.7844\n",
      "Epoch 150/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1333 - val_loss: 0.7840\n",
      "Epoch 151/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1389 - val_loss: 0.8001\n",
      "Epoch 152/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1358 - val_loss: 0.7871\n",
      "Epoch 153/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1343 - val_loss: 0.7834\n",
      "Epoch 154/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1333 - val_loss: 0.7904\n",
      "Epoch 155/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1365 - val_loss: 0.7918\n",
      "Epoch 156/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1304 - val_loss: 0.7849\n",
      "Epoch 157/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1309 - val_loss: 0.8049\n",
      "Epoch 158/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1313 - val_loss: 0.7858\n",
      "Epoch 159/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1343 - val_loss: 0.7981\n",
      "Epoch 160/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1321 - val_loss: 0.7966\n",
      "Epoch 161/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1305 - val_loss: 0.7881\n",
      "Epoch 162/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1320 - val_loss: 0.7950\n",
      "Epoch 163/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1294 - val_loss: 0.7971\n",
      "Epoch 164/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1285 - val_loss: 0.7942\n",
      "Epoch 165/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1282 - val_loss: 0.7964\n",
      "Epoch 166/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1284 - val_loss: 0.7971\n",
      "Epoch 167/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1313 - val_loss: 0.7980\n",
      "Epoch 168/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1275 - val_loss: 0.7907\n",
      "Epoch 169/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1345 - val_loss: 0.8022\n",
      "Epoch 170/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1271 - val_loss: 0.7975\n",
      "Epoch 171/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1380 - val_loss: 0.8070\n",
      "Epoch 172/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1293 - val_loss: 0.7937\n",
      "Epoch 173/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1297 - val_loss: 0.7869\n",
      "Epoch 174/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1280 - val_loss: 0.7972\n",
      "Epoch 175/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1277 - val_loss: 0.7980\n",
      "Epoch 176/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1317 - val_loss: 0.8036\n",
      "Epoch 177/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1307 - val_loss: 0.8013\n",
      "Epoch 178/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1310 - val_loss: 0.7991\n",
      "Epoch 179/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1272 - val_loss: 0.8018\n",
      "Epoch 180/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1258 - val_loss: 0.7916\n",
      "Epoch 181/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1327 - val_loss: 0.8085\n",
      "Epoch 182/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1255 - val_loss: 0.8100\n",
      "Epoch 183/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1253 - val_loss: 0.7995\n",
      "Epoch 184/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1321 - val_loss: 0.8030\n",
      "Epoch 185/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1323 - val_loss: 0.8145\n",
      "Epoch 186/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1303 - val_loss: 0.7998\n",
      "Epoch 187/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1278 - val_loss: 0.7963\n",
      "Epoch 188/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1320 - val_loss: 0.8044\n",
      "Epoch 189/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1267 - val_loss: 0.8057\n",
      "Epoch 190/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1252 - val_loss: 0.8177\n",
      "Epoch 191/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1300 - val_loss: 0.8127\n",
      "Epoch 192/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1248 - val_loss: 0.8042\n",
      "Epoch 193/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1287 - val_loss: 0.8096\n",
      "Epoch 194/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1240 - val_loss: 0.8046\n",
      "Epoch 195/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1249 - val_loss: 0.8168\n",
      "Epoch 196/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1258 - val_loss: 0.8206\n",
      "Epoch 197/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1265 - val_loss: 0.8060\n",
      "Epoch 198/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1323 - val_loss: 0.8090\n",
      "Epoch 199/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1284 - val_loss: 0.8213\n",
      "Epoch 200/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1274 - val_loss: 0.8168\n",
      "Epoch 201/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1258 - val_loss: 0.8080\n",
      "Epoch 202/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1249 - val_loss: 0.8138\n",
      "Epoch 203/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1303 - val_loss: 0.8183\n",
      "Epoch 204/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1238 - val_loss: 0.8081\n",
      "Epoch 205/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1243 - val_loss: 0.8117\n",
      "Epoch 206/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1306 - val_loss: 0.8323\n",
      "Epoch 207/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1250 - val_loss: 0.8004\n",
      "Epoch 208/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1239 - val_loss: 0.8082\n",
      "Epoch 209/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1232 - val_loss: 0.8218\n",
      "Epoch 210/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1245 - val_loss: 0.8102\n",
      "Epoch 211/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1244 - val_loss: 0.8142\n",
      "Epoch 212/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1234 - val_loss: 0.8209\n",
      "Epoch 213/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1240 - val_loss: 0.8068\n",
      "Epoch 214/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1244 - val_loss: 0.8066\n",
      "Epoch 215/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1302 - val_loss: 0.8203\n",
      "Epoch 216/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1270 - val_loss: 0.8126\n",
      "Epoch 217/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1280 - val_loss: 0.8060\n",
      "Epoch 218/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1257 - val_loss: 0.8090\n",
      "Epoch 219/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1227 - val_loss: 0.8207\n",
      "Epoch 220/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1271 - val_loss: 0.8230\n",
      "Epoch 221/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1259 - val_loss: 0.8078\n",
      "Epoch 222/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1227 - val_loss: 0.8199\n",
      "Epoch 223/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1212 - val_loss: 0.8167\n",
      "Epoch 224/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1227 - val_loss: 0.8275\n",
      "Epoch 225/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1312 - val_loss: 0.8180\n",
      "Epoch 226/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1265 - val_loss: 0.8117\n",
      "Epoch 227/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1216 - val_loss: 0.8150\n",
      "Epoch 228/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1205 - val_loss: 0.8198\n",
      "Epoch 229/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1213 - val_loss: 0.8321\n",
      "Epoch 230/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1217 - val_loss: 0.8177\n",
      "Epoch 231/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1216 - val_loss: 0.8209\n",
      "Epoch 232/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1214 - val_loss: 0.8200\n",
      "Epoch 233/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1203 - val_loss: 0.8221\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1198 - val_loss: 0.8199\n",
      "Epoch 235/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1230 - val_loss: 0.8179\n",
      "Epoch 236/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1206 - val_loss: 0.8190\n",
      "Epoch 237/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1177 - val_loss: 0.8243\n",
      "Epoch 238/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1213 - val_loss: 0.8339\n",
      "Epoch 239/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1276 - val_loss: 0.8229\n",
      "Epoch 240/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1207 - val_loss: 0.8214\n",
      "Epoch 241/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1214 - val_loss: 0.8181\n",
      "Epoch 242/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1198 - val_loss: 0.8259\n",
      "Epoch 243/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1202 - val_loss: 0.8216\n",
      "Epoch 244/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1189 - val_loss: 0.8264\n",
      "Epoch 245/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1207 - val_loss: 0.8242\n",
      "Epoch 246/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1220 - val_loss: 0.8295\n",
      "Epoch 247/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1236 - val_loss: 0.8286\n",
      "Epoch 248/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1221 - val_loss: 0.8282\n",
      "Epoch 249/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1190 - val_loss: 0.8277\n",
      "Epoch 250/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1189 - val_loss: 0.8222\n",
      "Epoch 251/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1208 - val_loss: 0.8225\n",
      "Epoch 252/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1206 - val_loss: 0.8371\n",
      "Epoch 253/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1213 - val_loss: 0.8265\n",
      "Epoch 254/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1192 - val_loss: 0.8305\n",
      "Epoch 255/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1189 - val_loss: 0.8314\n",
      "Epoch 256/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1241 - val_loss: 0.8304\n",
      "Epoch 257/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1287 - val_loss: 0.8289\n",
      "Epoch 258/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1290 - val_loss: 0.8298\n",
      "Epoch 259/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1272 - val_loss: 0.8350\n",
      "Epoch 260/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1279 - val_loss: 0.8328\n",
      "Epoch 261/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1231 - val_loss: 0.8170\n",
      "Epoch 262/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1188 - val_loss: 0.8286\n",
      "Epoch 263/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1176 - val_loss: 0.8279\n",
      "Epoch 264/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1188 - val_loss: 0.8389\n",
      "Epoch 265/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1171 - val_loss: 0.8349\n",
      "Epoch 266/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1212 - val_loss: 0.8315\n",
      "Epoch 267/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1187 - val_loss: 0.8342\n",
      "Epoch 268/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1196 - val_loss: 0.8412\n",
      "Epoch 269/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1190 - val_loss: 0.8474\n",
      "Epoch 270/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1295 - val_loss: 0.8328\n",
      "Epoch 271/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1184 - val_loss: 0.8307\n",
      "Epoch 272/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1183 - val_loss: 0.8351\n",
      "Epoch 273/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1169 - val_loss: 0.8435\n",
      "Epoch 274/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1184 - val_loss: 0.8425\n",
      "Epoch 275/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1182 - val_loss: 0.8401\n",
      "Epoch 276/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1195 - val_loss: 0.8392\n",
      "Epoch 277/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1165 - val_loss: 0.8326\n",
      "Epoch 278/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1211 - val_loss: 0.8341\n",
      "Epoch 279/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1196 - val_loss: 0.8447\n",
      "Epoch 280/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1160 - val_loss: 0.8383\n",
      "Epoch 281/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1193 - val_loss: 0.8442\n",
      "Epoch 282/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1179 - val_loss: 0.8441\n",
      "Epoch 283/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1200 - val_loss: 0.8420\n",
      "Epoch 284/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1168 - val_loss: 0.8438\n",
      "Epoch 285/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1148 - val_loss: 0.8454\n",
      "Epoch 286/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1192 - val_loss: 0.8424\n",
      "Epoch 287/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1194 - val_loss: 0.8411\n",
      "Epoch 288/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1166 - val_loss: 0.8368\n",
      "Epoch 289/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1156 - val_loss: 0.8403\n",
      "Epoch 290/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1179 - val_loss: 0.8431\n",
      "Epoch 291/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1187 - val_loss: 0.8509\n",
      "Epoch 292/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1180 - val_loss: 0.8500\n",
      "Epoch 293/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1159 - val_loss: 0.8467\n",
      "Epoch 294/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1197 - val_loss: 0.8465\n",
      "Epoch 295/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1149 - val_loss: 0.8418\n",
      "Epoch 296/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1159 - val_loss: 0.8599\n",
      "Epoch 297/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1165 - val_loss: 0.8499\n",
      "Epoch 298/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1173 - val_loss: 0.8546\n",
      "Epoch 299/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1211 - val_loss: 0.8487\n",
      "Epoch 300/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1176 - val_loss: 0.8556\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_uni_stacked_long_usa = build_univariate_stacked()\n",
    "model_uni_stacked_long_usa.fit(usa_cases_train_X,\n",
    "          usa_cases_train_y, \n",
    "          validation_data=(usa_cases_test_X, usa_cases_test_y),\n",
    "          epochs=300,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni_stacked_long_usa.save('univar_stacked_long_term_usa.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cdc896",
   "metadata": {},
   "source": [
    "<a name=predict></a>\n",
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1df6917e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 3, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_cases_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0cd8ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_cases_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2645ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test_X, model):\n",
    "    x_input = np.array(test_X)\n",
    "    y_hat = model.predict(x_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate Non Stacked -- Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4df1259b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 3, 1)\n",
      "(122, 10)\n"
     ]
    }
   ],
   "source": [
    "# Predictions for india cases on test dataset\n",
    "x_input_uni_non_stacked_india = np.array(india_cases_test_X)\n",
    "print(x_input_uni_non_stacked_india.shape)\n",
    "yhat_uni_non_stacked_india = model_uni_non_stacked.predict(x_input)\n",
    "print(yhat_uni_non_stacked_india.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for usa cases on test dataset\n",
    "x_input_uni_non_stacked_usa = np.array(usa_cases_test_X)\n",
    "print(x_input_uni_non_stacked_usa.shape)\n",
    "yhat_uni_non_stacked_usa = model_uni_non_stacked_usa.predict(x_input)\n",
    "print(yhat_uni_non_stacked_usa.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5498ea",
   "metadata": {},
   "source": [
    "### Univariate Non Stacked -- Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45ed9224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 3, 1)\n",
      "(122, 10)\n"
     ]
    }
   ],
   "source": [
    "# Predictions for india cases on test dataset\n",
    "x_input_uni_non_stacked_long_india = np.array(india_cases_test_X)\n",
    "print(x_input_uni_non_stacked_long_india.shape)\n",
    "yhat_uni_non_stacked_long_india = model_uni_non_stacked_long_india.predict(x_input)\n",
    "print(yhat_uni_non_stacked_long_india.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d08e090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 3, 1)\n",
      "(122, 10)\n"
     ]
    }
   ],
   "source": [
    "# Predictions for india cases on test dataset\n",
    "x_input_uni_non_stacked_long = np.array(india_cases_test_X)\n",
    "print(x_input_uni_non_stacked_long.shape)\n",
    "yhat_uni_non_stacked_long = model_uni_non_stacked_long.predict(x_input)\n",
    "print(yhat_uni_non_stacked_long.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate Stacked -- Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28f95543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 3, 1)\n",
      "(122, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predictions for india cases on test dataset\n",
    "x_input_uni_stacked = np.array(india_cases_test_X)\n",
    "print(x_input_uni_stacked.shape)\n",
    "yhat_uni_stacked = model_uni_stacked.predict(x_input)\n",
    "print(yhat_uni_stacked.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate Stacked -- Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91c5d74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 3, 1)\n",
      "(122, 10)\n"
     ]
    }
   ],
   "source": [
    "# Predictions for india cases on test dataset\n",
    "x_input_uni_stacked_long = np.array(india_cases_test_X)\n",
    "print(x_input_uni_stacked_long.shape)\n",
    "yhat_uni_stacked_long = model_uni_stacked_long.predict(x_input)\n",
    "print(yhat_uni_stacked_long.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82a69f",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788eade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate Non Stacked -- Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ca77a056",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.4175"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape = MeanAbsolutePercentageError()\n",
    "mape(india_cases_test_y, yhat_uni_non_stacked_india).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f109939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.061723262"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = MeanAbsoluteError()\n",
    "mae(india_cases_test_y, yhat_uni_non_stacked_india).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate Non Stacked -- Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca77a056",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.458015"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape = MeanAbsolutePercentageError()\n",
    "mape(india_cases_test_y, yhat_uni_non_stacked_long).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5f109939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06621277"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = MeanAbsoluteError()\n",
    "mae(india_cases_test_y, yhat_uni_non_stacked_long).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate Stacked -- Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca77a056",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.859512"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape = MeanAbsolutePercentageError()\n",
    "mape(india_cases_test_y, yhat_uni_stacked).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f109939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060793385"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = MeanAbsoluteError()\n",
    "mae(india_cases_test_y, yhat_uni_stacked).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate Stacked -- Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca77a056",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.21965"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape = MeanAbsolutePercentageError()\n",
    "mape(india_cases_test_y, yhat_uni_stacked_long).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f109939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.061704535"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = MeanAbsoluteError()\n",
    "mae(india_cases_test_y, yhat_uni_stacked_long).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc16329",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73816cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "1220\n"
     ]
    }
   ],
   "source": [
    "# Reversing Z-score normalization\n",
    "\n",
    "casted_mean = india_cases_mean.to_numpy()\n",
    "casted_std = india_cases_std.to_numpy()\n",
    "\n",
    "india_cases_test_scaled = (india_cases_test*india_cases_std[0])+india_cases_mean[0]\n",
    "yhat_uni_non_stacked = (india_cases_std[0]*yhat_uni_non_stacked)+india_cases_mean[0]\n",
    "yhat_uni_non_stacked_long = (india_cases_std[0]*yhat_uni_non_stacked_long)+india_cases_mean[0]\n",
    "yhat_uni_stacked = (india_cases_std[0]*yhat_uni_stacked)+india_cases_mean[0]\n",
    "yhat_uni_stacked_long = (india_cases_std[0]*yhat_uni_stacked_long)+india_cases_mean[0]\n",
    "\n",
    "print(yhat_uni_non_stacked.size)\n",
    "print(yhat_scaled.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4246121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fore_test(test, fore, title):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(12, 8)\n",
    "\n",
    "    ax.plot(test, color='blue', label='Test')\n",
    "    ax.plot(fore, color='red', label='Forecast')\n",
    "    ax.legend(loc='best')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate Non Stacked -- Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4dae349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fore_test(india_cases_test_scaled, yhat_uni_non_stacked, title='Daily cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate Non Stacked -- Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4dae349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fore_test(india_cases_test_scaled, yhat_uni_non_stacked_long, title='Daily cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate Stacked -- Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4dae349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fore_test(india_cases_test_scaled, yhat_uni_stacked, title='Daily cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa55519",
   "metadata": {},
   "source": [
    "### Univariate Stacked -- Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4dae349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fore_test(india_cases_test_scaled, yhat_uni_stacked_long, title='Daily cases')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
