{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. [Imports](#imports)\n",
    "2. [Data](#data)\n",
    "3. [Model](#model)\n",
    "5. [Train](#train)\n",
    "6. [Predict](#predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=imports></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f68681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=data></a>\n",
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ed14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path of the current working directory\n",
    "curPath = os.getcwd()\n",
    "# Appened the parent directory to the current path to step out of the current folder\n",
    "parentDir = os.path.abspath(os.path.join(curPath, os.pardir))\n",
    "print(\"Parent Directory\", parentDir)\n",
    "# Save the path to all of the datasets\n",
    "india_cases_path = os.path.join(parentDir, \"../cleaned_datasets/india/daily_cases_india.csv\")\n",
    "india_vacc_path = os.path.join(parentDir, \"../cleaned_datasets/india/daily_vacc_india.csv\")\n",
    "usa_cases_path = os.path.join(parentDir, \"../cleaned_datasets/usa/daily_cases_usa.csv\")\n",
    "usa_vacc_path = os.path.join(parentDir, \"../cleaned_datasets/usa/vacc_usa.csv\")\n",
    "\n",
    "# Quick check to make sure the path exists\n",
    "print(\"Path:\", india_cases_path)\n",
    "print(\"Exists:\", os.path.exists(india_cases_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18b18a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data as a pandas dataframe\n",
    "india_cases_df = pd.read_csv(india_cases_path)\n",
    "india_vacc_df =  pd.read_csv(india_vacc_path)\n",
    "\n",
    "usa_cases_df = pd.read_csv(usa_cases_path)\n",
    "usa_vacc_df = pd.read_csv(usa_vacc_path)\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('India Vacc:\\n',india_vacc_df.head(),'\\n')\n",
    "\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')\n",
    "print('USA Vacc:\\n',usa_vacc_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897297ae",
   "metadata": {},
   "source": [
    "### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03503052",
   "metadata": {},
   "outputs": [],
   "source": [
    "india_cases_multi_df = india_cases_df[[\"Date\",\"Confirmed\",\"Deaths\",\"Recovered\",\"Active\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd4455",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the Confirmed column for univariate analysis\n",
    "# Selecting from the first index because the 0th index is NaN\n",
    "india_cases_df = india_cases_df[[\"Confirmed\"]][1:]\n",
    "usa_cases_df = usa_cases_df[[\"Confirmed\"]][1:]\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "india_cases_mean = india_cases_df.mean()\n",
    "india_cases_std = india_cases_df.std()\n",
    "\n",
    "usa_cases_mean = usa_cases_df.mean()\n",
    "usa_cases_std = usa_cases_df.std()\n",
    "\n",
    "\n",
    "india_cases_df = (india_cases_df-india_cases_mean)/india_cases_std\n",
    "usa_cases_df = (usa_cases_df-usa_cases_mean)/usa_cases_std\n",
    "\n",
    "# Visualize the datasets\n",
    "print('India Cases:\\n',india_cases_df.head(),'\\n')\n",
    "print('USA Cases:\\n',usa_cases_df.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train test splits\n",
    "india_cases_train, india_cases_test = train_test_split(india_cases_df, test_size=0.2, shuffle=False)\n",
    "india_vacc_train, india_vacc_test = train_test_split(india_vacc_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "usa_cases_train, usa_cases_test = train_test_split(usa_cases_df, test_size=0.2, shuffle=False)\n",
    "usa_vacc_train, usa_vacc_test = train_test_split(usa_vacc_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Visualize splits\n",
    "print('India Cases:\\n',india_cases_train,'\\n')\n",
    "print('USA Cases:\\n',usa_cases_train,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa1445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "india_cases_train, india_cases_test = india_cases_train.to_numpy().flatten(), india_cases_test.to_numpy()\n",
    "usa_cases_train, usa_cases_test = usa_cases_train.to_numpy().flatten(), usa_cases_test.to_numpy()\n",
    "\n",
    "# Visualize outputs\n",
    "print('India Cases:\\n',india_cases_train,'\\n')\n",
    "print('USA Cases:\\n',usa_cases_train,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80961213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate data preparation\n",
    "from numpy import array\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9fb009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "india_cases_train_X, india_cases_train_y = split_sequence(india_cases_train, n_steps)\n",
    "india_cases_test_X, india_cases_test_y = split_sequence(india_cases_test, n_steps)\n",
    "\n",
    "\n",
    "# summarize the data\n",
    "for i in range(0,5):\n",
    "    print(india_cases_train_X[i], india_cases_train_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data into [samples, timesteps, features]\n",
    "# univariate\n",
    "n_features = 1\n",
    "\n",
    "india_cases_train_X = india_cases_train_X.reshape((india_cases_train_X.shape[0], \n",
    "                                                   india_cases_train_X.shape[1], n_features))\n",
    "india_cases_test_X = india_cases_test_X.reshape((india_cases_test_X.shape[0], \n",
    "                                                 india_cases_test_X.shape[1], n_features))\n",
    "\n",
    "# Visualize outputs\n",
    "print('India Cases:\\n',india_cases_train_X,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=model></a>\n",
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate non-stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6209e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.losses import MeanAbsolutePercentageError, MeanAbsoluteError\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3bf1a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_univariate_non_stacked(optimizer=\"adam\", lstm_nparams=100, n_steps=3, n_features=1):\n",
    "    model_uni = Sequential()\n",
    "    model_uni.add(LSTM(lstm_nparams, activation='relu', input_shape=(n_steps, n_features)))\n",
    "    model_uni.add(Dense(1))\n",
    "    model_uni.compile(optimizer=optimizer,loss='mae', metrics=[\"mae\"])\n",
    "    model_uni.summary()\n",
    "    return model_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6dd043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KerasClassifier wrapper \n",
    "keras_estimator = KerasRegressor(build_fn=build_univariate_non_stacked, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for the gridserach\n",
    "param_grid = {\n",
    "#     'epochs': [10,100,300,],\n",
    "    'lstm_nparams':[15,50],\n",
    "#     'n_steps': [3, 6, 15],\n",
    "#     'optimizer': ['RMSprop','Adam','Adamax','sgd']\n",
    "}\n",
    "\n",
    "kfold_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GridSearch\n",
    "grid = GridSearchCV(estimator=keras_estimator,\n",
    "                    verbose=-1,\n",
    "                    return_train_score=True,\n",
    "                    cv=kfold_splits,\n",
    "                    param_grid=param_grid,\n",
    "#                     scoring=\"neg_mean_absolute_error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc73262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting GridSearch\n",
    "grid_result = grid.fit(india_cases_train_X, india_cases_train_y, )\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the gridsearch results to file\n",
    "file1 = open(\"univariate_non_stacked_india.txt\", \"w\")\n",
    "file1.write(\"mean,stdev,pram\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    file1.write(\"%f,%f,%r\" % (mean, stdev, param))\n",
    "    file1.write(\"\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc006cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(grid_result.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab879991",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.cv_results_['split2_train_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_univariate_stacked(optimizer=\"adam\",lstm_nparams_l1=100, lstm_nparams_l2=150, n_steps=3, n_features=1):\n",
    "    model_uni_stacked = Sequential()\n",
    "    model_uni_stacked.add(LSTM(lstm_nparams_l1, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    model_uni_stacked.add(LSTM(lstm_nparams_l2, activation='relu'))\n",
    "    model_uni_stacked.add(Dense(1))\n",
    "    model_uni_stacked.compile(optimizer=optimizer,loss='mae')\n",
    "    model_uni_stacked.summary()\n",
    "    return model_uni_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31103e54",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d090ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KerasClassifier wrapper \n",
    "keras_estimator = KerasRegressor(build_fn=build_univariate_stacked, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5796d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for the gridserach\n",
    "param_grid = {\n",
    "    'epochs': [10,100,300,],\n",
    "    'lstm_nparams_l1':[15,50,100,150],\n",
    "    'lstm_nparams_l2':[15,50,100,150],\n",
    "    'n_steps': [3, 6, 15],\n",
    "#     'optimizer': ['RMSprop','Adam','Adamax','sgd']\n",
    "}\n",
    "\n",
    "kfold_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac03a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GridSearch\n",
    "grid = GridSearchCV(estimator=keras_estimator,\n",
    "                    verbose=-1,\n",
    "                    return_train_score=True,\n",
    "                    cv=kfold_splits,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring=\"neg_mean_absolute_error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1044188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting GridSearch\n",
    "grid_result = grid.fit(india_cases_train_X, india_cases_train_y, )\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the gridsearch results to file\n",
    "file1 = open(\"univariate_stacked_india.txt\", \"w\")\n",
    "file1.write(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "file1.write(\"\\n\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    file1.write(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    file1.write(\"\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f9fbe",
   "metadata": {},
   "source": [
    "## Multivariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_uni = Sequential()\n",
    "model_uni.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model_uni.add(Dense(1))\n",
    "model_uni.compile(optimizer='adam',loss='mae')\n",
    "model_uni.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=train></a>\n",
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1eb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard callback\n",
    "logdir = os.path.join(parentDir+\"/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate non-stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165ffb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model_uni = build_univariate_non_stacked()\n",
    "model_uni.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=500,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni.save('univar_1_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model_uni_stacked.fit(india_cases_train_X,\n",
    "          india_cases_train_y, \n",
    "          validation_data=(india_cases_test_X, india_cases_test_y),\n",
    "          epochs=500,\n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "model_uni_stacked.save('univar_2_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=predict></a>\n",
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india_cases_test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_input = np.array(india_cases_test_X)\n",
    "print(x_input)\n",
    "yhat = model_uni.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73816cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversing Z-score normalization\n",
    "\n",
    "india_cases_df = (india_cases_df-india_cases_mean)/india_cases_std\n",
    "usa_cases_df = (usa_cases_df-usa_cases_mean)/usa_cases_std\n",
    "\n",
    "x_input_scaled = india_cases_std*x_input+india_cases_mean\n",
    "yhat_scaled = india_cases_std*yhat+india_cases_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc16329",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fore_test(test, fore, title):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(7, 7)\n",
    "\n",
    "    ax.plot(test, color='blue', label='Test')\n",
    "    ax.plot(fore, color='red', label='Forecast')\n",
    "    ax.legend(loc='best')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dae349",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fore_test(x_input_scaled, yhat_scaled, title='Daily cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array(india_cases_test_X)\n",
    "print(x_input)\n",
    "yhat_stacked = model_uni_stacked.predict(x_input)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mape = MeanAbsolutePercentageError()\n",
    "mape(india_cases_test_y, yhat).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = MeanAbsoluteError()\n",
    "mae(india_cases_test_y, yhat).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mape(india_cases_test_y, yhat_stacked).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
